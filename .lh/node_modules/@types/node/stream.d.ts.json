{
    "sourceFile": "node_modules/@types/node/stream.d.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1746891956119,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1746891704042,
            "name": "cart",
            "content": "/**\n * A stream is an abstract interface for working with streaming data in Node.js.\n * The `node:stream` module provides an API for implementing the stream interface.\n *\n * There are many stream objects provided by Node.js. For instance, a [request to an HTTP server](https://nodejs.org/docs/latest-v22.x/api/http.html#class-httpincomingmessage)\n * and [`process.stdout`](https://nodejs.org/docs/latest-v22.x/api/process.html#processstdout) are both stream instances.\n *\n * Streams can be readable, writable, or both. All streams are instances of [`EventEmitter`](https://nodejs.org/docs/latest-v22.x/api/events.html#class-eventemitter).\n *\n * To access the `node:stream` module:\n *\n * ```js\n * import stream from 'node:stream';\n * ```\n *\n * The `node:stream` module is useful for creating new types of stream instances.\n * It is usually not necessary to use the `node:stream` module to consume streams.\n * @see [source](https://github.com/nodejs/node/blob/v22.x/lib/stream.js)\n */\ndeclare module \"stream\" {\n    import { Abortable, EventEmitter } from \"node:events\";\n    import { Blob as NodeBlob } from \"node:buffer\";\n    import * as streamPromises from \"node:stream/promises\";\n    import * as streamWeb from \"node:stream/web\";\n\n    type ComposeFnParam = (source: any) => void;\n\n    class Stream extends EventEmitter {\n        pipe<T extends NodeJS.WritableStream>(\n            destination: T,\n            options?: {\n                end?: boolean | undefined;\n            },\n        ): T;\n        compose<T extends NodeJS.ReadableStream>(\n            stream: T | ComposeFnParam | Iterable<T> | AsyncIterable<T>,\n            options?: { signal: AbortSignal },\n        ): T;\n    }\n    namespace Stream {\n        export { Stream, streamPromises as promises };\n    }\n    namespace Stream {\n        interface StreamOptions<T extends Stream> extends Abortable {\n            emitClose?: boolean | undefined;\n            highWaterMark?: number | undefined;\n            objectMode?: boolean | undefined;\n            construct?(this: T, callback: (error?: Error | null) => void): void;\n            destroy?(this: T, error: Error | null, callback: (error?: Error | null) => void): void;\n            autoDestroy?: boolean | undefined;\n        }\n        interface ReadableOptions<T extends Readable = Readable> extends StreamOptions<T> {\n            encoding?: BufferEncoding | undefined;\n            read?(this: T, size: number): void;\n        }\n        interface ArrayOptions {\n            /**\n             * The maximum concurrent invocations of `fn` to call on the stream at once.\n             * @default 1\n             */\n            concurrency?: number;\n            /** Allows destroying the stream if the signal is aborted. */\n            signal?: AbortSignal;\n        }\n        /**\n         * @since v0.9.4\n         */\n        class Readable extends Stream implements NodeJS.ReadableStream {\n            /**\n             * A utility method for creating Readable Streams out of iterators.\n             * @since v12.3.0, v10.17.0\n             * @param iterable Object implementing the `Symbol.asyncIterator` or `Symbol.iterator` iterable protocol. Emits an 'error' event if a null value is passed.\n             * @param options Options provided to `new stream.Readable([options])`. By default, `Readable.from()` will set `options.objectMode` to `true`, unless this is explicitly opted out by setting `options.objectMode` to `false`.\n             */\n            static from(iterable: Iterable<any> | AsyncIterable<any>, options?: ReadableOptions): Readable;\n            /**\n             * A utility method for creating a `Readable` from a web `ReadableStream`.\n             * @since v17.0.0\n             * @experimental\n             */\n            static fromWeb(\n                readableStream: streamWeb.ReadableStream,\n                options?: Pick<ReadableOptions, \"encoding\" | \"highWaterMark\" | \"objectMode\" | \"signal\">,\n            ): Readable;\n            /**\n             * A utility method for creating a web `ReadableStream` from a `Readable`.\n             * @since v17.0.0\n             * @experimental\n             */\n            static toWeb(\n                streamReadable: Readable,\n                options?: {\n                    strategy?: streamWeb.QueuingStrategy | undefined;\n                },\n            ): streamWeb.ReadableStream;\n            /**\n             * Returns whether the stream has been read from or cancelled.\n             * @since v16.8.0\n             */\n            static isDisturbed(stream: Readable | NodeJS.ReadableStream): boolean;\n            /**\n             * Returns whether the stream was destroyed or errored before emitting `'end'`.\n             * @since v16.8.0\n             * @experimental\n             */\n            readonly readableAborted: boolean;\n            /**\n             * Is `true` if it is safe to call {@link read}, which means\n             * the stream has not been destroyed or emitted `'error'` or `'end'`.\n             * @since v11.4.0\n             */\n            readable: boolean;\n            /**\n             * Returns whether `'data'` has been emitted.\n             * @since v16.7.0, v14.18.0\n             * @experimental\n             */\n            readonly readableDidRead: boolean;\n            /**\n             * Getter for the property `encoding` of a given `Readable` stream. The `encoding` property can be set using the {@link setEncoding} method.\n             * @since v12.7.0\n             */\n            readonly readableEncoding: BufferEncoding | null;\n            /**\n             * Becomes `true` when [`'end'`](https://nodejs.org/docs/latest-v22.x/api/stream.html#event-end) event is emitted.\n             * @since v12.9.0\n             */\n            readonly readableEnded: boolean;\n            /**\n             * This property reflects the current state of a `Readable` stream as described\n             * in the [Three states](https://nodejs.org/docs/latest-v22.x/api/stream.html#three-states) section.\n             * @since v9.4.0\n             */\n            readonly readableFlowing: boolean | null;\n            /**\n             * Returns the value of `highWaterMark` passed when creating this `Readable`.\n             * @since v9.3.0\n             */\n            readonly readableHighWaterMark: number;\n            /**\n             * This property contains the number of bytes (or objects) in the queue\n             * ready to be read. The value provides introspection data regarding\n             * the status of the `highWaterMark`.\n             * @since v9.4.0\n             */\n            readonly readableLength: number;\n            /**\n             * Getter for the property `objectMode` of a given `Readable` stream.\n             * @since v12.3.0\n             */\n            readonly readableObjectMode: boolean;\n            /**\n             * Is `true` after `readable.destroy()` has been called.\n             * @since v8.0.0\n             */\n            destroyed: boolean;\n            /**\n             * Is `true` after `'close'` has been emitted.\n             * @since v18.0.0\n             */\n            readonly closed: boolean;\n            /**\n             * Returns error if the stream has been destroyed with an error.\n             * @since v18.0.0\n             */\n            readonly errored: Error | null;\n            constructor(opts?: ReadableOptions);\n            _construct?(callback: (error?: Error | null) => void): void;\n            _read(size: number): void;\n            /**\n             * The `readable.read()` method reads data out of the internal buffer and\n             * returns it. If no data is available to be read, `null` is returned. By default,\n             * the data is returned as a `Buffer` object unless an encoding has been\n             * specified using the `readable.setEncoding()` method or the stream is operating\n             * in object mode.\n             *\n             * The optional `size` argument specifies a specific number of bytes to read. If\n             * `size` bytes are not available to be read, `null` will be returned _unless_ the\n             * stream has ended, in which case all of the data remaining in the internal buffer\n             * will be returned.\n             *\n             * If the `size` argument is not specified, all of the data contained in the\n             * internal buffer will be returned.\n             *\n             * The `size` argument must be less than or equal to 1 GiB.\n             *\n             * The `readable.read()` method should only be called on `Readable` streams\n             * operating in paused mode. In flowing mode, `readable.read()` is called\n             * automatically until the internal buffer is fully drained.\n             *\n             * ```js\n             * const readable = getReadableStreamSomehow();\n             *\n             * // 'readable' may be triggered multiple times as data is buffered in\n             * readable.on('readable', () => {\n             *   let chunk;\n             *   console.log('Stream is readable (new data received in buffer)');\n             *   // Use a loop to make sure we read all currently available data\n             *   while (null !== (chunk = readable.read())) {\n             *     console.log(`Read ${chunk.length} bytes of data...`);\n             *   }\n             * });\n             *\n             * // 'end' will be triggered once when there is no more data available\n             * readable.on('end', () => {\n             *   console.log('Reached end of stream.');\n             * });\n             * ```\n             *\n             * Each call to `readable.read()` returns a chunk of data, or `null`. The chunks\n             * are not concatenated. A `while` loop is necessary to consume all data\n             * currently in the buffer. When reading a large file `.read()` may return `null`,\n             * having consumed all buffered content so far, but there is still more data to\n             * come not yet buffered. In this case a new `'readable'` event will be emitted\n             * when there is more data in the buffer. Finally the `'end'` event will be\n             * emitted when there is no more data to come.\n             *\n             * Therefore to read a file's whole contents from a `readable`, it is necessary\n             * to collect chunks across multiple `'readable'` events:\n             *\n             * ```js\n             * const chunks = [];\n             *\n             * readable.on('readable', () => {\n             *   let chunk;\n             *   while (null !== (chunk = readable.read())) {\n             *     chunks.push(chunk);\n             *   }\n             * });\n             *\n             * readable.on('end', () => {\n             *   const content = chunks.join('');\n             * });\n             * ```\n             *\n             * A `Readable` stream in object mode will always return a single item from\n             * a call to `readable.read(size)`, regardless of the value of the `size` argument.\n             *\n             * If the `readable.read()` method returns a chunk of data, a `'data'` event will\n             * also be emitted.\n             *\n             * Calling {@link read} after the `'end'` event has\n             * been emitted will return `null`. No runtime error will be raised.\n             * @since v0.9.4\n             * @param size Optional argument to specify how much data to read.\n             */\n            read(size?: number): any;\n            /**\n             * The `readable.setEncoding()` method sets the character encoding for\n             * data read from the `Readable` stream.\n             *\n             * By default, no encoding is assigned and stream data will be returned as `Buffer` objects. Setting an encoding causes the stream data\n             * to be returned as strings of the specified encoding rather than as `Buffer` objects. For instance, calling `readable.setEncoding('utf8')` will cause the\n             * output data to be interpreted as UTF-8 data, and passed as strings. Calling `readable.setEncoding('hex')` will cause the data to be encoded in hexadecimal\n             * string format.\n             *\n             * The `Readable` stream will properly handle multi-byte characters delivered\n             * through the stream that would otherwise become improperly decoded if simply\n             * pulled from the stream as `Buffer` objects.\n             *\n             * ```js\n             * const readable = getReadableStreamSomehow();\n             * readable.setEncoding('utf8');\n             * readable.on('data', (chunk) => {\n             *   assert.equal(typeof chunk, 'string');\n             *   console.log('Got %d characters of string data:', chunk.length);\n             * });\n             * ```\n             * @since v0.9.4\n             * @param encoding The encoding to use.\n             */\n            setEncoding(encoding: BufferEncoding): this;\n            /**\n             * The `readable.pause()` method will cause a stream in flowing mode to stop\n             * emitting `'data'` events, switching out of flowing mode. Any data that\n             * becomes available will remain in the internal buffer.\n             *\n             * ```js\n             * const readable = getReadableStreamSomehow();\n             * readable.on('data', (chunk) => {\n             *   console.log(`Received ${chunk.length} bytes of data.`);\n             *   readable.pause();\n             *   console.log('There will be no additional data for 1 second.');\n             *   setTimeout(() => {\n             *     console.log('Now data will start flowing again.');\n             *     readable.resume();\n             *   }, 1000);\n             * });\n             * ```\n             *\n             * The `readable.pause()` method has no effect if there is a `'readable'` event listener.\n             * @since v0.9.4\n             */\n            pause(): this;\n            /**\n             * The `readable.resume()` method causes an explicitly paused `Readable` stream to\n             * resume emitting `'data'` events, switching the stream into flowing mode.\n             *\n             * The `readable.resume()` method can be used to fully consume the data from a\n             * stream without actually processing any of that data:\n             *\n             * ```js\n             * getReadableStreamSomehow()\n             *   .resume()\n             *   .on('end', () => {\n             *     console.log('Reached the end, but did not read anything.');\n             *   });\n             * ```\n             *\n             * The `readable.resume()` method has no effect if there is a `'readable'` event listener.\n             * @since v0.9.4\n             */\n            resume(): this;\n            /**\n             * The `readable.isPaused()` method returns the current operating state of the `Readable`.\n             * This is used primarily by the mechanism that underlies the `readable.pipe()` method.\n             * In most typical cases, there will be no reason to use this method directly.\n             *\n             * ```js\n             * const readable = new stream.Readable();\n             *\n             * readable.isPaused(); // === false\n             * readable.pause();\n             * readable.isPaused(); // === true\n             * readable.resume();\n             * readable.isPaused(); // === false\n             * ```\n             * @since v0.11.14\n             */\n            isPaused(): boolean;\n            /**\n             * The `readable.unpipe()` method detaches a `Writable` stream previously attached\n             * using the {@link pipe} method.\n             *\n             * If the `destination` is not specified, then _all_ pipes are detached.\n             *\n             * If the `destination` is specified, but no pipe is set up for it, then\n             * the method does nothing.\n             *\n             * ```js\n             * import fs from 'node:fs';\n             * const readable = getReadableStreamSomehow();\n             * const writable = fs.createWriteStream('file.txt');\n             * // All the data from readable goes into 'file.txt',\n             * // but only for the first second.\n             * readable.pipe(writable);\n             * setTimeout(() => {\n             *   console.log('Stop writing to file.txt.');\n             *   readable.unpipe(writable);\n             *   console.log('Manually close the file stream.');\n             *   writable.end();\n             * }, 1000);\n             * ```\n             * @since v0.9.4\n             * @param destination Optional specific stream to unpipe\n             */\n            unpipe(destination?: NodeJS.WritableStream): this;\n            /**\n             * Passing `chunk` as `null` signals the end of the stream (EOF) and behaves the\n             * same as `readable.push(null)`, after which no more data can be written. The EOF\n             * signal is put at the end of the buffer and any buffered data will still be\n             * flushed.\n             *\n             * The `readable.unshift()` method pushes a chunk of data back into the internal\n             * buffer. This is useful in certain situations where a stream is being consumed by\n             * code that needs to \"un-consume\" some amount of data that it has optimistically\n             * pulled out of the source, so that the data can be passed on to some other party.\n             *\n             * The `stream.unshift(chunk)` method cannot be called after the `'end'` event\n             * has been emitted or a runtime error will be thrown.\n             *\n             * Developers using `stream.unshift()` often should consider switching to\n             * use of a `Transform` stream instead. See the `API for stream implementers` section for more information.\n             *\n             * ```js\n             * // Pull off a header delimited by \\n\\n.\n             * // Use unshift() if we get too much.\n             * // Call the callback with (error, header, stream).\n             * import { StringDecoder } from 'node:string_decoder';\n             * function parseHeader(stream, callback) {\n             *   stream.on('error', callback);\n             *   stream.on('readable', onReadable);\n             *   const decoder = new StringDecoder('utf8');\n             *   let header = '';\n             *   function onReadable() {\n             *     let chunk;\n             *     while (null !== (chunk = stream.read())) {\n             *       const str = decoder.write(chunk);\n             *       if (str.includes('\\n\\n')) {\n             *         // Found the header boundary.\n             *         const split = str.split(/\\n\\n/);\n             *         header += split.shift();\n             *         const remaining = split.join('\\n\\n');\n             *         const buf = Buffer.from(remaining, 'utf8');\n             *         stream.removeListener('error', callback);\n             *         // Remove the 'readable' listener before unshifting.\n             *         stream.removeListener('readable', onReadable);\n             *         if (buf.length)\n             *           stream.unshift(buf);\n             *         // Now the body of the message can be read from the stream.\n             *         callback(null, header, stream);\n             *         return;\n             *       }\n             *       // Still reading the header.\n             *       header += str;\n             *     }\n             *   }\n             * }\n             * ```\n             *\n             * Unlike {@link push}, `stream.unshift(chunk)` will not\n             * end the reading process by resetting the internal reading state of the stream.\n             * This can cause unexpected results if `readable.unshift()` is called during a\n             * read (i.e. from within a {@link _read} implementation on a\n             * custom stream). Following the call to `readable.unshift()` with an immediate {@link push} will reset the reading state appropriately,\n             * however it is best to simply avoid calling `readable.unshift()` while in the\n             * process of performing a read.\n             * @since v0.9.11\n             * @param chunk Chunk of data to unshift onto the read queue. For streams not operating in object mode, `chunk` must\n             * be a {string}, {Buffer}, {TypedArray}, {DataView} or `null`. For object mode streams, `chunk` may be any JavaScript value.\n             * @param encoding Encoding of string chunks. Must be a valid `Buffer` encoding, such as `'utf8'` or `'ascii'`.\n             */\n            unshift(chunk: any, encoding?: BufferEncoding): void;\n            /**\n             * Prior to Node.js 0.10, streams did not implement the entire `node:stream` module API as it is currently defined. (See `Compatibility` for more\n             * information.)\n             *\n             * When using an older Node.js library that emits `'data'` events and has a {@link pause} method that is advisory only, the `readable.wrap()` method can be used to create a `Readable`\n             * stream that uses\n             * the old stream as its data source.\n             *\n             * It will rarely be necessary to use `readable.wrap()` but the method has been\n             * provided as a convenience for interacting with older Node.js applications and\n             * libraries.\n             *\n             * ```js\n             * import { OldReader } from './old-api-module.js';\n             * import { Readable } from 'node:stream';\n             * const oreader = new OldReader();\n             * const myReader = new Readable().wrap(oreader);\n             *\n             * myReader.on('readable', () => {\n             *   myReader.read(); // etc.\n             * });\n             * ```\n             * @since v0.9.4\n             * @param stream An \"old style\" readable stream\n             */\n            wrap(stream: NodeJS.ReadableStream): this;\n            push(chunk: any, encoding?: BufferEncoding): boolean;\n            /**\n             * The iterator created by this method gives users the option to cancel the destruction\n             * of the stream if the `for await...of` loop is exited by `return`, `break`, or `throw`,\n             * or if the iterator should destroy the stream if the stream emitted an error during iteration.\n             * @since v16.3.0\n             * @param options.destroyOnReturn When set to `false`, calling `return` on the async iterator,\n             * or exiting a `for await...of` iteration using a `break`, `return`, or `throw` will not destroy the stream.\n             * **Default: `true`**.\n             */\n            iterator(options?: { destroyOnReturn?: boolean }): NodeJS.AsyncIterator<any>;\n            /**\n             * This method allows mapping over the stream. The *fn* function will be called for every chunk in the stream.\n             * If the *fn* function returns a promise - that promise will be `await`ed before being passed to the result stream.\n             * @since v17.4.0, v16.14.0\n             * @param fn a function to map over every chunk in the stream. Async or not.\n             * @returns a stream mapped with the function *fn*.\n             */\n            map(fn: (data: any, options?: Pick<ArrayOptions, \"signal\">) => any, options?: ArrayOptions): Readable;\n            /**\n             * This method allows filtering the stream. For each chunk in the stream the *fn* function will be called\n             * and if it returns a truthy value, the chunk will be passed to the result stream.\n             * If the *fn* function returns a promise - that promise will be `await`ed.\n             * @since v17.4.0, v16.14.0\n             * @param fn a function to filter chunks from the stream. Async or not.\n             * @returns a stream filtered with the predicate *fn*.\n             */\n            filter(\n                fn: (data: any, options?: Pick<ArrayOptions, \"signal\">) => boolean | Promise<boolean>,\n                options?: ArrayOptions,\n            ): Readable;\n            /**\n             * This method allows iterating a stream. For each chunk in the stream the *fn* function will be called.\n             * If the *fn* function returns a promise - that promise will be `await`ed.\n             *\n             * This method is different from `for await...of` loops in that it can optionally process chunks concurrently.\n             * In addition, a `forEach` iteration can only be stopped by having passed a `signal` option\n             * and aborting the related AbortController while `for await...of` can be stopped with `break` or `return`.\n             * In either case the stream will be destroyed.\n             *\n             * This method is different from listening to the `'data'` event in that it uses the `readable` event\n             * in the underlying machinary and can limit the number of concurrent *fn* calls.\n             * @since v17.5.0\n             * @param fn a function to call on each chunk of the stream. Async or not.\n             * @returns a promise for when the stream has finished.\n             */\n            forEach(\n                fn: (data: any, options?: Pick<ArrayOptions, \"signal\">) => void | Promise<void>,\n                options?: ArrayOptions,\n            ): Promise<void>;\n            /**\n             * This method allows easily obtaining the contents of a stream.\n             *\n             * As this method reads the entire stream into memory, it negates the benefits of streams. It's intended\n             * for interoperability and convenience, not as the primary way to consume streams.\n             * @since v17.5.0\n             * @returns a promise containing an array with the contents of the stream.\n             */\n            toArray(options?: Pick<ArrayOptions, \"signal\">): Promise<any[]>;\n            /**\n             * This method is similar to `Array.prototype.some` and calls *fn* on each chunk in the stream\n             * until the awaited return value is `true` (or any truthy value). Once an *fn* call on a chunk\n             * `await`ed return value is truthy, the stream is destroyed and the promise is fulfilled with `true`.\n             * If none of the *fn* calls on the chunks return a truthy value, the promise is fulfilled with `false`.\n             * @since v17.5.0\n             * @param fn a function to call on each chunk of the stream. Async or not.\n             * @returns a promise evaluating to `true` if *fn* returned a truthy value for at least one of the chunks.\n             */\n            some(\n                fn: (data: any, options?: Pick<ArrayOptions, \"signal\">) => boolean | Promise<boolean>,\n                options?: ArrayOptions,\n            ): Promise<boolean>;\n            /**\n             * This method is similar to `Array.prototype.find` and calls *fn* on each chunk in the stream\n             * to find a chunk with a truthy value for *fn*. Once an *fn* call's awaited return value is truthy,\n             * the stream is destroyed and the promise is fulfilled with value for which *fn* returned a truthy value.\n             * If all of the *fn* calls on the chunks return a falsy value, the promise is fulfilled with `undefined`.\n             * @since v17.5.0\n             * @param fn a function to call on each chunk of the stream. Async or not.\n             * @returns a promise evaluating to the first chunk for which *fn* evaluated with a truthy value,\n             * or `undefined` if no element was found.\n             */\n            find<T>(\n                fn: (data: any, options?: Pick<ArrayOptions, \"signal\">) => data is T,\n                options?: ArrayOptions,\n            ): Promise<T | undefined>;\n            find(\n                fn: (data: any, options?: Pick<ArrayOptions, \"signal\">) => boolean | Promise<boolean>,\n                options?: ArrayOptions,\n            ): Promise<any>;\n            /**\n             * This method is similar to `Array.prototype.every` and calls *fn* on each chunk in the stream\n             * to check if all awaited return values are truthy value for *fn*. Once an *fn* call on a chunk\n             * `await`ed return value is falsy, the stream is destroyed and the promise is fulfilled with `false`.\n             * If all of the *fn* calls on the chunks return a truthy value, the promise is fulfilled with `true`.\n             * @since v17.5.0\n             * @param fn a function to call on each chunk of the stream. Async or not.\n             * @returns a promise evaluating to `true` if *fn* returned a truthy value for every one of the chunks.\n             */\n            every(\n                fn: (data: any, options?: Pick<ArrayOptions, \"signal\">) => boolean | Promise<boolean>,\n                options?: ArrayOptions,\n            ): Promise<boolean>;\n            /**\n             * This method returns a new stream by applying the given callback to each chunk of the stream\n             * and then flattening the result.\n             *\n             * It is possible to return a stream or another iterable or async iterable from *fn* and the result streams\n             * will be merged (flattened) into the returned stream.\n             * @since v17.5.0\n             * @param fn a function to map over every chunk in the stream. May be async. May be a stream or generator.\n             * @returns a stream flat-mapped with the function *fn*.\n             */\n            flatMap(fn: (data: any, options?: Pick<ArrayOptions, \"signal\">) => any, options?: ArrayOptions): Readable;\n            /**\n             * This method returns a new stream with the first *limit* chunks dropped from the start.\n             * @since v17.5.0\n             * @param limit the number of chunks to drop from the readable.\n             * @returns a stream with *limit* chunks dropped from the start.\n             */\n            drop(limit: number, options?: Pick<ArrayOptions, \"signal\">): Readable;\n            /**\n             * This method returns a new stream with the first *limit* chunks.\n             * @since v17.5.0\n             * @param limit the number of chunks to take from the readable.\n             * @returns a stream with *limit* chunks taken.\n             */\n            take(limit: number, options?: Pick<ArrayOptions, \"signal\">): Readable;\n            /**\n             * This method returns a new stream with chunks of the underlying stream paired with a counter\n             * in the form `[index, chunk]`. The first index value is `0` and it increases by 1 for each chunk produced.\n             * @since v17.5.0\n             * @returns a stream of indexed pairs.\n             */\n            asIndexedPairs(options?: Pick<ArrayOptions, \"signal\">): Readable;\n            /**\n             * This method calls *fn* on each chunk of the stream in order, passing it the result from the calculation\n             * on the previous element. It returns a promise for the final value of the reduction.\n             *\n             * If no *initial* value is supplied the first chunk of the stream is used as the initial value.\n             * If the stream is empty, the promise is rejected with a `TypeError` with the `ERR_INVALID_ARGS` code property.\n             *\n             * The reducer function iterates the stream element-by-element which means that there is no *concurrency* parameter\n             * or parallelism. To perform a reduce concurrently, you can extract the async function to `readable.map` method.\n             * @since v17.5.0\n             * @param fn a reducer function to call over every chunk in the stream. Async or not.\n             * @param initial the initial value to use in the reduction.\n             * @returns a promise for the final value of the reduction.\n             */\n            reduce<T = any>(\n                fn: (previous: any, data: any, options?: Pick<ArrayOptions, \"signal\">) => T,\n                initial?: undefined,\n                options?: Pick<ArrayOptions, \"signal\">,\n            ): Promise<T>;\n            reduce<T = any>(\n                fn: (previous: T, data: any, options?: Pick<ArrayOptions, \"signal\">) => T,\n                initial: T,\n                options?: Pick<ArrayOptions, \"signal\">,\n            ): Promise<T>;\n            _destroy(error: Error | null, callback: (error?: Error | null) => void): void;\n            /**\n             * Destroy the stream. Optionally emit an `'error'` event, and emit a `'close'` event (unless `emitClose` is set to `false`). After this call, the readable\n             * stream will release any internal resources and subsequent calls to `push()` will be ignored.\n             *\n             * Once `destroy()` has been called any further calls will be a no-op and no\n             * further errors except from `_destroy()` may be emitted as `'error'`.\n             *\n             * Implementors should not override this method, but instead implement `readable._destroy()`.\n             * @since v8.0.0\n             * @param error Error which will be passed as payload in `'error'` event\n             */\n            destroy(error?: Error): this;\n            /**\n             * Event emitter\n             * The defined events on documents including:\n             * 1. close\n             * 2. data\n             * 3. end\n             * 4. error\n             * 5. pause\n             * 6. readable\n             * 7. resume\n             */\n            addListener(event: \"close\", listener: () => void): this;\n            addListener(event: \"data\", listener: (chunk: any) => void): this;\n            addListener(event: \"end\", listener: () => void): this;\n            addListener(event: \"error\", listener: (err: Error) => void): this;\n            addListener(event: \"pause\", listener: () => void): this;\n            addListener(event: \"readable\", listener: () => void): this;\n            addListener(event: \"resume\", listener: () => void): this;\n            addListener(event: string | symbol, listener: (...args: any[]) => void): this;\n            emit(event: \"close\"): boolean;\n            emit(event: \"data\", chunk: any): boolean;\n            emit(event: \"end\"): boolean;\n            emit(event: \"error\", err: Error): boolean;\n            emit(event: \"pause\"): boolean;\n            emit(event: \"readable\"): boolean;\n            emit(event: \"resume\"): boolean;\n            emit(event: string | symbol, ...args: any[]): boolean;\n            on(event: \"close\", listener: () => void): this;\n            on(event: \"data\", listener: (chunk: any) => void): this;\n            on(event: \"end\", listener: () => void): this;\n            on(event: \"error\", listener: (err: Error) => void): this;\n            on(event: \"pause\", listener: () => void): this;\n            on(event: \"readable\", listener: () => void): this;\n            on(event: \"resume\", listener: () => void): this;\n            on(event: string | symbol, listener: (...args: any[]) => void): this;\n            once(event: \"close\", listener: () => void): this;\n            once(event: \"data\", listener: (chunk: any) => void): this;\n            once(event: \"end\", listener: () => void): this;\n            once(event: \"error\", listener: (err: Error) => void): this;\n            once(event: \"pause\", listener: () => void): this;\n            once(event: \"readable\", listener: () => void): this;\n            once(event: \"resume\", listener: () => void): this;\n            once(event: string | symbol, listener: (...args: any[]) => void): this;\n            prependListener(event: \"close\", listener: () => void): this;\n            prependListener(event: \"data\", listener: (chunk: any) => void): this;\n            prependListener(event: \"end\", listener: () => void): this;\n            prependListener(event: \"error\", listener: (err: Error) => void): this;\n            prependListener(event: \"pause\", listener: () => void): this;\n            prependListener(event: \"readable\", listener: () => void): this;\n            prependListener(event: \"resume\", listener: () => void): this;\n            prependListener(event: string | symbol, listener: (...args: any[]) => void): this;\n            prependOnceListener(event: \"close\", listener: () => void): this;\n            prependOnceListener(event: \"data\", listener: (chunk: any) => void): this;\n            prependOnceListener(event: \"end\", listener: () => void): this;\n            prependOnceListener(event: \"error\", listener: (err: Error) => void): this;\n            prependOnceListener(event: \"pause\", listener: () => void): this;\n            prependOnceListener(event: \"readable\", listener: () => void): this;\n            prependOnceListener(event: \"resume\", listener: () => void): this;\n            prependOnceListener(event: string | symbol, listener: (...args: any[]) => void): this;\n            removeListener(event: \"close\", listener: () => void): this;\n            removeListener(event: \"data\", listener: (chunk: any) => void): this;\n            removeListener(event: \"end\", listener: () => void): this;\n            removeListener(event: \"error\", listener: (err: Error) => void): this;\n            removeListener(event: \"pause\", listener: () => void): this;\n            removeListener(event: \"readable\", listener: () => void): this;\n            removeListener(event: \"resume\", listener: () => void): this;\n            removeListener(event: string | symbol, listener: (...args: any[]) => void): this;\n            [Symbol.asyncIterator](): NodeJS.AsyncIterator<any>;\n            /**\n             * Calls `readable.destroy()` with an `AbortError` and returns a promise that fulfills when the stream is finished.\n             * @since v20.4.0\n             */\n            [Symbol.asyncDispose](): Promise<void>;\n        }\n        interface WritableOptions<T extends Writable = Writable> extends StreamOptions<T> {\n            decodeStrings?: boolean | undefined;\n            defaultEncoding?: BufferEncoding | undefined;\n            write?(\n                this: T,\n                chunk: any,\n                encoding: BufferEncoding,\n                callback: (error?: Error | null) => void,\n            ): void;\n            writev?(\n                this: T,\n                chunks: Array<{\n                    chunk: any;\n                    encoding: BufferEncoding;\n                }>,\n                callback: (error?: Error | null) => void,\n            ): void;\n            final?(this: T, callback: (error?: Error | null) => void): void;\n        }\n        /**\n         * @since v0.9.4\n         */\n        class Writable extends Stream implements NodeJS.WritableStream {\n            /**\n             * A utility method for creating a `Writable` from a web `WritableStream`.\n             * @since v17.0.0\n             * @experimental\n             */\n            static fromWeb(\n                writableStream: streamWeb.WritableStream,\n                options?: Pick<WritableOptions, \"decodeStrings\" | \"highWaterMark\" | \"objectMode\" | \"signal\">,\n            ): Writable;\n            /**\n             * A utility method for creating a web `WritableStream` from a `Writable`.\n             * @since v17.0.0\n             * @experimental\n             */\n            static toWeb(streamWritable: Writable): streamWeb.WritableStream;\n            /**\n             * Is `true` if it is safe to call `writable.write()`, which means\n             * the stream has not been destroyed, errored, or ended.\n             * @since v11.4.0\n             */\n            readonly writable: boolean;\n            /**\n             * Is `true` after `writable.end()` has been called. This property\n             * does not indicate whether the data has been flushed, for this use `writable.writableFinished` instead.\n             * @since v12.9.0\n             */\n            readonly writableEnded: boolean;\n            /**\n             * Is set to `true` immediately before the `'finish'` event is emitted.\n             * @since v12.6.0\n             */\n            readonly writableFinished: boolean;\n            /**\n             * Return the value of `highWaterMark` passed when creating this `Writable`.\n             * @since v9.3.0\n             */\n            readonly writableHighWaterMark: number;\n            /**\n             * This property contains the number of bytes (or objects) in the queue\n             * ready to be written. The value provides introspection data regarding\n             * the status of the `highWaterMark`.\n             * @since v9.4.0\n             */\n            readonly writableLength: number;\n            /**\n             * Getter for the property `objectMode` of a given `Writable` stream.\n             * @since v12.3.0\n             */\n            readonly writableObjectMode: boolean;\n            /**\n             * Number of times `writable.uncork()` needs to be\n             * called in order to fully uncork the stream.\n             * @since v13.2.0, v12.16.0\n             */\n            readonly writableCorked: number;\n            /**\n             * Is `true` after `writable.destroy()` has been called.\n             * @since v8.0.0\n             */\n            destroyed: boolean;\n            /**\n             * Is `true` after `'close'` has been emitted.\n             * @since v18.0.0\n             */\n            readonly closed: boolean;\n            /**\n             * Returns error if the stream has been destroyed with an error.\n             * @since v18.0.0\n             */\n            readonly errored: Error | null;\n            /**\n             * Is `true` if the stream's buffer has been full and stream will emit `'drain'`.\n             * @since v15.2.0, v14.17.0\n             */\n            readonly writableNeedDrain: boolean;\n            constructor(opts?: WritableOptions);\n            _write(chunk: any, encoding: BufferEncoding, callback: (error?: Error | null) => void): void;\n            _writev?(\n                chunks: Array<{\n                    chunk: any;\n                    encoding: BufferEncoding;\n                }>,\n                callback: (error?: Error | null) => void,\n            ): void;\n            _construct?(callback: (error?: Error | null) => void): void;\n            _destroy(error: Error | null, callback: (error?: Error | null) => void): void;\n            _final(callback: (error?: Error | null) => void): void;\n            /**\n             * The `writable.write()` method writes some data to the stream, and calls the\n             * supplied `callback` once the data has been fully handled. If an error\n             * occurs, the `callback` will be called with the error as its\n             * first argument. The `callback` is called asynchronously and before `'error'` is\n             * emitted.\n             *\n             * The return value is `true` if the internal buffer is less than the `highWaterMark` configured when the stream was created after admitting `chunk`.\n             * If `false` is returned, further attempts to write data to the stream should\n             * stop until the `'drain'` event is emitted.\n             *\n             * While a stream is not draining, calls to `write()` will buffer `chunk`, and\n             * return false. Once all currently buffered chunks are drained (accepted for\n             * delivery by the operating system), the `'drain'` event will be emitted.\n             * Once `write()` returns false, do not write more chunks\n             * until the `'drain'` event is emitted. While calling `write()` on a stream that\n             * is not draining is allowed, Node.js will buffer all written chunks until\n             * maximum memory usage occurs, at which point it will abort unconditionally.\n             * Even before it aborts, high memory usage will cause poor garbage collector\n             * performance and high RSS (which is not typically released back to the system,\n             * even after the memory is no longer required). Since TCP sockets may never\n             * drain if the remote peer does not read the data, writing a socket that is\n             * not draining may lead to a remotely exploitable vulnerability.\n             *\n             * Writing data while the stream is not draining is particularly\n             * problematic for a `Transform`, because the `Transform` streams are paused\n             * by default until they are piped or a `'data'` or `'readable'` event handler\n             * is added.\n             *\n             * If the data to be written can be generated or fetched on demand, it is\n             * recommended to encapsulate the logic into a `Readable` and use {@link pipe}. However, if calling `write()` is preferred, it is\n             * possible to respect backpressure and avoid memory issues using the `'drain'` event:\n             *\n             * ```js\n             * function write(data, cb) {\n             *   if (!stream.write(data)) {\n             *     stream.once('drain', cb);\n             *   } else {\n             *     process.nextTick(cb);\n             *   }\n             * }\n             *\n             * // Wait for cb to be called before doing any other write.\n             * write('hello', () => {\n             *   console.log('Write completed, do more writes now.');\n             * });\n             * ```\n             *\n             * A `Writable` stream in object mode will always ignore the `encoding` argument.\n             * @since v0.9.4\n             * @param chunk Optional data to write. For streams not operating in object mode, `chunk` must be a {string}, {Buffer},\n             * {TypedArray} or {DataView}. For object mode streams, `chunk` may be any JavaScript value other than `null`.\n             * @param [encoding='utf8'] The encoding, if `chunk` is a string.\n             * @param callback Callback for when this chunk of data is flushed.\n             * @return `false` if the stream wishes for the calling code to wait for the `'drain'` event to be emitted before continuing to write additional data; otherwise `true`.\n             */\n            write(chunk: any, callback?: (error: Error | null | undefined) => void): boolean;\n            write(chunk: any, encoding: BufferEncoding, callback?: (error: Error | null | undefined) => void): boolean;\n            /**\n             * The `writable.setDefaultEncoding()` method sets the default `encoding` for a `Writable` stream.\n             * @since v0.11.15\n             * @param encoding The new default encoding\n             */\n            setDefaultEncoding(encoding: BufferEncoding): this;\n            /**\n             * Calling the `writable.end()` method signals that no more data will be written\n             * to the `Writable`. The optional `chunk` and `encoding` arguments allow one\n             * final additional chunk of data to be written immediately before closing the\n             * stream.\n             *\n             * Calling the {@link write} method after calling {@link end} will raise an error.\n             *\n             * ```js\n             * // Write 'hello, ' and then end with 'world!'.\n             * import fs from 'node:fs';\n             * const file = fs.createWriteStream('example.txt');\n             * file.write('hello, ');\n             * file.end('world!');\n             * // Writing more now is not allowed!\n             * ```\n             * @since v0.9.4\n             * @param chunk Optional data to write. For streams not operating in object mode, `chunk` must be a {string}, {Buffer},\n             * {TypedArray} or {DataView}. For object mode streams, `chunk` may be any JavaScript value other than `null`.\n             * @param encoding The encoding if `chunk` is a string\n             * @param callback Callback for when the stream is finished.\n             */\n            end(cb?: () => void): this;\n            end(chunk: any, cb?: () => void): this;\n            end(chunk: any, encoding: BufferEncoding, cb?: () => void): this;\n            /**\n             * The `writable.cork()` method forces all written data to be buffered in memory.\n             * The buffered data will be flushed when either the {@link uncork} or {@link end} methods are called.\n             *\n             * The primary intent of `writable.cork()` is to accommodate a situation in which\n             * several small chunks are written to the stream in rapid succession. Instead of\n             * immediately forwarding them to the underlying destination, `writable.cork()` buffers all the chunks until `writable.uncork()` is called, which will pass them\n             * all to `writable._writev()`, if present. This prevents a head-of-line blocking\n             * situation where data is being buffered while waiting for the first small chunk\n             * to be processed. However, use of `writable.cork()` without implementing `writable._writev()` may have an adverse effect on throughput.\n             *\n             * See also: `writable.uncork()`, `writable._writev()`.\n             * @since v0.11.2\n             */\n            cork(): void;\n            /**\n             * The `writable.uncork()` method flushes all data buffered since {@link cork} was called.\n             *\n             * When using `writable.cork()` and `writable.uncork()` to manage the buffering\n             * of writes to a stream, defer calls to `writable.uncork()` using `process.nextTick()`. Doing so allows batching of all `writable.write()` calls that occur within a given Node.js event\n             * loop phase.\n             *\n             * ```js\n             * stream.cork();\n             * stream.write('some ');\n             * stream.write('data ');\n             * process.nextTick(() => stream.uncork());\n             * ```\n             *\n             * If the `writable.cork()` method is called multiple times on a stream, the\n             * same number of calls to `writable.uncork()` must be called to flush the buffered\n             * data.\n             *\n             * ```js\n             * stream.cork();\n             * stream.write('some ');\n             * stream.cork();\n             * stream.write('data ');\n             * process.nextTick(() => {\n             *   stream.uncork();\n             *   // The data will not be flushed until uncork() is called a second time.\n             *   stream.uncork();\n             * });\n             * ```\n             *\n             * See also: `writable.cork()`.\n             * @since v0.11.2\n             */\n            uncork(): void;\n            /**\n             * Destroy the stream. Optionally emit an `'error'` event, and emit a `'close'` event (unless `emitClose` is set to `false`). After this call, the writable\n             * stream has ended and subsequent calls to `write()` or `end()` will result in\n             * an `ERR_STREAM_DESTROYED` error.\n             * This is a destructive and immediate way to destroy a stream. Previous calls to `write()` may not have drained, and may trigger an `ERR_STREAM_DESTROYED` error.\n             * Use `end()` instead of destroy if data should flush before close, or wait for\n             * the `'drain'` event before destroying the stream.\n             *\n             * Once `destroy()` has been called any further calls will be a no-op and no\n             * further errors except from `_destroy()` may be emitted as `'error'`.\n             *\n             * Implementors should not override this method,\n             * but instead implement `writable._destroy()`.\n             * @since v8.0.0\n             * @param error Optional, an error to emit with `'error'` event.\n             */\n            destroy(error?: Error): this;\n            /**\n             * Event emitter\n             * The defined events on documents including:\n             * 1. close\n             * 2. drain\n             * 3. error\n             * 4. finish\n             * 5. pipe\n             * 6. unpipe\n             */\n            addListener(event: \"close\", listener: () => void): this;\n            addListener(event: \"drain\", listener: () => void): this;\n            addListener(event: \"error\", listener: (err: Error) => void): this;\n            addListener(event: \"finish\", listener: () => void): this;\n            addListener(event: \"pipe\", listener: (src: Readable) => void): this;\n            addListener(event: \"unpipe\", listener: (src: Readable) => void): this;\n            addListener(event: string | symbol, listener: (...args: any[]) => void): this;\n            emit(event: \"close\"): boolean;\n            emit(event: \"drain\"): boolean;\n            emit(event: \"error\", err: Error): boolean;\n            emit(event: \"finish\"): boolean;\n            emit(event: \"pipe\", src: Readable): boolean;\n            emit(event: \"unpipe\", src: Readable): boolean;\n            emit(event: string | symbol, ...args: any[]): boolean;\n            on(event: \"close\", listener: () => void): this;\n            on(event: \"drain\", listener: () => void): this;\n            on(event: \"error\", listener: (err: Error) => void): this;\n            on(event: \"finish\", listener: () => void): this;\n            on(event: \"pipe\", listener: (src: Readable) => void): this;\n            on(event: \"unpipe\", listener: (src: Readable) => void): this;\n            on(event: string | symbol, listener: (...args: any[]) => void): this;\n            once(event: \"close\", listener: () => void): this;\n            once(event: \"drain\", listener: () => void): this;\n            once(event: \"error\", listener: (err: Error) => void): this;\n            once(event: \"finish\", listener: () => void): this;\n            once(event: \"pipe\", listener: (src: Readable) => void): this;\n            once(event: \"unpipe\", listener: (src: Readable) => void): this;\n            once(event: string | symbol, listener: (...args: any[]) => void): this;\n            prependListener(event: \"close\", listener: () => void): this;\n            prependListener(event: \"drain\", listener: () => void): this;\n            prependListener(event: \"error\", listener: (err: Error) => void): this;\n            prependListener(event: \"finish\", listener: () => void): this;\n            prependListener(event: \"pipe\", listener: (src: Readable) => void): this;\n            prependListener(event: \"unpipe\", listener: (src: Readable) => void): this;\n            prependListener(event: string | symbol, listener: (...args: any[]) => void): this;\n            prependOnceListener(event: \"close\", listener: () => void): this;\n            prependOnceListener(event: \"drain\", listener: () => void): this;\n            prependOnceListener(event: \"error\", listener: (err: Error) => void): this;\n            prependOnceListener(event: \"finish\", listener: () => void): this;\n            prependOnceListener(event: \"pipe\", listener: (src: Readable) => void): this;\n            prependOnceListener(event: \"unpipe\", listener: (src: Readable) => void): this;\n            prependOnceListener(event: string | symbol, listener: (...args: any[]) => void): this;\n            removeListener(event: \"close\", listener: () => void): this;\n            removeListener(event: \"drain\", listener: () => void): this;\n            removeListener(event: \"error\", listener: (err: Error) => void): this;\n            removeListener(event: \"finish\", listener: () => void): this;\n            removeListener(event: \"pipe\", listener: (src: Readable) => void): this;\n            removeListener(event: \"unpipe\", listener: (src: Readable) => void): this;\n            removeListener(event: string | symbol, listener: (...args: any[]) => void): this;\n        }\n        interface DuplexOptions<T extends Duplex = Duplex> extends ReadableOptions<T>, WritableOptions<T> {\n            allowHalfOpen?: boolean | undefined;\n            readableObjectMode?: boolean | undefined;\n            writableObjectMode?: boolean | undefined;\n            readableHighWaterMark?: number | undefined;\n            writableHighWaterMark?: number | undefined;\n            writableCorked?: number | undefined;\n        }\n        /**\n         * Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.\n         *\n         * Examples of `Duplex` streams include:\n         *\n         * * `TCP sockets`\n         * * `zlib streams`\n         * * `crypto streams`\n         * @since v0.9.4\n         */\n        class Duplex extends Stream implements NodeJS.ReadWriteStream {\n            /**\n             * If `false` then the stream will automatically end the writable side when the\n             * readable side ends. Set initially by the `allowHalfOpen` constructor option,\n             * which defaults to `true`.\n             *\n             * This can be changed manually to change the half-open behavior of an existing\n             * `Duplex` stream instance, but must be changed before the `'end'` event is emitted.\n             * @since v0.9.4\n             */\n            allowHalfOpen: boolean;\n            constructor(opts?: DuplexOptions);\n            /**\n             * A utility method for creating duplex streams.\n             *\n             * - `Stream` converts writable stream into writable `Duplex` and readable stream\n             *   to `Duplex`.\n             * - `Blob` converts into readable `Duplex`.\n             * - `string` converts into readable `Duplex`.\n             * - `ArrayBuffer` converts into readable `Duplex`.\n             * - `AsyncIterable` converts into a readable `Duplex`. Cannot yield `null`.\n             * - `AsyncGeneratorFunction` converts into a readable/writable transform\n             *   `Duplex`. Must take a source `AsyncIterable` as first parameter. Cannot yield\n             *   `null`.\n             * - `AsyncFunction` converts into a writable `Duplex`. Must return\n             *   either `null` or `undefined`\n             * - `Object ({ writable, readable })` converts `readable` and\n             *   `writable` into `Stream` and then combines them into `Duplex` where the\n             *   `Duplex` will write to the `writable` and read from the `readable`.\n             * - `Promise` converts into readable `Duplex`. Value `null` is ignored.\n             *\n             * @since v16.8.0\n             */\n            static from(\n                src:\n                    | Stream\n                    | NodeBlob\n                    | ArrayBuffer\n                    | string\n                    | Iterable<any>\n                    | AsyncIterable<any>\n                    | AsyncGeneratorFunction\n                    | Promise<any>\n                    | Object,\n            ): Duplex;\n            /**\n             * A utility method for creating a web `ReadableStream` and `WritableStream` from a `Duplex`.\n             * @since v17.0.0\n             * @experimental\n             */\n            static toWeb(streamDuplex: Duplex): {\n                readable: streamWeb.ReadableStream;\n                writable: streamWeb.WritableStream;\n            };\n            /**\n             * A utility method for creating a `Duplex` from a web `ReadableStream` and `WritableStream`.\n             * @since v17.0.0\n             * @experimental\n             */\n            static fromWeb(\n                duplexStream: {\n                    readable: streamWeb.ReadableStream;\n                    writable: streamWeb.WritableStream;\n                },\n                options?: Pick<\n                    DuplexOptions,\n                    \"allowHalfOpen\" | \"decodeStrings\" | \"encoding\" | \"highWaterMark\" | \"objectMode\" | \"signal\"\n                >,\n            ): Duplex;\n            /**\n             * Event emitter\n             * The defined events on documents including:\n             * 1.  close\n             * 2.  data\n             * 3.  drain\n             * 4.  end\n             * 5.  error\n             * 6.  finish\n             * 7.  pause\n             * 8.  pipe\n             * 9.  readable\n             * 10. resume\n             * 11. unpipe\n             */\n            addListener(event: \"close\", listener: () => void): this;\n            addListener(event: \"data\", listener: (chunk: any) => void): this;\n            addListener(event: \"drain\", listener: () => void): this;\n            addListener(event: \"end\", listener: () => void): this;\n            addListener(event: \"error\", listener: (err: Error) => void): this;\n            addListener(event: \"finish\", listener: () => void): this;\n            addListener(event: \"pause\", listener: () => void): this;\n            addListener(event: \"pipe\", listener: (src: Readable) => void): this;\n            addListener(event: \"readable\", listener: () => void): this;\n            addListener(event: \"resume\", listener: () => void): this;\n            addListener(event: \"unpipe\", listener: (src: Readable) => void): this;\n            addListener(event: string | symbol, listener: (...args: any[]) => void): this;\n            emit(event: \"close\"): boolean;\n            emit(event: \"data\", chunk: any): boolean;\n            emit(event: \"drain\"): boolean;\n            emit(event: \"end\"): boolean;\n            emit(event: \"error\", err: Error): boolean;\n            emit(event: \"finish\"): boolean;\n            emit(event: \"pause\"): boolean;\n            emit(event: \"pipe\", src: Readable): boolean;\n            emit(event: \"readable\"): boolean;\n            emit(event: \"resume\"): boolean;\n            emit(event: \"unpipe\", src: Readable): boolean;\n            emit(event: string | symbol, ...args: any[]): boolean;\n            on(event: \"close\", listener: () => void): this;\n            on(event: \"data\", listener: (chunk: any) => void): this;\n            on(event: \"drain\", listener: () => void): this;\n            on(event: \"end\", listener: () => void): this;\n            on(event: \"error\", listener: (err: Error) => void): this;\n            on(event: \"finish\", listener: () => void): this;\n            on(event: \"pause\", listener: () => void): this;\n            on(event: \"pipe\", listener: (src: Readable) => void): this;\n            on(event: \"readable\", listener: () => void): this;\n            on(event: \"resume\", listener: () => void): this;\n            on(event: \"unpipe\", listener: (src: Readable) => void): this;\n            on(event: string | symbol, listener: (...args: any[]) => void): this;\n            once(event: \"close\", listener: () => void): this;\n            once(event: \"data\", listener: (chunk: any) => void): this;\n            once(event: \"drain\", listener: () => void): this;\n            once(event: \"end\", listener: () => void): this;\n            once(event: \"error\", listener: (err: Error) => void): this;\n            once(event: \"finish\", listener: () => void): this;\n            once(event: \"pause\", listener: () => void): this;\n            once(event: \"pipe\", listener: (src: Readable) => void): this;\n            once(event: \"readable\", listener: () => void): this;\n            once(event: \"resume\", listener: () => void): this;\n            once(event: \"unpipe\", listener: (src: Readable) => void): this;\n            once(event: string | symbol, listener: (...args: any[]) => void): this;\n            prependListener(event: \"close\", listener: () => void): this;\n            prependListener(event: \"data\", listener: (chunk: any) => void): this;\n            prependListener(event: \"drain\", listener: () => void): this;\n            prependListener(event: \"end\", listener: () => void): this;\n            prependListener(event: \"error\", listener: (err: Error) => void): this;\n            prependListener(event: \"finish\", listener: () => void): this;\n            prependListener(event: \"pause\", listener: () => void): this;\n            prependListener(event: \"pipe\", listener: (src: Readable) => void): this;\n            prependListener(event: \"readable\", listener: () => void): this;\n            prependListener(event: \"resume\", listener: () => void): this;\n            prependListener(event: \"unpipe\", listener: (src: Readable) => void): this;\n            prependListener(event: string | symbol, listener: (...args: any[]) => void): this;\n            prependOnceListener(event: \"close\", listener: () => void): this;\n            prependOnceListener(event: \"data\", listener: (chunk: any) => void): this;\n            prependOnceListener(event: \"drain\", listener: () => void): this;\n            prependOnceListener(event: \"end\", listener: () => void): this;\n            prependOnceListener(event: \"error\", listener: (err: Error) => void): this;\n            prependOnceListener(event: \"finish\", listener: () => void): this;\n            prependOnceListener(event: \"pause\", listener: () => void): this;\n            prependOnceListener(event: \"pipe\", listener: (src: Readable) => void): this;\n            prependOnceListener(event: \"readable\", listener: () => void): this;\n            prependOnceListener(event: \"resume\", listener: () => void): this;\n            prependOnceListener(event: \"unpipe\", listener: (src: Readable) => void): this;\n            prependOnceListener(event: string | symbol, listener: (...args: any[]) => void): this;\n            removeListener(event: \"close\", listener: () => void): this;\n            removeListener(event: \"data\", listener: (chunk: any) => void): this;\n            removeListener(event: \"drain\", listener: () => void): this;\n            removeListener(event: \"end\", listener: () => void): this;\n            removeListener(event: \"error\", listener: (err: Error) => void): this;\n            removeListener(event: \"finish\", listener: () => void): this;\n            removeListener(event: \"pause\", listener: () => void): this;\n            removeListener(event: \"pipe\", listener: (src: Readable) => void): this;\n            removeListener(event: \"readable\", listener: () => void): this;\n            removeListener(event: \"resume\", listener: () => void): this;\n            removeListener(event: \"unpipe\", listener: (src: Readable) => void): this;\n            removeListener(event: string | symbol, listener: (...args: any[]) => void): this;\n        }\n        interface Duplex extends Readable, Writable {}\n        /**\n         * The utility function `duplexPair` returns an Array with two items,\n         * each being a `Duplex` stream connected to the other side:\n         *\n         * ```js\n         * const [ sideA, sideB ] = duplexPair();\n         * ```\n         *\n         * Whatever is written to one stream is made readable on the other. It provides\n         * behavior analogous to a network connection, where the data written by the client\n         * becomes readable by the server, and vice-versa.\n         *\n         * The Duplex streams are symmetrical; one or the other may be used without any\n         * difference in behavior.\n         * @param options A value to pass to both {@link Duplex} constructors,\n         * to set options such as buffering.\n         * @since v22.6.0\n         */\n        function duplexPair(options?: DuplexOptions): [Duplex, Duplex];\n        type TransformCallback = (error?: Error | null, data?: any) => void;\n        interface TransformOptions<T extends Transform = Transform> extends DuplexOptions<T> {\n            transform?(this: T, chunk: any, encoding: BufferEncoding, callback: TransformCallback): void;\n            flush?(this: T, callback: TransformCallback): void;\n        }\n        /**\n         * Transform streams are `Duplex` streams where the output is in some way\n         * related to the input. Like all `Duplex` streams, `Transform` streams\n         * implement both the `Readable` and `Writable` interfaces.\n         *\n         * Examples of `Transform` streams include:\n         *\n         * * `zlib streams`\n         * * `crypto streams`\n         * @since v0.9.4\n         */\n        class Transform extends Duplex {\n            constructor(opts?: TransformOptions);\n            _transform(chunk: any, encoding: BufferEncoding, callback: TransformCallback): void;\n            _flush(callback: TransformCallback): void;\n        }\n        /**\n         * The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is\n         * primarily for examples and testing, but there are some use cases where `stream.PassThrough` is useful as a building block for novel sorts of streams.\n         */\n        class PassThrough extends Transform {}\n        /**\n         * A stream to attach a signal to.\n         *\n         * Attaches an AbortSignal to a readable or writeable stream. This lets code\n         * control stream destruction using an `AbortController`.\n         *\n         * Calling `abort` on the `AbortController` corresponding to the passed `AbortSignal` will behave the same way as calling `.destroy(new AbortError())` on the\n         * stream, and `controller.error(new AbortError())` for webstreams.\n         *\n         * ```js\n         * import fs from 'node:fs';\n         *\n         * const controller = new AbortController();\n         * const read = addAbortSignal(\n         *   controller.signal,\n         *   fs.createReadStream(('object.json')),\n         * );\n         * // Later, abort the operation closing the stream\n         * controller.abort();\n         * ```\n         *\n         * Or using an `AbortSignal` with a readable stream as an async iterable:\n         *\n         * ```js\n         * const controller = new AbortController();\n         * setTimeout(() => controller.abort(), 10_000); // set a timeout\n         * const stream = addAbortSignal(\n         *   controller.signal,\n         *   fs.createReadStream(('object.json')),\n         * );\n         * (async () => {\n         *   try {\n         *     for await (const chunk of stream) {\n         *       await process(chunk);\n         *     }\n         *   } catch (e) {\n         *     if (e.name === 'AbortError') {\n         *       // The operation was cancelled\n         *     } else {\n         *       throw e;\n         *     }\n         *   }\n         * })();\n         * ```\n         *\n         * Or using an `AbortSignal` with a ReadableStream:\n         *\n         * ```js\n         * const controller = new AbortController();\n         * const rs = new ReadableStream({\n         *   start(controller) {\n         *     controller.enqueue('hello');\n         *     controller.enqueue('world');\n         *     controller.close();\n         *   },\n         * });\n         *\n         * addAbortSignal(controller.signal, rs);\n         *\n         * finished(rs, (err) => {\n         *   if (err) {\n         *     if (err.name === 'AbortError') {\n         *       // The operation was cancelled\n         *     }\n         *   }\n         * });\n         *\n         * const reader = rs.getReader();\n         *\n         * reader.read().then(({ value, done }) => {\n         *   console.log(value); // hello\n         *   console.log(done); // false\n         *   controller.abort();\n         * });\n         * ```\n         * @since v15.4.0\n         * @param signal A signal representing possible cancellation\n         * @param stream A stream to attach a signal to.\n         */\n        function addAbortSignal<T extends Stream>(signal: AbortSignal, stream: T): T;\n        /**\n         * Returns the default highWaterMark used by streams.\n         * Defaults to `65536` (64 KiB), or `16` for `objectMode`.\n         * @since v19.9.0\n         */\n        function getDefaultHighWaterMark(objectMode: boolean): number;\n        /**\n         * Sets the default highWaterMark used by streams.\n         * @since v19.9.0\n         * @param value highWaterMark value\n         */\n        function setDefaultHighWaterMark(objectMode: boolean, value: number): void;\n        interface FinishedOptions extends Abortable {\n            error?: boolean | undefined;\n            readable?: boolean | undefined;\n            writable?: boolean | undefined;\n        }\n        /**\n         * A readable and/or writable stream/webstream.\n         *\n         * A function to get notified when a stream is no longer readable, writable\n         * or has experienced an error or a premature close event.\n         *\n         * ```js\n         * import { finished } from 'node:stream';\n         * import fs from 'node:fs';\n         *\n         * const rs = fs.createReadStream('archive.tar');\n         *\n         * finished(rs, (err) => {\n         *   if (err) {\n         *     console.error('Stream failed.', err);\n         *   } else {\n         *     console.log('Stream is done reading.');\n         *   }\n         * });\n         *\n         * rs.resume(); // Drain the stream.\n         * ```\n         *\n         * Especially useful in error handling scenarios where a stream is destroyed\n         * prematurely (like an aborted HTTP request), and will not emit `'end'` or `'finish'`.\n         *\n         * The `finished` API provides [`promise version`](https://nodejs.org/docs/latest-v22.x/api/stream.html#streamfinishedstream-options).\n         *\n         * `stream.finished()` leaves dangling event listeners (in particular `'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been\n         * invoked. The reason for this is so that unexpected `'error'` events (due to\n         * incorrect stream implementations) do not cause unexpected crashes.\n         * If this is unwanted behavior then the returned cleanup function needs to be\n         * invoked in the callback:\n         *\n         * ```js\n         * const cleanup = finished(rs, (err) => {\n         *   cleanup();\n         *   // ...\n         * });\n         * ```\n         * @since v10.0.0\n         * @param stream A readable and/or writable stream.\n         * @param callback A callback function that takes an optional error argument.\n         * @returns A cleanup function which removes all registered listeners.\n         */\n        function finished(\n            stream: NodeJS.ReadableStream | NodeJS.WritableStream | NodeJS.ReadWriteStream,\n            options: FinishedOptions,\n            callback: (err?: NodeJS.ErrnoException | null) => void,\n        ): () => void;\n        function finished(\n            stream: NodeJS.ReadableStream | NodeJS.WritableStream | NodeJS.ReadWriteStream,\n            callback: (err?: NodeJS.ErrnoException | null) => void,\n        ): () => void;\n        namespace finished {\n            function __promisify__(\n                stream: NodeJS.ReadableStream | NodeJS.WritableStream | NodeJS.ReadWriteStream,\n                options?: FinishedOptions,\n            ): Promise<void>;\n        }\n        type PipelineSourceFunction<T> = () => Iterable<T> | AsyncIterable<T>;\n        type PipelineSource<T> = Iterable<T> | AsyncIterable<T> | NodeJS.ReadableStream | PipelineSourceFunction<T>;\n        type PipelineTransform<S extends PipelineTransformSource<any>, U> =\n            | NodeJS.ReadWriteStream\n            | ((\n                source: S extends (...args: any[]) => Iterable<infer ST> | AsyncIterable<infer ST> ? AsyncIterable<ST>\n                    : S,\n            ) => AsyncIterable<U>);\n        type PipelineTransformSource<T> = PipelineSource<T> | PipelineTransform<any, T>;\n        type PipelineDestinationIterableFunction<T> = (source: AsyncIterable<T>) => AsyncIterable<any>;\n        type PipelineDestinationPromiseFunction<T, P> = (source: AsyncIterable<T>) => Promise<P>;\n        type PipelineDestination<S extends PipelineTransformSource<any>, P> = S extends\n            PipelineTransformSource<infer ST> ?\n                | NodeJS.WritableStream\n                | PipelineDestinationIterableFunction<ST>\n                | PipelineDestinationPromiseFunction<ST, P>\n            : never;\n        type PipelineCallback<S extends PipelineDestination<any, any>> = S extends\n            PipelineDestinationPromiseFunction<any, infer P> ? (err: NodeJS.ErrnoException | null, value: P) => void\n            : (err: NodeJS.ErrnoException | null) => void;\n        type PipelinePromise<S extends PipelineDestination<any, any>> = S extends\n            PipelineDestinationPromiseFunction<any, infer P> ? Promise<P> : Promise<void>;\n        interface PipelineOptions {\n            signal?: AbortSignal | undefined;\n            end?: boolean | undefined;\n        }\n        /**\n         * A module method to pipe between streams and generators forwarding errors and\n         * properly cleaning up and provide a callback when the pipeline is complete.\n         *\n         * ```js\n         * import { pipeline } from 'node:stream';\n         * import fs from 'node:fs';\n         * import zlib from 'node:zlib';\n         *\n         * // Use the pipeline API to easily pipe a series of streams\n         * // together and get notified when the pipeline is fully done.\n         *\n         * // A pipeline to gzip a potentially huge tar file efficiently:\n         *\n         * pipeline(\n         *   fs.createReadStream('archive.tar'),\n         *   zlib.createGzip(),\n         *   fs.createWriteStream('archive.tar.gz'),\n         *   (err) => {\n         *     if (err) {\n         *       console.error('Pipeline failed.', err);\n         *     } else {\n         *       console.log('Pipeline succeeded.');\n         *     }\n         *   },\n         * );\n         * ```\n         *\n         * The `pipeline` API provides a [`promise version`](https://nodejs.org/docs/latest-v22.x/api/stream.html#streampipelinesource-transforms-destination-options).\n         *\n         * `stream.pipeline()` will call `stream.destroy(err)` on all streams except:\n         *\n         * * `Readable` streams which have emitted `'end'` or `'close'`.\n         * * `Writable` streams which have emitted `'finish'` or `'close'`.\n         *\n         * `stream.pipeline()` leaves dangling event listeners on the streams\n         * after the `callback` has been invoked. In the case of reuse of streams after\n         * failure, this can cause event listener leaks and swallowed errors. If the last\n         * stream is readable, dangling event listeners will be removed so that the last\n         * stream can be consumed later.\n         *\n         * `stream.pipeline()` closes all the streams when an error is raised.\n         * The `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior\n         * once it would destroy the socket without sending the expected response.\n         * See the example below:\n         *\n         * ```js\n         * import fs from 'node:fs';\n         * import http from 'node:http';\n         * import { pipeline } from 'node:stream';\n         *\n         * const server = http.createServer((req, res) => {\n         *   const fileStream = fs.createReadStream('./fileNotExist.txt');\n         *   pipeline(fileStream, res, (err) => {\n         *     if (err) {\n         *       console.log(err); // No such file\n         *       // this message can't be sent once `pipeline` already destroyed the socket\n         *       return res.end('error!!!');\n         *     }\n         *   });\n         * });\n         * ```\n         * @since v10.0.0\n         * @param callback Called when the pipeline is fully done.\n         */\n        function pipeline<A extends PipelineSource<any>, B extends PipelineDestination<A, any>>(\n            source: A,\n            destination: B,\n            callback: PipelineCallback<B>,\n        ): B extends NodeJS.WritableStream ? B : NodeJS.WritableStream;\n        function pipeline<\n            A extends PipelineSource<any>,\n            T1 extends PipelineTransform<A, any>,\n            B extends PipelineDestination<T1, any>,\n        >(\n            source: A,\n            transform1: T1,\n            destination: B,\n            callback: PipelineCallback<B>,\n        ): B extends NodeJS.WritableStream ? B : NodeJS.WritableStream;\n        function pipeline<\n            A extends PipelineSource<any>,\n            T1 extends PipelineTransform<A, any>,\n            T2 extends PipelineTransform<T1, any>,\n            B extends PipelineDestination<T2, any>,\n        >(\n            source: A,\n            transform1: T1,\n            transform2: T2,\n            destination: B,\n            callback: PipelineCallback<B>,\n        ): B extends NodeJS.WritableStream ? B : NodeJS.WritableStream;\n        function pipeline<\n            A extends PipelineSource<any>,\n            T1 extends PipelineTransform<A, any>,\n            T2 extends PipelineTransform<T1, any>,\n            T3 extends PipelineTransform<T2, any>,\n            B extends PipelineDestination<T3, any>,\n        >(\n            source: A,\n            transform1: T1,\n            transform2: T2,\n            transform3: T3,\n            destination: B,\n            callback: PipelineCallback<B>,\n        ): B extends NodeJS.WritableStream ? B : NodeJS.WritableStream;\n        function pipeline<\n            A extends PipelineSource<any>,\n            T1 extends PipelineTransform<A, any>,\n            T2 extends PipelineTransform<T1, any>,\n            T3 extends PipelineTransform<T2, any>,\n            T4 extends PipelineTransform<T3, any>,\n            B extends PipelineDestination<T4, any>,\n        >(\n            source: A,\n            transform1: T1,\n            transform2: T2,\n            transform3: T3,\n            transform4: T4,\n            destination: B,\n            callback: PipelineCallback<B>,\n        ): B extends NodeJS.WritableStream ? B : NodeJS.WritableStream;\n        function pipeline(\n            streams: ReadonlyArray<NodeJS.ReadableStream | NodeJS.WritableStream | NodeJS.ReadWriteStream>,\n            callback: (err: NodeJS.ErrnoException | null) => void,\n        ): NodeJS.WritableStream;\n        function pipeline(\n            stream1: NodeJS.ReadableStream,\n            stream2: NodeJS.ReadWriteStream | NodeJS.WritableStream,\n            ...streams: Array<\n                NodeJS.ReadWriteStream | NodeJS.WritableStream | ((err: NodeJS.ErrnoException | null) => void)\n            >\n        ): NodeJS.WritableStream;\n        namespace pipeline {\n            function __promisify__<A extends PipelineSource<any>, B extends PipelineDestination<A, any>>(\n                source: A,\n                destination: B,\n                options?: PipelineOptions,\n            ): PipelinePromise<B>;\n            function __promisify__<\n                A extends PipelineSource<any>,\n                T1 extends PipelineTransform<A, any>,\n                B extends PipelineDestination<T1, any>,\n            >(\n                source: A,\n                transform1: T1,\n                destination: B,\n                options?: PipelineOptions,\n            ): PipelinePromise<B>;\n            function __promisify__<\n                A extends PipelineSource<any>,\n                T1 extends PipelineTransform<A, any>,\n                T2 extends PipelineTransform<T1, any>,\n                B extends PipelineDestination<T2, any>,\n            >(\n                source: A,\n                transform1: T1,\n                transform2: T2,\n                destination: B,\n                options?: PipelineOptions,\n            ): PipelinePromise<B>;\n            function __promisify__<\n                A extends PipelineSource<any>,\n                T1 extends PipelineTransform<A, any>,\n                T2 extends PipelineTransform<T1, any>,\n                T3 extends PipelineTransform<T2, any>,\n                B extends PipelineDestination<T3, any>,\n            >(\n                source: A,\n                transform1: T1,\n                transform2: T2,\n                transform3: T3,\n                destination: B,\n                options?: PipelineOptions,\n            ): PipelinePromise<B>;\n            function __promisify__<\n                A extends PipelineSource<any>,\n                T1 extends PipelineTransform<A, any>,\n                T2 extends PipelineTransform<T1, any>,\n                T3 extends PipelineTransform<T2, any>,\n                T4 extends PipelineTransform<T3, any>,\n                B extends PipelineDestination<T4, any>,\n            >(\n                source: A,\n                transform1: T1,\n                transform2: T2,\n                transform3: T3,\n                transform4: T4,\n                destination: B,\n                options?: PipelineOptions,\n            ): PipelinePromise<B>;\n            function __promisify__(\n                streams: ReadonlyArray<NodeJS.ReadableStream | NodeJS.WritableStream | NodeJS.ReadWriteStream>,\n                options?: PipelineOptions,\n            ): Promise<void>;\n            function __promisify__(\n                stream1: NodeJS.ReadableStream,\n                stream2: NodeJS.ReadWriteStream | NodeJS.WritableStream,\n                ...streams: Array<NodeJS.ReadWriteStream | NodeJS.WritableStream | PipelineOptions>\n            ): Promise<void>;\n        }\n        interface Pipe {\n            close(): void;\n            hasRef(): boolean;\n            ref(): void;\n            unref(): void;\n        }\n        /**\n         * Returns whether the stream has encountered an error.\n         * @since v17.3.0, v16.14.0\n         * @experimental\n         */\n        function isErrored(stream: Readable | Writable | NodeJS.ReadableStream | NodeJS.WritableStream): boolean;\n        /**\n         * Returns whether the stream is readable.\n         * @since v17.4.0, v16.14.0\n         * @experimental\n         */\n        function isReadable(stream: Readable | NodeJS.ReadableStream): boolean;\n    }\n    export = Stream;\n}\ndeclare module \"node:stream\" {\n    import stream = require(\"stream\");\n    export = stream;\n}\n"
        }
    ]
}