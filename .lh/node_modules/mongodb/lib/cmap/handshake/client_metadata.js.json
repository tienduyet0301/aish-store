{
    "sourceFile": "node_modules/mongodb/lib/cmap/handshake/client_metadata.js",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1746892618056,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1746891704042,
            "name": "cart",
            "content": "\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.LimitedSizeDocument = void 0;\nexports.makeClientMetadata = makeClientMetadata;\nexports.addContainerMetadata = addContainerMetadata;\nexports.getFAASEnv = getFAASEnv;\nconst os = require(\"os\");\nconst process = require(\"process\");\nconst bson_1 = require(\"../../bson\");\nconst error_1 = require(\"../../error\");\nconst utils_1 = require(\"../../utils\");\n// eslint-disable-next-line @typescript-eslint/no-require-imports\nconst NODE_DRIVER_VERSION = require('../../../package.json').version;\n/** @internal */\nclass LimitedSizeDocument {\n    constructor(maxSize) {\n        this.maxSize = maxSize;\n        this.document = new Map();\n        /** BSON overhead: Int32 + Null byte */\n        this.documentSize = 5;\n    }\n    /** Only adds key/value if the bsonByteLength is less than MAX_SIZE */\n    ifItFitsItSits(key, value) {\n        // The BSON byteLength of the new element is the same as serializing it to its own document\n        // subtracting the document size int32 and the null terminator.\n        const newElementSize = bson_1.BSON.serialize(new Map().set(key, value)).byteLength - 5;\n        if (newElementSize + this.documentSize > this.maxSize) {\n            return false;\n        }\n        this.documentSize += newElementSize;\n        this.document.set(key, value);\n        return true;\n    }\n    toObject() {\n        return bson_1.BSON.deserialize(bson_1.BSON.serialize(this.document), {\n            promoteLongs: false,\n            promoteBuffers: false,\n            promoteValues: false,\n            useBigInt64: false\n        });\n    }\n}\nexports.LimitedSizeDocument = LimitedSizeDocument;\n/**\n * From the specs:\n * Implementors SHOULD cumulatively update fields in the following order until the document is under the size limit:\n * 1. Omit fields from `env` except `env.name`.\n * 2. Omit fields from `os` except `os.type`.\n * 3. Omit the `env` document entirely.\n * 4. Truncate `platform`. -- special we do not truncate this field\n */\nfunction makeClientMetadata(options) {\n    const metadataDocument = new LimitedSizeDocument(512);\n    const { appName = '' } = options;\n    // Add app name first, it must be sent\n    if (appName.length > 0) {\n        const name = Buffer.byteLength(appName, 'utf8') <= 128\n            ? options.appName\n            : Buffer.from(appName, 'utf8').subarray(0, 128).toString('utf8');\n        metadataDocument.ifItFitsItSits('application', { name });\n    }\n    const { name = '', version = '', platform = '' } = options.driverInfo;\n    const driverInfo = {\n        name: name.length > 0 ? `nodejs|${name}` : 'nodejs',\n        version: version.length > 0 ? `${NODE_DRIVER_VERSION}|${version}` : NODE_DRIVER_VERSION\n    };\n    if (!metadataDocument.ifItFitsItSits('driver', driverInfo)) {\n        throw new error_1.MongoInvalidArgumentError('Unable to include driverInfo name and version, metadata cannot exceed 512 bytes');\n    }\n    let runtimeInfo = getRuntimeInfo();\n    if (platform.length > 0) {\n        runtimeInfo = `${runtimeInfo}|${platform}`;\n    }\n    if (!metadataDocument.ifItFitsItSits('platform', runtimeInfo)) {\n        throw new error_1.MongoInvalidArgumentError('Unable to include driverInfo platform, metadata cannot exceed 512 bytes');\n    }\n    // Note: order matters, os.type is last so it will be removed last if we're at maxSize\n    const osInfo = new Map()\n        .set('name', process.platform)\n        .set('architecture', process.arch)\n        .set('version', os.release())\n        .set('type', os.type());\n    if (!metadataDocument.ifItFitsItSits('os', osInfo)) {\n        for (const key of osInfo.keys()) {\n            osInfo.delete(key);\n            if (osInfo.size === 0)\n                break;\n            if (metadataDocument.ifItFitsItSits('os', osInfo))\n                break;\n        }\n    }\n    const faasEnv = getFAASEnv();\n    if (faasEnv != null) {\n        if (!metadataDocument.ifItFitsItSits('env', faasEnv)) {\n            for (const key of faasEnv.keys()) {\n                faasEnv.delete(key);\n                if (faasEnv.size === 0)\n                    break;\n                if (metadataDocument.ifItFitsItSits('env', faasEnv))\n                    break;\n            }\n        }\n    }\n    return metadataDocument.toObject();\n}\nlet dockerPromise;\n/** @internal */\nasync function getContainerMetadata() {\n    const containerMetadata = {};\n    dockerPromise ??= (0, utils_1.fileIsAccessible)('/.dockerenv');\n    const isDocker = await dockerPromise;\n    const { KUBERNETES_SERVICE_HOST = '' } = process.env;\n    const isKubernetes = KUBERNETES_SERVICE_HOST.length > 0 ? true : false;\n    if (isDocker)\n        containerMetadata.runtime = 'docker';\n    if (isKubernetes)\n        containerMetadata.orchestrator = 'kubernetes';\n    return containerMetadata;\n}\n/**\n * @internal\n * Re-add each metadata value.\n * Attempt to add new env container metadata, but keep old data if it does not fit.\n */\nasync function addContainerMetadata(originalMetadata) {\n    const containerMetadata = await getContainerMetadata();\n    if (Object.keys(containerMetadata).length === 0)\n        return originalMetadata;\n    const extendedMetadata = new LimitedSizeDocument(512);\n    const extendedEnvMetadata = { ...originalMetadata?.env, container: containerMetadata };\n    for (const [key, val] of Object.entries(originalMetadata)) {\n        if (key !== 'env') {\n            extendedMetadata.ifItFitsItSits(key, val);\n        }\n        else {\n            if (!extendedMetadata.ifItFitsItSits('env', extendedEnvMetadata)) {\n                // add in old data if newer / extended metadata does not fit\n                extendedMetadata.ifItFitsItSits('env', val);\n            }\n        }\n    }\n    if (!('env' in originalMetadata)) {\n        extendedMetadata.ifItFitsItSits('env', extendedEnvMetadata);\n    }\n    return extendedMetadata.toObject();\n}\n/**\n * Collects FaaS metadata.\n * - `name` MUST be the last key in the Map returned.\n */\nfunction getFAASEnv() {\n    const { AWS_EXECUTION_ENV = '', AWS_LAMBDA_RUNTIME_API = '', FUNCTIONS_WORKER_RUNTIME = '', K_SERVICE = '', FUNCTION_NAME = '', VERCEL = '', AWS_LAMBDA_FUNCTION_MEMORY_SIZE = '', AWS_REGION = '', FUNCTION_MEMORY_MB = '', FUNCTION_REGION = '', FUNCTION_TIMEOUT_SEC = '', VERCEL_REGION = '' } = process.env;\n    const isAWSFaaS = AWS_EXECUTION_ENV.startsWith('AWS_Lambda_') || AWS_LAMBDA_RUNTIME_API.length > 0;\n    const isAzureFaaS = FUNCTIONS_WORKER_RUNTIME.length > 0;\n    const isGCPFaaS = K_SERVICE.length > 0 || FUNCTION_NAME.length > 0;\n    const isVercelFaaS = VERCEL.length > 0;\n    // Note: order matters, name must always be the last key\n    const faasEnv = new Map();\n    // When isVercelFaaS is true so is isAWSFaaS; Vercel inherits the AWS env\n    if (isVercelFaaS && !(isAzureFaaS || isGCPFaaS)) {\n        if (VERCEL_REGION.length > 0) {\n            faasEnv.set('region', VERCEL_REGION);\n        }\n        faasEnv.set('name', 'vercel');\n        return faasEnv;\n    }\n    if (isAWSFaaS && !(isAzureFaaS || isGCPFaaS || isVercelFaaS)) {\n        if (AWS_REGION.length > 0) {\n            faasEnv.set('region', AWS_REGION);\n        }\n        if (AWS_LAMBDA_FUNCTION_MEMORY_SIZE.length > 0 &&\n            Number.isInteger(+AWS_LAMBDA_FUNCTION_MEMORY_SIZE)) {\n            faasEnv.set('memory_mb', new bson_1.Int32(AWS_LAMBDA_FUNCTION_MEMORY_SIZE));\n        }\n        faasEnv.set('name', 'aws.lambda');\n        return faasEnv;\n    }\n    if (isAzureFaaS && !(isGCPFaaS || isAWSFaaS || isVercelFaaS)) {\n        faasEnv.set('name', 'azure.func');\n        return faasEnv;\n    }\n    if (isGCPFaaS && !(isAzureFaaS || isAWSFaaS || isVercelFaaS)) {\n        if (FUNCTION_REGION.length > 0) {\n            faasEnv.set('region', FUNCTION_REGION);\n        }\n        if (FUNCTION_MEMORY_MB.length > 0 && Number.isInteger(+FUNCTION_MEMORY_MB)) {\n            faasEnv.set('memory_mb', new bson_1.Int32(FUNCTION_MEMORY_MB));\n        }\n        if (FUNCTION_TIMEOUT_SEC.length > 0 && Number.isInteger(+FUNCTION_TIMEOUT_SEC)) {\n            faasEnv.set('timeout_sec', new bson_1.Int32(FUNCTION_TIMEOUT_SEC));\n        }\n        faasEnv.set('name', 'gcp.func');\n        return faasEnv;\n    }\n    return null;\n}\n/**\n * @internal\n * Get current JavaScript runtime platform\n *\n * NOTE: The version information fetching is intentionally written defensively\n * to avoid having a released driver version that becomes incompatible\n * with a future change to these global objects.\n */\nfunction getRuntimeInfo() {\n    if ('Deno' in globalThis) {\n        const version = typeof Deno?.version?.deno === 'string' ? Deno?.version?.deno : '0.0.0-unknown';\n        return `Deno v${version}, ${os.endianness()}`;\n    }\n    if ('Bun' in globalThis) {\n        const version = typeof Bun?.version === 'string' ? Bun?.version : '0.0.0-unknown';\n        return `Bun v${version}, ${os.endianness()}`;\n    }\n    return `Node.js ${process.version}, ${os.endianness()}`;\n}\n//# sourceMappingURL=client_metadata.js.map"
        }
    ]
}