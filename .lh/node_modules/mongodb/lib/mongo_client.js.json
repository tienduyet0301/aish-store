{
    "sourceFile": "node_modules/mongodb/lib/mongo_client.js",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1746892621679,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1746891704042,
            "name": "cart",
            "content": "\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.MongoClient = exports.ServerApiVersion = void 0;\nconst fs_1 = require(\"fs\");\nconst bson_1 = require(\"./bson\");\nconst change_stream_1 = require(\"./change_stream\");\nconst mongo_credentials_1 = require(\"./cmap/auth/mongo_credentials\");\nconst providers_1 = require(\"./cmap/auth/providers\");\nconst connection_string_1 = require(\"./connection_string\");\nconst constants_1 = require(\"./constants\");\nconst db_1 = require(\"./db\");\nconst error_1 = require(\"./error\");\nconst mongo_client_auth_providers_1 = require(\"./mongo_client_auth_providers\");\nconst mongo_logger_1 = require(\"./mongo_logger\");\nconst mongo_types_1 = require(\"./mongo_types\");\nconst executor_1 = require(\"./operations/client_bulk_write/executor\");\nconst execute_operation_1 = require(\"./operations/execute_operation\");\nconst run_command_1 = require(\"./operations/run_command\");\nconst read_preference_1 = require(\"./read_preference\");\nconst resource_management_1 = require(\"./resource_management\");\nconst server_selection_1 = require(\"./sdam/server_selection\");\nconst topology_1 = require(\"./sdam/topology\");\nconst sessions_1 = require(\"./sessions\");\nconst utils_1 = require(\"./utils\");\n/** @public */\nexports.ServerApiVersion = Object.freeze({\n    v1: '1'\n});\n/**\n * The **MongoClient** class is a class that allows for making Connections to MongoDB.\n * @public\n *\n * @remarks\n * The programmatically provided options take precedence over the URI options.\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * // Enable command monitoring for debugging\n * const client = new MongoClient('mongodb://localhost:27017', { monitorCommands: true });\n *\n * client.on('commandStarted', started => console.log(started));\n * client.db().collection('pets');\n * await client.insertOne({ name: 'spot', kind: 'dog' });\n * ```\n */\nclass MongoClient extends mongo_types_1.TypedEventEmitter {\n    constructor(url, options) {\n        super();\n        this.on('error', utils_1.noop);\n        this.options = (0, connection_string_1.parseOptions)(url, this, options);\n        const shouldSetLogger = Object.values(this.options.mongoLoggerOptions.componentSeverities).some(value => value !== mongo_logger_1.SeverityLevel.OFF);\n        this.mongoLogger = shouldSetLogger\n            ? new mongo_logger_1.MongoLogger(this.options.mongoLoggerOptions)\n            : undefined;\n        // eslint-disable-next-line @typescript-eslint/no-this-alias\n        const client = this;\n        // The internal state\n        this.s = {\n            url,\n            bsonOptions: (0, bson_1.resolveBSONOptions)(this.options),\n            namespace: (0, utils_1.ns)('admin'),\n            hasBeenClosed: false,\n            sessionPool: new sessions_1.ServerSessionPool(this),\n            activeSessions: new Set(),\n            activeCursors: new Set(),\n            authProviders: new mongo_client_auth_providers_1.MongoClientAuthProviders(),\n            get options() {\n                return client.options;\n            },\n            get readConcern() {\n                return client.options.readConcern;\n            },\n            get writeConcern() {\n                return client.options.writeConcern;\n            },\n            get readPreference() {\n                return client.options.readPreference;\n            },\n            get isMongoClient() {\n                return true;\n            }\n        };\n        this.checkForNonGenuineHosts();\n    }\n    /** @internal */\n    async asyncDispose() {\n        await this.close();\n    }\n    /** @internal */\n    checkForNonGenuineHosts() {\n        const documentDBHostnames = this.options.hosts.filter((hostAddress) => (0, utils_1.isHostMatch)(utils_1.DOCUMENT_DB_CHECK, hostAddress.host));\n        const srvHostIsDocumentDB = (0, utils_1.isHostMatch)(utils_1.DOCUMENT_DB_CHECK, this.options.srvHost);\n        const cosmosDBHostnames = this.options.hosts.filter((hostAddress) => (0, utils_1.isHostMatch)(utils_1.COSMOS_DB_CHECK, hostAddress.host));\n        const srvHostIsCosmosDB = (0, utils_1.isHostMatch)(utils_1.COSMOS_DB_CHECK, this.options.srvHost);\n        if (documentDBHostnames.length !== 0 || srvHostIsDocumentDB) {\n            this.mongoLogger?.info('client', utils_1.DOCUMENT_DB_MSG);\n        }\n        else if (cosmosDBHostnames.length !== 0 || srvHostIsCosmosDB) {\n            this.mongoLogger?.info('client', utils_1.COSMOS_DB_MSG);\n        }\n    }\n    get serverApi() {\n        return this.options.serverApi && Object.freeze({ ...this.options.serverApi });\n    }\n    /**\n     * Intended for APM use only\n     * @internal\n     */\n    get monitorCommands() {\n        return this.options.monitorCommands;\n    }\n    set monitorCommands(value) {\n        this.options.monitorCommands = value;\n    }\n    /** @internal */\n    get autoEncrypter() {\n        return this.options.autoEncrypter;\n    }\n    get readConcern() {\n        return this.s.readConcern;\n    }\n    get writeConcern() {\n        return this.s.writeConcern;\n    }\n    get readPreference() {\n        return this.s.readPreference;\n    }\n    get bsonOptions() {\n        return this.s.bsonOptions;\n    }\n    get timeoutMS() {\n        return this.s.options.timeoutMS;\n    }\n    /**\n     * Executes a client bulk write operation, available on server 8.0+.\n     * @param models - The client bulk write models.\n     * @param options - The client bulk write options.\n     * @returns A ClientBulkWriteResult for acknowledged writes and ok: 1 for unacknowledged writes.\n     */\n    async bulkWrite(models, options) {\n        if (this.autoEncrypter) {\n            throw new error_1.MongoInvalidArgumentError('MongoClient bulkWrite does not currently support automatic encryption.');\n        }\n        // We do not need schema type information past this point (\"as any\" is fine)\n        return await new executor_1.ClientBulkWriteExecutor(this, models, (0, utils_1.resolveOptions)(this, options)).execute();\n    }\n    /**\n     * Connect to MongoDB using a url\n     *\n     * @remarks\n     * Calling `connect` is optional since the first operation you perform will call `connect` if it's needed.\n     * `timeoutMS` will bound the time any operation can take before throwing a timeout error.\n     * However, when the operation being run is automatically connecting your `MongoClient` the `timeoutMS` will not apply to the time taken to connect the MongoClient.\n     * This means the time to setup the `MongoClient` does not count against `timeoutMS`.\n     * If you are using `timeoutMS` we recommend connecting your client explicitly in advance of any operation to avoid this inconsistent execution time.\n     *\n     * @remarks\n     * The driver will look up corresponding SRV and TXT records if the connection string starts with `mongodb+srv://`.\n     * If those look ups throw a DNS Timeout error, the driver will retry the look up once.\n     *\n     * @see docs.mongodb.org/manual/reference/connection-string/\n     */\n    async connect() {\n        if (this.connectionLock) {\n            return await this.connectionLock;\n        }\n        try {\n            this.connectionLock = this._connect();\n            await this.connectionLock;\n        }\n        finally {\n            // release\n            this.connectionLock = undefined;\n        }\n        return this;\n    }\n    /**\n     * Create a topology to open the connection, must be locked to avoid topology leaks in concurrency scenario.\n     * Locking is enforced by the connect method.\n     *\n     * @internal\n     */\n    async _connect() {\n        if (this.topology && this.topology.isConnected()) {\n            return this;\n        }\n        const options = this.options;\n        if (options.tls) {\n            if (typeof options.tlsCAFile === 'string') {\n                options.ca ??= await fs_1.promises.readFile(options.tlsCAFile);\n            }\n            if (typeof options.tlsCRLFile === 'string') {\n                options.crl ??= await fs_1.promises.readFile(options.tlsCRLFile);\n            }\n            if (typeof options.tlsCertificateKeyFile === 'string') {\n                if (!options.key || !options.cert) {\n                    const contents = await fs_1.promises.readFile(options.tlsCertificateKeyFile);\n                    options.key ??= contents;\n                    options.cert ??= contents;\n                }\n            }\n        }\n        if (typeof options.srvHost === 'string') {\n            const hosts = await (0, connection_string_1.resolveSRVRecord)(options);\n            for (const [index, host] of hosts.entries()) {\n                options.hosts[index] = host;\n            }\n        }\n        // It is important to perform validation of hosts AFTER SRV resolution, to check the real hostname,\n        // but BEFORE we even attempt connecting with a potentially not allowed hostname\n        if (options.credentials?.mechanism === providers_1.AuthMechanism.MONGODB_OIDC) {\n            const allowedHosts = options.credentials?.mechanismProperties?.ALLOWED_HOSTS || mongo_credentials_1.DEFAULT_ALLOWED_HOSTS;\n            const isServiceAuth = !!options.credentials?.mechanismProperties?.ENVIRONMENT;\n            if (!isServiceAuth) {\n                for (const host of options.hosts) {\n                    if (!(0, utils_1.hostMatchesWildcards)(host.toHostPort().host, allowedHosts)) {\n                        throw new error_1.MongoInvalidArgumentError(`Host '${host}' is not valid for OIDC authentication with ALLOWED_HOSTS of '${allowedHosts.join(',')}'`);\n                    }\n                }\n            }\n        }\n        this.topology = new topology_1.Topology(this, options.hosts, options);\n        // Events can be emitted before initialization is complete so we have to\n        // save the reference to the topology on the client ASAP if the event handlers need to access it\n        this.topology.once(topology_1.Topology.OPEN, () => this.emit('open', this));\n        for (const event of constants_1.MONGO_CLIENT_EVENTS) {\n            this.topology.on(event, (...args) => this.emit(event, ...args));\n        }\n        const topologyConnect = async () => {\n            try {\n                await this.topology?.connect(options);\n            }\n            catch (error) {\n                this.topology?.close();\n                throw error;\n            }\n        };\n        if (this.autoEncrypter) {\n            await this.autoEncrypter?.init();\n            await topologyConnect();\n            await options.encrypter.connectInternalClient();\n        }\n        else {\n            await topologyConnect();\n        }\n        return this;\n    }\n    /**\n     * Cleans up client-side resources used by the MongoCLient and .  This includes:\n     *\n     * - Closes all open, unused connections (see note).\n     * - Ends all in-use sessions with {@link ClientSession#endSession|ClientSession.endSession()}.\n     * - Ends all unused sessions server-side.\n     * - Cleans up any resources being used for auto encryption if auto encryption is enabled.\n     *\n     * @remarks Any in-progress operations are not killed and any connections used by in progress operations\n     * will be cleaned up lazily as operations finish.\n     *\n     * @param force - Force close, emitting no events\n     */\n    async close(force = false) {\n        if (this.closeLock) {\n            return await this.closeLock;\n        }\n        try {\n            this.closeLock = this._close(force);\n            await this.closeLock;\n        }\n        finally {\n            // release\n            this.closeLock = undefined;\n        }\n    }\n    /* @internal */\n    async _close(force = false) {\n        // There's no way to set hasBeenClosed back to false\n        Object.defineProperty(this.s, 'hasBeenClosed', {\n            value: true,\n            enumerable: true,\n            configurable: false,\n            writable: false\n        });\n        const activeCursorCloses = Array.from(this.s.activeCursors, cursor => cursor.close());\n        this.s.activeCursors.clear();\n        await Promise.all(activeCursorCloses);\n        const activeSessionEnds = Array.from(this.s.activeSessions, session => session.endSession());\n        this.s.activeSessions.clear();\n        await Promise.all(activeSessionEnds);\n        if (this.topology == null) {\n            return;\n        }\n        // If we would attempt to select a server and get nothing back we short circuit\n        // to avoid the server selection timeout.\n        const selector = (0, server_selection_1.readPreferenceServerSelector)(read_preference_1.ReadPreference.primaryPreferred);\n        const topologyDescription = this.topology.description;\n        const serverDescriptions = Array.from(topologyDescription.servers.values());\n        const servers = selector(topologyDescription, serverDescriptions);\n        if (servers.length !== 0) {\n            const endSessions = Array.from(this.s.sessionPool.sessions, ({ id }) => id);\n            if (endSessions.length !== 0) {\n                try {\n                    await (0, execute_operation_1.executeOperation)(this, new run_command_1.RunAdminCommandOperation({ endSessions }, { readPreference: read_preference_1.ReadPreference.primaryPreferred, noResponse: true }));\n                }\n                catch (error) {\n                    (0, utils_1.squashError)(error);\n                }\n            }\n        }\n        // clear out references to old topology\n        const topology = this.topology;\n        this.topology = undefined;\n        topology.close();\n        const { encrypter } = this.options;\n        if (encrypter) {\n            await encrypter.close(this, force);\n        }\n    }\n    /**\n     * Create a new Db instance sharing the current socket connections.\n     *\n     * @param dbName - The name of the database we want to use. If not provided, use database name from connection string.\n     * @param options - Optional settings for Db construction\n     */\n    db(dbName, options) {\n        options = options ?? {};\n        // Default to db from connection string if not provided\n        if (!dbName) {\n            dbName = this.s.options.dbName;\n        }\n        // Copy the options and add out internal override of the not shared flag\n        const finalOptions = Object.assign({}, this.options, options);\n        // Return the db object\n        const db = new db_1.Db(this, dbName, finalOptions);\n        // Return the database\n        return db;\n    }\n    /**\n     * Connect to MongoDB using a url\n     *\n     * @remarks\n     * Calling `connect` is optional since the first operation you perform will call `connect` if it's needed.\n     * `timeoutMS` will bound the time any operation can take before throwing a timeout error.\n     * However, when the operation being run is automatically connecting your `MongoClient` the `timeoutMS` will not apply to the time taken to connect the MongoClient.\n     * This means the time to setup the `MongoClient` does not count against `timeoutMS`.\n     * If you are using `timeoutMS` we recommend connecting your client explicitly in advance of any operation to avoid this inconsistent execution time.\n     *\n     * @remarks\n     * The programmatically provided options take precedence over the URI options.\n     *\n     * @remarks\n     * The driver will look up corresponding SRV and TXT records if the connection string starts with `mongodb+srv://`.\n     * If those look ups throw a DNS Timeout error, the driver will retry the look up once.\n     *\n     * @see https://www.mongodb.com/docs/manual/reference/connection-string/\n     */\n    static async connect(url, options) {\n        const client = new this(url, options);\n        return await client.connect();\n    }\n    /**\n     * Creates a new ClientSession. When using the returned session in an operation\n     * a corresponding ServerSession will be created.\n     *\n     * @remarks\n     * A ClientSession instance may only be passed to operations being performed on the same\n     * MongoClient it was started from.\n     */\n    startSession(options) {\n        const session = new sessions_1.ClientSession(this, this.s.sessionPool, { explicit: true, ...options }, this.options);\n        this.s.activeSessions.add(session);\n        session.once('ended', () => {\n            this.s.activeSessions.delete(session);\n        });\n        return session;\n    }\n    async withSession(optionsOrExecutor, executor) {\n        const options = {\n            // Always define an owner\n            owner: Symbol(),\n            // If it's an object inherit the options\n            ...(typeof optionsOrExecutor === 'object' ? optionsOrExecutor : {})\n        };\n        const withSessionCallback = typeof optionsOrExecutor === 'function' ? optionsOrExecutor : executor;\n        if (withSessionCallback == null) {\n            throw new error_1.MongoInvalidArgumentError('Missing required callback parameter');\n        }\n        const session = this.startSession(options);\n        try {\n            return await withSessionCallback(session);\n        }\n        finally {\n            try {\n                await session.endSession();\n            }\n            catch (error) {\n                (0, utils_1.squashError)(error);\n            }\n        }\n    }\n    /**\n     * Create a new Change Stream, watching for new changes (insertions, updates,\n     * replacements, deletions, and invalidations) in this cluster. Will ignore all\n     * changes to system collections, as well as the local, admin, and config databases.\n     *\n     * @remarks\n     * watch() accepts two generic arguments for distinct use cases:\n     * - The first is to provide the schema that may be defined for all the data within the current cluster\n     * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n     *\n     * @remarks\n     * When `timeoutMS` is configured for a change stream, it will have different behaviour depending\n     * on whether the change stream is in iterator mode or emitter mode. In both cases, a change\n     * stream will time out if it does not receive a change event within `timeoutMS` of the last change\n     * event.\n     *\n     * Note that if a change stream is consistently timing out when watching a collection, database or\n     * client that is being changed, then this may be due to the server timing out before it can finish\n     * processing the existing oplog. To address this, restart the change stream with a higher\n     * `timeoutMS`.\n     *\n     * If the change stream times out the initial aggregate operation to establish the change stream on\n     * the server, then the client will close the change stream. If the getMore calls to the server\n     * time out, then the change stream will be left open, but will throw a MongoOperationTimeoutError\n     * when in iterator mode and emit an error event that returns a MongoOperationTimeoutError in\n     * emitter mode.\n     *\n     * To determine whether or not the change stream is still open following a timeout, check the\n     * {@link ChangeStream.closed} getter.\n     *\n     * @example\n     * In iterator mode, if a next() call throws a timeout error, it will attempt to resume the change stream.\n     * The next call can just be retried after this succeeds.\n     * ```ts\n     * const changeStream = collection.watch([], { timeoutMS: 100 });\n     * try {\n     *     await changeStream.next();\n     * } catch (e) {\n     *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n     *       await changeStream.next();\n     *     }\n     *     throw e;\n     * }\n     * ```\n     *\n     * @example\n     * In emitter mode, if the change stream goes `timeoutMS` without emitting a change event, it will\n     * emit an error event that returns a MongoOperationTimeoutError, but will not close the change\n     * stream unless the resume attempt fails. There is no need to re-establish change listeners as\n     * this will automatically continue emitting change events once the resume attempt completes.\n     *\n     * ```ts\n     * const changeStream = collection.watch([], { timeoutMS: 100 });\n     * changeStream.on('change', console.log);\n     * changeStream.on('error', e => {\n     *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n     *         // do nothing\n     *     } else {\n     *         changeStream.close();\n     *     }\n     * });\n     * ```\n     * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n     * @param options - Optional settings for the command\n     * @typeParam TSchema - Type of the data being detected by the change stream\n     * @typeParam TChange - Type of the whole change stream document emitted\n     */\n    watch(pipeline = [], options = {}) {\n        // Allow optionally not specifying a pipeline\n        if (!Array.isArray(pipeline)) {\n            options = pipeline;\n            pipeline = [];\n        }\n        return new change_stream_1.ChangeStream(this, pipeline, (0, utils_1.resolveOptions)(this, options));\n    }\n}\nexports.MongoClient = MongoClient;\n(0, resource_management_1.configureResourceManagement)(MongoClient.prototype);\n//# sourceMappingURL=mongo_client.js.map"
        }
    ]
}