{
    "sourceFile": "node_modules/mongodb/src/gridfs/index.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1746892635143,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1746891704042,
            "name": "cart",
            "content": "import type { ObjectId } from '../bson';\nimport type { Collection } from '../collection';\nimport type { FindCursor } from '../cursor/find_cursor';\nimport type { Db } from '../db';\nimport { MongoOperationTimeoutError, MongoRuntimeError } from '../error';\nimport { type Filter, TypedEventEmitter } from '../mongo_types';\nimport type { ReadPreference } from '../read_preference';\nimport type { Sort } from '../sort';\nimport { CSOTTimeoutContext } from '../timeout';\nimport { noop, resolveOptions } from '../utils';\nimport { WriteConcern, type WriteConcernOptions } from '../write_concern';\nimport type { FindOptions } from './../operations/find';\nimport {\n  GridFSBucketReadStream,\n  type GridFSBucketReadStreamOptions,\n  type GridFSBucketReadStreamOptionsWithRevision,\n  type GridFSFile\n} from './download';\nimport {\n  GridFSBucketWriteStream,\n  type GridFSBucketWriteStreamOptions,\n  type GridFSChunk\n} from './upload';\n\nconst DEFAULT_GRIDFS_BUCKET_OPTIONS: {\n  bucketName: string;\n  chunkSizeBytes: number;\n} = {\n  bucketName: 'fs',\n  chunkSizeBytes: 255 * 1024\n};\n\n/** @public */\nexport interface GridFSBucketOptions extends WriteConcernOptions {\n  /** The 'files' and 'chunks' collections will be prefixed with the bucket name followed by a dot. */\n  bucketName?: string;\n  /** Number of bytes stored in each chunk. Defaults to 255KB */\n  chunkSizeBytes?: number;\n  /** Read preference to be passed to read operations */\n  readPreference?: ReadPreference;\n  /**\n   * @experimental\n   * Specifies the lifetime duration of a gridFS stream. If any async operations are in progress\n   * when this timeout expires, the stream will throw a timeout error.\n   */\n  timeoutMS?: number;\n}\n\n/** @internal */\nexport interface GridFSBucketPrivate {\n  db: Db;\n  options: {\n    bucketName: string;\n    chunkSizeBytes: number;\n    readPreference?: ReadPreference;\n    writeConcern: WriteConcern | undefined;\n    timeoutMS?: number;\n  };\n  _chunksCollection: Collection<GridFSChunk>;\n  _filesCollection: Collection<GridFSFile>;\n  checkedIndexes: boolean;\n  calledOpenUploadStream: boolean;\n}\n\n/** @public */\nexport type GridFSBucketEvents = {\n  index(): void;\n};\n\n/**\n * Constructor for a streaming GridFS interface\n * @public\n */\nexport class GridFSBucket extends TypedEventEmitter<GridFSBucketEvents> {\n  /** @internal */\n  s: GridFSBucketPrivate;\n\n  /**\n   * When the first call to openUploadStream is made, the upload stream will\n   * check to see if it needs to create the proper indexes on the chunks and\n   * files collections. This event is fired either when 1) it determines that\n   * no index creation is necessary, 2) when it successfully creates the\n   * necessary indexes.\n   * @event\n   */\n  static readonly INDEX = 'index' as const;\n\n  constructor(db: Db, options?: GridFSBucketOptions) {\n    super();\n    this.on('error', noop);\n    this.setMaxListeners(0);\n    const privateOptions = resolveOptions(db, {\n      ...DEFAULT_GRIDFS_BUCKET_OPTIONS,\n      ...options,\n      writeConcern: WriteConcern.fromOptions(options)\n    });\n    this.s = {\n      db,\n      options: privateOptions,\n      _chunksCollection: db.collection<GridFSChunk>(privateOptions.bucketName + '.chunks'),\n      _filesCollection: db.collection<GridFSFile>(privateOptions.bucketName + '.files'),\n      checkedIndexes: false,\n      calledOpenUploadStream: false\n    };\n  }\n\n  /**\n   * Returns a writable stream (GridFSBucketWriteStream) for writing\n   * buffers to GridFS. The stream's 'id' property contains the resulting\n   * file's id.\n   *\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   */\n\n  openUploadStream(\n    filename: string,\n    options?: GridFSBucketWriteStreamOptions\n  ): GridFSBucketWriteStream {\n    return new GridFSBucketWriteStream(this, filename, {\n      timeoutMS: this.s.options.timeoutMS,\n      ...options\n    });\n  }\n\n  /**\n   * Returns a writable stream (GridFSBucketWriteStream) for writing\n   * buffers to GridFS for a custom file id. The stream's 'id' property contains the resulting\n   * file's id.\n   */\n  openUploadStreamWithId(\n    id: ObjectId,\n    filename: string,\n    options?: GridFSBucketWriteStreamOptions\n  ): GridFSBucketWriteStream {\n    return new GridFSBucketWriteStream(this, filename, {\n      timeoutMS: this.s.options.timeoutMS,\n      ...options,\n      id\n    });\n  }\n\n  /** Returns a readable stream (GridFSBucketReadStream) for streaming file data from GridFS. */\n  openDownloadStream(\n    id: ObjectId,\n    options?: GridFSBucketReadStreamOptions\n  ): GridFSBucketReadStream {\n    return new GridFSBucketReadStream(\n      this.s._chunksCollection,\n      this.s._filesCollection,\n      this.s.options.readPreference,\n      { _id: id },\n      { timeoutMS: this.s.options.timeoutMS, ...options }\n    );\n  }\n\n  /**\n   * Deletes a file with the given id\n   *\n   * @param id - The id of the file doc\n   */\n  async delete(id: ObjectId, options?: { timeoutMS: number }): Promise<void> {\n    const { timeoutMS } = resolveOptions(this.s.db, options);\n    let timeoutContext: CSOTTimeoutContext | undefined = undefined;\n\n    if (timeoutMS) {\n      timeoutContext = new CSOTTimeoutContext({\n        timeoutMS,\n        serverSelectionTimeoutMS: this.s.db.client.s.options.serverSelectionTimeoutMS\n      });\n    }\n\n    const { deletedCount } = await this.s._filesCollection.deleteOne(\n      { _id: id },\n      { timeoutMS: timeoutContext?.remainingTimeMS }\n    );\n\n    const remainingTimeMS = timeoutContext?.remainingTimeMS;\n    if (remainingTimeMS != null && remainingTimeMS <= 0)\n      throw new MongoOperationTimeoutError(`Timed out after ${timeoutMS}ms`);\n    // Delete orphaned chunks before returning FileNotFound\n    await this.s._chunksCollection.deleteMany({ files_id: id }, { timeoutMS: remainingTimeMS });\n\n    if (deletedCount === 0) {\n      // TODO(NODE-3483): Replace with more appropriate error\n      // Consider creating new error MongoGridFSFileNotFoundError\n      throw new MongoRuntimeError(`File not found for id ${id}`);\n    }\n  }\n\n  /** Convenience wrapper around find on the files collection */\n  find(filter: Filter<GridFSFile> = {}, options: FindOptions = {}): FindCursor<GridFSFile> {\n    return this.s._filesCollection.find(filter, options);\n  }\n\n  /**\n   * Returns a readable stream (GridFSBucketReadStream) for streaming the\n   * file with the given name from GridFS. If there are multiple files with\n   * the same name, this will stream the most recent file with the given name\n   * (as determined by the `uploadDate` field). You can set the `revision`\n   * option to change this behavior.\n   */\n  openDownloadStreamByName(\n    filename: string,\n    options?: GridFSBucketReadStreamOptionsWithRevision\n  ): GridFSBucketReadStream {\n    let sort: Sort = { uploadDate: -1 };\n    let skip = undefined;\n    if (options && options.revision != null) {\n      if (options.revision >= 0) {\n        sort = { uploadDate: 1 };\n        skip = options.revision;\n      } else {\n        skip = -options.revision - 1;\n      }\n    }\n    return new GridFSBucketReadStream(\n      this.s._chunksCollection,\n      this.s._filesCollection,\n      this.s.options.readPreference,\n      { filename },\n      { timeoutMS: this.s.options.timeoutMS, ...options, sort, skip }\n    );\n  }\n\n  /**\n   * Renames the file with the given _id to the given string\n   *\n   * @param id - the id of the file to rename\n   * @param filename - new name for the file\n   */\n  async rename(id: ObjectId, filename: string, options?: { timeoutMS: number }): Promise<void> {\n    const filter = { _id: id };\n    const update = { $set: { filename } };\n    const { matchedCount } = await this.s._filesCollection.updateOne(filter, update, options);\n    if (matchedCount === 0) {\n      throw new MongoRuntimeError(`File with id ${id} not found`);\n    }\n  }\n\n  /** Removes this bucket's files collection, followed by its chunks collection. */\n  async drop(options?: { timeoutMS: number }): Promise<void> {\n    const { timeoutMS } = resolveOptions(this.s.db, options);\n    let timeoutContext: CSOTTimeoutContext | undefined = undefined;\n\n    if (timeoutMS) {\n      timeoutContext = new CSOTTimeoutContext({\n        timeoutMS,\n        serverSelectionTimeoutMS: this.s.db.client.s.options.serverSelectionTimeoutMS\n      });\n    }\n\n    if (timeoutContext) {\n      await this.s._filesCollection.drop({ timeoutMS: timeoutContext.remainingTimeMS });\n      const remainingTimeMS = timeoutContext.getRemainingTimeMSOrThrow(\n        `Timed out after ${timeoutMS}ms`\n      );\n      await this.s._chunksCollection.drop({ timeoutMS: remainingTimeMS });\n    } else {\n      await this.s._filesCollection.drop();\n      await this.s._chunksCollection.drop();\n    }\n  }\n}\n"
        }
    ]
}