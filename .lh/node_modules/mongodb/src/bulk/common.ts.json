{
    "sourceFile": "node_modules/mongodb/src/bulk/common.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1746892632331,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1746891704042,
            "name": "cart",
            "content": "import { type BSONSerializeOptions, type Document, EJSON, resolveBSONOptions } from '../bson';\nimport type { Collection } from '../collection';\nimport {\n  type AnyError,\n  MongoBatchReExecutionError,\n  MONGODB_ERROR_CODES,\n  MongoInvalidArgumentError,\n  MongoRuntimeError,\n  MongoServerError,\n  MongoWriteConcernError\n} from '../error';\nimport type { Filter, OneOrMore, OptionalId, UpdateFilter, WithoutId } from '../mongo_types';\nimport type { CollationOptions, CommandOperationOptions } from '../operations/command';\nimport { DeleteOperation, type DeleteStatement, makeDeleteStatement } from '../operations/delete';\nimport { executeOperation } from '../operations/execute_operation';\nimport { InsertOperation } from '../operations/insert';\nimport { AbstractOperation, type Hint } from '../operations/operation';\nimport { makeUpdateStatement, UpdateOperation, type UpdateStatement } from '../operations/update';\nimport type { Server } from '../sdam/server';\nimport type { Topology } from '../sdam/topology';\nimport type { ClientSession } from '../sessions';\nimport { type TimeoutContext } from '../timeout';\nimport {\n  applyRetryableWrites,\n  getTopology,\n  hasAtomicOperators,\n  maybeAddIdToDocuments,\n  type MongoDBNamespace,\n  resolveOptions\n} from '../utils';\nimport { WriteConcern } from '../write_concern';\n\n/** @public */\nexport const BatchType = Object.freeze({\n  INSERT: 1,\n  UPDATE: 2,\n  DELETE: 3\n} as const);\n\n/** @public */\nexport type BatchType = (typeof BatchType)[keyof typeof BatchType];\n\n/** @public */\nexport interface InsertOneModel<TSchema extends Document = Document> {\n  /** The document to insert. */\n  document: OptionalId<TSchema>;\n}\n\n/** @public */\nexport interface DeleteOneModel<TSchema extends Document = Document> {\n  /** The filter to limit the deleted documents. */\n  filter: Filter<TSchema>;\n  /** Specifies a collation. */\n  collation?: CollationOptions;\n  /** The index to use. If specified, then the query system will only consider plans using the hinted index. */\n  hint?: Hint;\n}\n\n/** @public */\nexport interface DeleteManyModel<TSchema extends Document = Document> {\n  /** The filter to limit the deleted documents. */\n  filter: Filter<TSchema>;\n  /** Specifies a collation. */\n  collation?: CollationOptions;\n  /** The index to use. If specified, then the query system will only consider plans using the hinted index. */\n  hint?: Hint;\n}\n\n/** @public */\nexport interface ReplaceOneModel<TSchema extends Document = Document> {\n  /** The filter to limit the replaced document. */\n  filter: Filter<TSchema>;\n  /** The document with which to replace the matched document. */\n  replacement: WithoutId<TSchema>;\n  /** Specifies a collation. */\n  collation?: CollationOptions;\n  /** The index to use. If specified, then the query system will only consider plans using the hinted index. */\n  hint?: Hint;\n  /** When true, creates a new document if no document matches the query. */\n  upsert?: boolean;\n}\n\n/** @public */\nexport interface UpdateOneModel<TSchema extends Document = Document> {\n  /** The filter to limit the updated documents. */\n  filter: Filter<TSchema>;\n  /**\n   * The modifications to apply. The value can be either:\n   * UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * Document[] - an aggregation pipeline.\n   */\n  update: UpdateFilter<TSchema> | Document[];\n  /** A set of filters specifying to which array elements an update should apply. */\n  arrayFilters?: Document[];\n  /** Specifies a collation. */\n  collation?: CollationOptions;\n  /** The index to use. If specified, then the query system will only consider plans using the hinted index. */\n  hint?: Hint;\n  /** When true, creates a new document if no document matches the query. */\n  upsert?: boolean;\n}\n\n/** @public */\nexport interface UpdateManyModel<TSchema extends Document = Document> {\n  /** The filter to limit the updated documents. */\n  filter: Filter<TSchema>;\n  /**\n   * The modifications to apply. The value can be either:\n   * UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * Document[] - an aggregation pipeline.\n   */\n  update: UpdateFilter<TSchema> | Document[];\n  /** A set of filters specifying to which array elements an update should apply. */\n  arrayFilters?: Document[];\n  /** Specifies a collation. */\n  collation?: CollationOptions;\n  /** The index to use. If specified, then the query system will only consider plans using the hinted index. */\n  hint?: Hint;\n  /** When true, creates a new document if no document matches the query. */\n  upsert?: boolean;\n}\n\n/** @public */\nexport type AnyBulkWriteOperation<TSchema extends Document = Document> =\n  | { insertOne: InsertOneModel<TSchema> }\n  | { replaceOne: ReplaceOneModel<TSchema> }\n  | { updateOne: UpdateOneModel<TSchema> }\n  | { updateMany: UpdateManyModel<TSchema> }\n  | { deleteOne: DeleteOneModel<TSchema> }\n  | { deleteMany: DeleteManyModel<TSchema> };\n\n/** @internal */\nexport interface BulkResult {\n  ok: number;\n  writeErrors: WriteError[];\n  writeConcernErrors: WriteConcernError[];\n  insertedIds: Document[];\n  nInserted: number;\n  nUpserted: number;\n  nMatched: number;\n  nModified: number;\n  nRemoved: number;\n  upserted: Document[];\n}\n\n/**\n * Keeps the state of a unordered batch so we can rewrite the results\n * correctly after command execution\n *\n * @public\n */\nexport class Batch<T = Document> {\n  originalZeroIndex: number;\n  currentIndex: number;\n  originalIndexes: number[];\n  batchType: BatchType;\n  operations: T[];\n  size: number;\n  sizeBytes: number;\n\n  constructor(batchType: BatchType, originalZeroIndex: number) {\n    this.originalZeroIndex = originalZeroIndex;\n    this.currentIndex = 0;\n    this.originalIndexes = [];\n    this.batchType = batchType;\n    this.operations = [];\n    this.size = 0;\n    this.sizeBytes = 0;\n  }\n}\n\n/**\n * @public\n * The result of a bulk write.\n */\nexport class BulkWriteResult {\n  private readonly result: BulkResult;\n  /** Number of documents inserted. */\n  readonly insertedCount: number;\n  /** Number of documents matched for update. */\n  readonly matchedCount: number;\n  /** Number of documents modified. */\n  readonly modifiedCount: number;\n  /** Number of documents deleted. */\n  readonly deletedCount: number;\n  /** Number of documents upserted. */\n  readonly upsertedCount: number;\n  /** Upserted document generated Id's, hash key is the index of the originating operation */\n  readonly upsertedIds: { [key: number]: any };\n  /** Inserted document generated Id's, hash key is the index of the originating operation */\n  readonly insertedIds: { [key: number]: any };\n\n  private static generateIdMap(ids: Document[]): { [key: number]: any } {\n    const idMap: { [index: number]: any } = {};\n    for (const doc of ids) {\n      idMap[doc.index] = doc._id;\n    }\n    return idMap;\n  }\n\n  /**\n   * Create a new BulkWriteResult instance\n   * @internal\n   */\n  constructor(bulkResult: BulkResult, isOrdered: boolean) {\n    this.result = bulkResult;\n    this.insertedCount = this.result.nInserted ?? 0;\n    this.matchedCount = this.result.nMatched ?? 0;\n    this.modifiedCount = this.result.nModified ?? 0;\n    this.deletedCount = this.result.nRemoved ?? 0;\n    this.upsertedCount = this.result.upserted.length ?? 0;\n    this.upsertedIds = BulkWriteResult.generateIdMap(this.result.upserted);\n    this.insertedIds = BulkWriteResult.generateIdMap(\n      this.getSuccessfullyInsertedIds(bulkResult, isOrdered)\n    );\n    Object.defineProperty(this, 'result', { value: this.result, enumerable: false });\n  }\n\n  /** Evaluates to true if the bulk operation correctly executes */\n  get ok(): number {\n    return this.result.ok;\n  }\n\n  /**\n   * Returns document_ids that were actually inserted\n   * @internal\n   */\n  private getSuccessfullyInsertedIds(bulkResult: BulkResult, isOrdered: boolean): Document[] {\n    if (bulkResult.writeErrors.length === 0) return bulkResult.insertedIds;\n\n    if (isOrdered) {\n      return bulkResult.insertedIds.slice(0, bulkResult.writeErrors[0].index);\n    }\n\n    return bulkResult.insertedIds.filter(\n      ({ index }) => !bulkResult.writeErrors.some(writeError => index === writeError.index)\n    );\n  }\n\n  /** Returns the upserted id at the given index */\n  getUpsertedIdAt(index: number): Document | undefined {\n    return this.result.upserted[index];\n  }\n\n  /** Returns raw internal result */\n  getRawResponse(): Document {\n    return this.result;\n  }\n\n  /** Returns true if the bulk operation contains a write error */\n  hasWriteErrors(): boolean {\n    return this.result.writeErrors.length > 0;\n  }\n\n  /** Returns the number of write errors off the bulk operation */\n  getWriteErrorCount(): number {\n    return this.result.writeErrors.length;\n  }\n\n  /** Returns a specific write error object */\n  getWriteErrorAt(index: number): WriteError | undefined {\n    return index < this.result.writeErrors.length ? this.result.writeErrors[index] : undefined;\n  }\n\n  /** Retrieve all write errors */\n  getWriteErrors(): WriteError[] {\n    return this.result.writeErrors;\n  }\n\n  /** Retrieve the write concern error if one exists */\n  getWriteConcernError(): WriteConcernError | undefined {\n    if (this.result.writeConcernErrors.length === 0) {\n      return;\n    } else if (this.result.writeConcernErrors.length === 1) {\n      // Return the error\n      return this.result.writeConcernErrors[0];\n    } else {\n      // Combine the errors\n      let errmsg = '';\n      for (let i = 0; i < this.result.writeConcernErrors.length; i++) {\n        const err = this.result.writeConcernErrors[i];\n        errmsg = errmsg + err.errmsg;\n\n        // TODO: Something better\n        if (i === 0) errmsg = errmsg + ' and ';\n      }\n\n      return new WriteConcernError({ errmsg, code: MONGODB_ERROR_CODES.WriteConcernTimeout });\n    }\n  }\n\n  toString(): string {\n    return `BulkWriteResult(${EJSON.stringify(this.result)})`;\n  }\n\n  isOk(): boolean {\n    return this.result.ok === 1;\n  }\n}\n\n/** @public */\nexport interface WriteConcernErrorData {\n  code: number;\n  errmsg: string;\n  errInfo?: Document;\n}\n\n/**\n * An error representing a failure by the server to apply the requested write concern to the bulk operation.\n * @public\n * @category Error\n */\nexport class WriteConcernError {\n  /** @internal */\n  private serverError: WriteConcernErrorData;\n\n  constructor(error: WriteConcernErrorData) {\n    this.serverError = error;\n  }\n\n  /** Write concern error code. */\n  get code(): number | undefined {\n    return this.serverError.code;\n  }\n\n  /** Write concern error message. */\n  get errmsg(): string | undefined {\n    return this.serverError.errmsg;\n  }\n\n  /** Write concern error info. */\n  get errInfo(): Document | undefined {\n    return this.serverError.errInfo;\n  }\n\n  toJSON(): WriteConcernErrorData {\n    return this.serverError;\n  }\n\n  toString(): string {\n    return `WriteConcernError(${this.errmsg})`;\n  }\n}\n\n/** @public */\nexport interface BulkWriteOperationError {\n  index: number;\n  code: number;\n  errmsg: string;\n  errInfo: Document;\n  op: Document | UpdateStatement | DeleteStatement;\n}\n\n/**\n * An error that occurred during a BulkWrite on the server.\n * @public\n * @category Error\n */\nexport class WriteError {\n  err: BulkWriteOperationError;\n\n  constructor(err: BulkWriteOperationError) {\n    this.err = err;\n  }\n\n  /** WriteError code. */\n  get code(): number {\n    return this.err.code;\n  }\n\n  /** WriteError original bulk operation index. */\n  get index(): number {\n    return this.err.index;\n  }\n\n  /** WriteError message. */\n  get errmsg(): string | undefined {\n    return this.err.errmsg;\n  }\n\n  /** WriteError details. */\n  get errInfo(): Document | undefined {\n    return this.err.errInfo;\n  }\n\n  /** Returns the underlying operation that caused the error */\n  getOperation(): Document {\n    return this.err.op;\n  }\n\n  toJSON(): { code: number; index: number; errmsg?: string; op: Document } {\n    return { code: this.err.code, index: this.err.index, errmsg: this.err.errmsg, op: this.err.op };\n  }\n\n  toString(): string {\n    return `WriteError(${JSON.stringify(this.toJSON())})`;\n  }\n}\n\n/** Merges results into shared data structure */\nexport function mergeBatchResults(\n  batch: Batch,\n  bulkResult: BulkResult,\n  err?: AnyError,\n  result?: Document\n): void {\n  // If we have an error set the result to be the err object\n  if (err) {\n    result = err;\n  } else if (result && result.result) {\n    result = result.result;\n  }\n\n  if (result == null) {\n    return;\n  }\n\n  // Do we have a top level error stop processing and return\n  if (result.ok === 0 && bulkResult.ok === 1) {\n    bulkResult.ok = 0;\n\n    const writeError = {\n      index: 0,\n      code: result.code || 0,\n      errmsg: result.message,\n      errInfo: result.errInfo,\n      op: batch.operations[0]\n    };\n\n    bulkResult.writeErrors.push(new WriteError(writeError));\n    return;\n  } else if (result.ok === 0 && bulkResult.ok === 0) {\n    return;\n  }\n\n  // If we have an insert Batch type\n  if (isInsertBatch(batch) && result.n) {\n    bulkResult.nInserted = bulkResult.nInserted + result.n;\n  }\n\n  // If we have an insert Batch type\n  if (isDeleteBatch(batch) && result.n) {\n    bulkResult.nRemoved = bulkResult.nRemoved + result.n;\n  }\n\n  let nUpserted = 0;\n\n  // We have an array of upserted values, we need to rewrite the indexes\n  if (Array.isArray(result.upserted)) {\n    nUpserted = result.upserted.length;\n\n    for (let i = 0; i < result.upserted.length; i++) {\n      bulkResult.upserted.push({\n        index: result.upserted[i].index + batch.originalZeroIndex,\n        _id: result.upserted[i]._id\n      });\n    }\n  } else if (result.upserted) {\n    nUpserted = 1;\n\n    bulkResult.upserted.push({\n      index: batch.originalZeroIndex,\n      _id: result.upserted\n    });\n  }\n\n  // If we have an update Batch type\n  if (isUpdateBatch(batch) && result.n) {\n    const nModified = result.nModified;\n    bulkResult.nUpserted = bulkResult.nUpserted + nUpserted;\n    bulkResult.nMatched = bulkResult.nMatched + (result.n - nUpserted);\n\n    if (typeof nModified === 'number') {\n      bulkResult.nModified = bulkResult.nModified + nModified;\n    } else {\n      bulkResult.nModified = 0;\n    }\n  }\n\n  if (Array.isArray(result.writeErrors)) {\n    for (let i = 0; i < result.writeErrors.length; i++) {\n      const writeError = {\n        index: batch.originalIndexes[result.writeErrors[i].index],\n        code: result.writeErrors[i].code,\n        errmsg: result.writeErrors[i].errmsg,\n        errInfo: result.writeErrors[i].errInfo,\n        op: batch.operations[result.writeErrors[i].index]\n      };\n\n      bulkResult.writeErrors.push(new WriteError(writeError));\n    }\n  }\n\n  if (result.writeConcernError) {\n    bulkResult.writeConcernErrors.push(new WriteConcernError(result.writeConcernError));\n  }\n}\n\nasync function executeCommands(\n  bulkOperation: BulkOperationBase,\n  options: BulkWriteOptions & { timeoutContext?: TimeoutContext | null }\n): Promise<BulkWriteResult> {\n  if (bulkOperation.s.batches.length === 0) {\n    return new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered);\n  }\n\n  for (const batch of bulkOperation.s.batches) {\n    const finalOptions = resolveOptions(bulkOperation, {\n      ...options,\n      ordered: bulkOperation.isOrdered\n    });\n\n    if (finalOptions.bypassDocumentValidation !== true) {\n      delete finalOptions.bypassDocumentValidation;\n    }\n\n    // Is the bypassDocumentValidation options specific\n    if (bulkOperation.s.bypassDocumentValidation === true) {\n      finalOptions.bypassDocumentValidation = true;\n    }\n\n    // Is the checkKeys option disabled\n    if (bulkOperation.s.checkKeys === false) {\n      finalOptions.checkKeys = false;\n    }\n\n    if (finalOptions.retryWrites) {\n      if (isUpdateBatch(batch)) {\n        finalOptions.retryWrites =\n          finalOptions.retryWrites && !batch.operations.some(op => op.multi);\n      }\n\n      if (isDeleteBatch(batch)) {\n        finalOptions.retryWrites =\n          finalOptions.retryWrites && !batch.operations.some(op => op.limit === 0);\n      }\n    }\n\n    const operation = isInsertBatch(batch)\n      ? new InsertOperation(bulkOperation.s.namespace, batch.operations, finalOptions)\n      : isUpdateBatch(batch)\n        ? new UpdateOperation(bulkOperation.s.namespace, batch.operations, finalOptions)\n        : isDeleteBatch(batch)\n          ? new DeleteOperation(bulkOperation.s.namespace, batch.operations, finalOptions)\n          : null;\n\n    if (operation == null) throw new MongoRuntimeError(`Unknown batchType: ${batch.batchType}`);\n\n    let thrownError = null;\n    let result;\n    try {\n      result = await executeOperation(\n        bulkOperation.s.collection.client,\n        operation,\n        finalOptions.timeoutContext\n      );\n    } catch (error) {\n      thrownError = error;\n    }\n\n    if (thrownError != null) {\n      if (thrownError instanceof MongoWriteConcernError) {\n        mergeBatchResults(batch, bulkOperation.s.bulkResult, thrownError, result);\n        const writeResult = new BulkWriteResult(\n          bulkOperation.s.bulkResult,\n          bulkOperation.isOrdered\n        );\n\n        throw new MongoBulkWriteError(\n          {\n            message: thrownError.result.writeConcernError.errmsg,\n            code: thrownError.result.writeConcernError.code\n          },\n          writeResult\n        );\n      } else {\n        // Error is a driver related error not a bulk op error, return early\n        throw new MongoBulkWriteError(\n          thrownError,\n          new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered)\n        );\n      }\n    }\n\n    mergeBatchResults(batch, bulkOperation.s.bulkResult, thrownError, result);\n    const writeResult = new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered);\n    bulkOperation.handleWriteError(writeResult);\n  }\n\n  bulkOperation.s.batches.length = 0;\n\n  const writeResult = new BulkWriteResult(bulkOperation.s.bulkResult, bulkOperation.isOrdered);\n  bulkOperation.handleWriteError(writeResult);\n  return writeResult;\n}\n\n/**\n * An error indicating an unsuccessful Bulk Write\n * @public\n * @category Error\n */\nexport class MongoBulkWriteError extends MongoServerError {\n  result: BulkWriteResult;\n  writeErrors: OneOrMore<WriteError> = [];\n  err?: WriteConcernError;\n\n  /**\n   * **Do not use this constructor!**\n   *\n   * Meant for internal use only.\n   *\n   * @remarks\n   * This class is only meant to be constructed within the driver. This constructor is\n   * not subject to semantic versioning compatibility guarantees and may change at any time.\n   *\n   * @public\n   **/\n  constructor(\n    error:\n      | { message: string; code: number; writeErrors?: WriteError[] }\n      | WriteConcernError\n      | AnyError,\n    result: BulkWriteResult\n  ) {\n    super(error);\n\n    if (error instanceof WriteConcernError) this.err = error;\n    else if (!(error instanceof Error)) {\n      this.message = error.message;\n      this.code = error.code;\n      this.writeErrors = error.writeErrors ?? [];\n    }\n\n    this.result = result;\n    Object.assign(this, error);\n  }\n\n  override get name(): string {\n    return 'MongoBulkWriteError';\n  }\n\n  /** Number of documents inserted. */\n  get insertedCount(): number {\n    return this.result.insertedCount;\n  }\n  /** Number of documents matched for update. */\n  get matchedCount(): number {\n    return this.result.matchedCount;\n  }\n  /** Number of documents modified. */\n  get modifiedCount(): number {\n    return this.result.modifiedCount;\n  }\n  /** Number of documents deleted. */\n  get deletedCount(): number {\n    return this.result.deletedCount;\n  }\n  /** Number of documents upserted. */\n  get upsertedCount(): number {\n    return this.result.upsertedCount;\n  }\n  /** Inserted document generated Id's, hash key is the index of the originating operation */\n  get insertedIds(): { [key: number]: any } {\n    return this.result.insertedIds;\n  }\n  /** Upserted document generated Id's, hash key is the index of the originating operation */\n  get upsertedIds(): { [key: number]: any } {\n    return this.result.upsertedIds;\n  }\n}\n\n/**\n * A builder object that is returned from {@link BulkOperationBase#find}.\n * Is used to build a write operation that involves a query filter.\n *\n * @public\n */\nexport class FindOperators {\n  bulkOperation: BulkOperationBase;\n\n  /**\n   * Creates a new FindOperators object.\n   * @internal\n   */\n  constructor(bulkOperation: BulkOperationBase) {\n    this.bulkOperation = bulkOperation;\n  }\n\n  /** Add a multiple update operation to the bulk operation */\n  update(updateDocument: Document | Document[]): BulkOperationBase {\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(\n      BatchType.UPDATE,\n      makeUpdateStatement(currentOp.selector, updateDocument, {\n        ...currentOp,\n        multi: true\n      })\n    );\n  }\n\n  /** Add a single update operation to the bulk operation */\n  updateOne(updateDocument: Document | Document[]): BulkOperationBase {\n    if (!hasAtomicOperators(updateDocument)) {\n      throw new MongoInvalidArgumentError('Update document requires atomic operators');\n    }\n\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(\n      BatchType.UPDATE,\n      makeUpdateStatement(currentOp.selector, updateDocument, { ...currentOp, multi: false })\n    );\n  }\n\n  /** Add a replace one operation to the bulk operation */\n  replaceOne(replacement: Document): BulkOperationBase {\n    if (hasAtomicOperators(replacement)) {\n      throw new MongoInvalidArgumentError('Replacement document must not use atomic operators');\n    }\n\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(\n      BatchType.UPDATE,\n      makeUpdateStatement(currentOp.selector, replacement, { ...currentOp, multi: false })\n    );\n  }\n\n  /** Add a delete one operation to the bulk operation */\n  deleteOne(): BulkOperationBase {\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(\n      BatchType.DELETE,\n      makeDeleteStatement(currentOp.selector, { ...currentOp, limit: 1 })\n    );\n  }\n\n  /** Add a delete many operation to the bulk operation */\n  delete(): BulkOperationBase {\n    const currentOp = buildCurrentOp(this.bulkOperation);\n    return this.bulkOperation.addToOperationsList(\n      BatchType.DELETE,\n      makeDeleteStatement(currentOp.selector, { ...currentOp, limit: 0 })\n    );\n  }\n\n  /** Upsert modifier for update bulk operation, noting that this operation is an upsert. */\n  upsert(): this {\n    if (!this.bulkOperation.s.currentOp) {\n      this.bulkOperation.s.currentOp = {};\n    }\n\n    this.bulkOperation.s.currentOp.upsert = true;\n    return this;\n  }\n\n  /** Specifies the collation for the query condition. */\n  collation(collation: CollationOptions): this {\n    if (!this.bulkOperation.s.currentOp) {\n      this.bulkOperation.s.currentOp = {};\n    }\n\n    this.bulkOperation.s.currentOp.collation = collation;\n    return this;\n  }\n\n  /** Specifies arrayFilters for UpdateOne or UpdateMany bulk operations. */\n  arrayFilters(arrayFilters: Document[]): this {\n    if (!this.bulkOperation.s.currentOp) {\n      this.bulkOperation.s.currentOp = {};\n    }\n\n    this.bulkOperation.s.currentOp.arrayFilters = arrayFilters;\n    return this;\n  }\n\n  /** Specifies hint for the bulk operation. */\n  hint(hint: Hint): this {\n    if (!this.bulkOperation.s.currentOp) {\n      this.bulkOperation.s.currentOp = {};\n    }\n\n    this.bulkOperation.s.currentOp.hint = hint;\n    return this;\n  }\n}\n\n/** @internal */\nexport interface BulkOperationPrivate {\n  bulkResult: BulkResult;\n  currentBatch?: Batch;\n  currentIndex: number;\n  // ordered specific\n  currentBatchSize: number;\n  currentBatchSizeBytes: number;\n  // unordered specific\n  currentInsertBatch?: Batch;\n  currentUpdateBatch?: Batch;\n  currentRemoveBatch?: Batch;\n  batches: Batch[];\n  // Write concern\n  writeConcern?: WriteConcern;\n  // Max batch size options\n  maxBsonObjectSize: number;\n  maxBatchSizeBytes: number;\n  maxWriteBatchSize: number;\n  maxKeySize: number;\n  // Namespace\n  namespace: MongoDBNamespace;\n  // Topology\n  topology: Topology;\n  // Options\n  options: BulkWriteOptions;\n  // BSON options\n  bsonOptions: BSONSerializeOptions;\n  // Document used to build a bulk operation\n  currentOp?: Document;\n  // Executed\n  executed: boolean;\n  // Collection\n  collection: Collection;\n  // Fundamental error\n  err?: AnyError;\n  // check keys\n  checkKeys: boolean;\n  bypassDocumentValidation?: boolean;\n}\n\n/** @public */\nexport interface BulkWriteOptions extends CommandOperationOptions {\n  /**\n   * Allow driver to bypass schema validation.\n   * @defaultValue `false` - documents will be validated by default\n   **/\n  bypassDocumentValidation?: boolean;\n  /**\n   * If true, when an insert fails, don't execute the remaining writes.\n   * If false, continue with remaining inserts when one fails.\n   * @defaultValue `true` - inserts are ordered by default\n   */\n  ordered?: boolean;\n  /**\n   * Force server to assign _id values instead of driver.\n   * @defaultValue `false` - the driver generates `_id` fields by default\n   **/\n  forceServerObjectId?: boolean;\n  /** Map of parameter names and values that can be accessed using $$var (requires MongoDB 5.0). */\n  let?: Document;\n\n  /** @internal */\n  timeoutContext?: TimeoutContext;\n}\n\n/**\n * TODO(NODE-4063)\n * BulkWrites merge complexity is implemented in executeCommands\n * This provides a vehicle to treat bulkOperations like any other operation (hence \"shim\")\n * We would like this logic to simply live inside the BulkWriteOperation class\n * @internal\n */\nexport class BulkWriteShimOperation extends AbstractOperation {\n  bulkOperation: BulkOperationBase;\n  constructor(bulkOperation: BulkOperationBase, options: BulkWriteOptions) {\n    super(options);\n    this.bulkOperation = bulkOperation;\n  }\n\n  get commandName(): string {\n    return 'bulkWrite' as const;\n  }\n\n  async execute(\n    _server: Server,\n    session: ClientSession | undefined,\n    timeoutContext: TimeoutContext\n  ): Promise<any> {\n    if (this.options.session == null) {\n      // An implicit session could have been created by 'executeOperation'\n      // So if we stick it on finalOptions here, each bulk operation\n      // will use this same session, it'll be passed in the same way\n      // an explicit session would be\n      this.options.session = session;\n    }\n    return await executeCommands(this.bulkOperation, { ...this.options, timeoutContext });\n  }\n}\n\n/** @public */\nexport abstract class BulkOperationBase {\n  isOrdered: boolean;\n  /** @internal */\n  s: BulkOperationPrivate;\n  operationId?: number;\n\n  /**\n   * Create a new OrderedBulkOperation or UnorderedBulkOperation instance\n   * @internal\n   */\n  constructor(\n    private collection: Collection,\n    options: BulkWriteOptions,\n    isOrdered: boolean\n  ) {\n    // determine whether bulkOperation is ordered or unordered\n    this.isOrdered = isOrdered;\n\n    const topology = getTopology(collection);\n    options = options == null ? {} : options;\n    // TODO Bring from driver information in hello\n    // Get the namespace for the write operations\n    const namespace = collection.s.namespace;\n    // Used to mark operation as executed\n    const executed = false;\n\n    // Current item\n    const currentOp = undefined;\n\n    // Set max byte size\n    const hello = topology.lastHello();\n\n    // If we have autoEncryption on, batch-splitting must be done on 2mb chunks, but single documents\n    // over 2mb are still allowed\n    const usingAutoEncryption = !!(topology.s.options && topology.s.options.autoEncrypter);\n    const maxBsonObjectSize =\n      hello && hello.maxBsonObjectSize ? hello.maxBsonObjectSize : 1024 * 1024 * 16;\n    const maxBatchSizeBytes = usingAutoEncryption ? 1024 * 1024 * 2 : maxBsonObjectSize;\n    const maxWriteBatchSize = hello && hello.maxWriteBatchSize ? hello.maxWriteBatchSize : 1000;\n\n    // Calculates the largest possible size of an Array key, represented as a BSON string\n    // element. This calculation:\n    //     1 byte for BSON type\n    //     # of bytes = length of (string representation of (maxWriteBatchSize - 1))\n    //   + 1 bytes for null terminator\n    const maxKeySize = (maxWriteBatchSize - 1).toString(10).length + 2;\n\n    // Final options for retryable writes\n    let finalOptions = Object.assign({}, options);\n    finalOptions = applyRetryableWrites(finalOptions, collection.s.db);\n\n    // Final results\n    const bulkResult: BulkResult = {\n      ok: 1,\n      writeErrors: [],\n      writeConcernErrors: [],\n      insertedIds: [],\n      nInserted: 0,\n      nUpserted: 0,\n      nMatched: 0,\n      nModified: 0,\n      nRemoved: 0,\n      upserted: []\n    };\n\n    // Internal state\n    this.s = {\n      // Final result\n      bulkResult,\n      // Current batch state\n      currentBatch: undefined,\n      currentIndex: 0,\n      // ordered specific\n      currentBatchSize: 0,\n      currentBatchSizeBytes: 0,\n      // unordered specific\n      currentInsertBatch: undefined,\n      currentUpdateBatch: undefined,\n      currentRemoveBatch: undefined,\n      batches: [],\n      // Write concern\n      writeConcern: WriteConcern.fromOptions(options),\n      // Max batch size options\n      maxBsonObjectSize,\n      maxBatchSizeBytes,\n      maxWriteBatchSize,\n      maxKeySize,\n      // Namespace\n      namespace,\n      // Topology\n      topology,\n      // Options\n      options: finalOptions,\n      // BSON options\n      bsonOptions: resolveBSONOptions(options),\n      // Current operation\n      currentOp,\n      // Executed\n      executed,\n      // Collection\n      collection,\n      // Fundamental error\n      err: undefined,\n      // check keys\n      checkKeys: typeof options.checkKeys === 'boolean' ? options.checkKeys : false\n    };\n\n    // bypass Validation\n    if (options.bypassDocumentValidation === true) {\n      this.s.bypassDocumentValidation = true;\n    }\n  }\n\n  /**\n   * Add a single insert document to the bulk operation\n   *\n   * @example\n   * ```ts\n   * const bulkOp = collection.initializeOrderedBulkOp();\n   *\n   * // Adds three inserts to the bulkOp.\n   * bulkOp\n   *   .insert({ a: 1 })\n   *   .insert({ b: 2 })\n   *   .insert({ c: 3 });\n   * await bulkOp.execute();\n   * ```\n   */\n  insert(document: Document): BulkOperationBase {\n    maybeAddIdToDocuments(this.collection, document, {\n      forceServerObjectId: this.shouldForceServerObjectId()\n    });\n\n    return this.addToOperationsList(BatchType.INSERT, document);\n  }\n\n  /**\n   * Builds a find operation for an update/updateOne/delete/deleteOne/replaceOne.\n   * Returns a builder object used to complete the definition of the operation.\n   *\n   * @example\n   * ```ts\n   * const bulkOp = collection.initializeOrderedBulkOp();\n   *\n   * // Add an updateOne to the bulkOp\n   * bulkOp.find({ a: 1 }).updateOne({ $set: { b: 2 } });\n   *\n   * // Add an updateMany to the bulkOp\n   * bulkOp.find({ c: 3 }).update({ $set: { d: 4 } });\n   *\n   * // Add an upsert\n   * bulkOp.find({ e: 5 }).upsert().updateOne({ $set: { f: 6 } });\n   *\n   * // Add a deletion\n   * bulkOp.find({ g: 7 }).deleteOne();\n   *\n   * // Add a multi deletion\n   * bulkOp.find({ h: 8 }).delete();\n   *\n   * // Add a replaceOne\n   * bulkOp.find({ i: 9 }).replaceOne({writeConcern: { j: 10 }});\n   *\n   * // Update using a pipeline (requires Mongodb 4.2 or higher)\n   * bulk.find({ k: 11, y: { $exists: true }, z: { $exists: true } }).updateOne([\n   *   { $set: { total: { $sum: [ '$y', '$z' ] } } }\n   * ]);\n   *\n   * // All of the ops will now be executed\n   * await bulkOp.execute();\n   * ```\n   */\n  find(selector: Document): FindOperators {\n    if (!selector) {\n      throw new MongoInvalidArgumentError('Bulk find operation must specify a selector');\n    }\n\n    // Save a current selector\n    this.s.currentOp = {\n      selector: selector\n    };\n\n    return new FindOperators(this);\n  }\n\n  /** Specifies a raw operation to perform in the bulk write. */\n  raw(op: AnyBulkWriteOperation): this {\n    if (op == null || typeof op !== 'object') {\n      throw new MongoInvalidArgumentError('Operation must be an object with an operation key');\n    }\n    if ('insertOne' in op) {\n      const forceServerObjectId = this.shouldForceServerObjectId();\n      const document =\n        op.insertOne && op.insertOne.document == null\n          ? // TODO(NODE-6003): remove support for omitting the `documents` subdocument in bulk inserts\n            (op.insertOne as Document)\n          : op.insertOne.document;\n\n      maybeAddIdToDocuments(this.collection, document, { forceServerObjectId });\n\n      return this.addToOperationsList(BatchType.INSERT, document);\n    }\n\n    if ('replaceOne' in op || 'updateOne' in op || 'updateMany' in op) {\n      if ('replaceOne' in op) {\n        if ('q' in op.replaceOne) {\n          throw new MongoInvalidArgumentError('Raw operations are not allowed');\n        }\n        const updateStatement = makeUpdateStatement(\n          op.replaceOne.filter,\n          op.replaceOne.replacement,\n          { ...op.replaceOne, multi: false }\n        );\n        if (hasAtomicOperators(updateStatement.u)) {\n          throw new MongoInvalidArgumentError('Replacement document must not use atomic operators');\n        }\n        return this.addToOperationsList(BatchType.UPDATE, updateStatement);\n      }\n\n      if ('updateOne' in op) {\n        if ('q' in op.updateOne) {\n          throw new MongoInvalidArgumentError('Raw operations are not allowed');\n        }\n        const updateStatement = makeUpdateStatement(op.updateOne.filter, op.updateOne.update, {\n          ...op.updateOne,\n          multi: false\n        });\n        if (!hasAtomicOperators(updateStatement.u)) {\n          throw new MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n        return this.addToOperationsList(BatchType.UPDATE, updateStatement);\n      }\n\n      if ('updateMany' in op) {\n        if ('q' in op.updateMany) {\n          throw new MongoInvalidArgumentError('Raw operations are not allowed');\n        }\n        const updateStatement = makeUpdateStatement(op.updateMany.filter, op.updateMany.update, {\n          ...op.updateMany,\n          multi: true\n        });\n        if (!hasAtomicOperators(updateStatement.u)) {\n          throw new MongoInvalidArgumentError('Update document requires atomic operators');\n        }\n        return this.addToOperationsList(BatchType.UPDATE, updateStatement);\n      }\n    }\n\n    if ('deleteOne' in op) {\n      if ('q' in op.deleteOne) {\n        throw new MongoInvalidArgumentError('Raw operations are not allowed');\n      }\n      return this.addToOperationsList(\n        BatchType.DELETE,\n        makeDeleteStatement(op.deleteOne.filter, { ...op.deleteOne, limit: 1 })\n      );\n    }\n\n    if ('deleteMany' in op) {\n      if ('q' in op.deleteMany) {\n        throw new MongoInvalidArgumentError('Raw operations are not allowed');\n      }\n      return this.addToOperationsList(\n        BatchType.DELETE,\n        makeDeleteStatement(op.deleteMany.filter, { ...op.deleteMany, limit: 0 })\n      );\n    }\n\n    // otherwise an unknown operation was provided\n    throw new MongoInvalidArgumentError(\n      'bulkWrite only supports insertOne, updateOne, updateMany, deleteOne, deleteMany'\n    );\n  }\n\n  get length(): number {\n    return this.s.currentIndex;\n  }\n\n  get bsonOptions(): BSONSerializeOptions {\n    return this.s.bsonOptions;\n  }\n\n  get writeConcern(): WriteConcern | undefined {\n    return this.s.writeConcern;\n  }\n\n  get batches(): Batch[] {\n    const batches = [...this.s.batches];\n    if (this.isOrdered) {\n      if (this.s.currentBatch) batches.push(this.s.currentBatch);\n    } else {\n      if (this.s.currentInsertBatch) batches.push(this.s.currentInsertBatch);\n      if (this.s.currentUpdateBatch) batches.push(this.s.currentUpdateBatch);\n      if (this.s.currentRemoveBatch) batches.push(this.s.currentRemoveBatch);\n    }\n    return batches;\n  }\n\n  async execute(options: BulkWriteOptions = {}): Promise<BulkWriteResult> {\n    if (this.s.executed) {\n      throw new MongoBatchReExecutionError();\n    }\n\n    const writeConcern = WriteConcern.fromOptions(options);\n    if (writeConcern) {\n      this.s.writeConcern = writeConcern;\n    }\n\n    // If we have current batch\n    if (this.isOrdered) {\n      if (this.s.currentBatch) this.s.batches.push(this.s.currentBatch);\n    } else {\n      if (this.s.currentInsertBatch) this.s.batches.push(this.s.currentInsertBatch);\n      if (this.s.currentUpdateBatch) this.s.batches.push(this.s.currentUpdateBatch);\n      if (this.s.currentRemoveBatch) this.s.batches.push(this.s.currentRemoveBatch);\n    }\n    // If we have no operations in the bulk raise an error\n    if (this.s.batches.length === 0) {\n      throw new MongoInvalidArgumentError('Invalid BulkOperation, Batch cannot be empty');\n    }\n\n    this.s.executed = true;\n    const finalOptions = { ...this.s.options, ...options };\n    const operation = new BulkWriteShimOperation(this, finalOptions);\n\n    return await executeOperation(this.s.collection.client, operation, finalOptions.timeoutContext);\n  }\n\n  /**\n   * Handles the write error before executing commands\n   * @internal\n   */\n  handleWriteError(writeResult: BulkWriteResult): void {\n    if (this.s.bulkResult.writeErrors.length > 0) {\n      const msg = this.s.bulkResult.writeErrors[0].errmsg\n        ? this.s.bulkResult.writeErrors[0].errmsg\n        : 'write operation failed';\n\n      throw new MongoBulkWriteError(\n        {\n          message: msg,\n          code: this.s.bulkResult.writeErrors[0].code,\n          writeErrors: this.s.bulkResult.writeErrors\n        },\n        writeResult\n      );\n    }\n\n    const writeConcernError = writeResult.getWriteConcernError();\n    if (writeConcernError) {\n      throw new MongoBulkWriteError(writeConcernError, writeResult);\n    }\n  }\n\n  abstract addToOperationsList(\n    batchType: BatchType,\n    document: Document | UpdateStatement | DeleteStatement\n  ): this;\n\n  private shouldForceServerObjectId(): boolean {\n    return (\n      this.s.options.forceServerObjectId === true ||\n      this.s.collection.s.db.options?.forceServerObjectId === true\n    );\n  }\n}\n\nfunction isInsertBatch(batch: Batch): boolean {\n  return batch.batchType === BatchType.INSERT;\n}\n\nfunction isUpdateBatch(batch: Batch): batch is Batch<UpdateStatement> {\n  return batch.batchType === BatchType.UPDATE;\n}\n\nfunction isDeleteBatch(batch: Batch): batch is Batch<DeleteStatement> {\n  return batch.batchType === BatchType.DELETE;\n}\n\nfunction buildCurrentOp(bulkOp: BulkOperationBase): Document {\n  let { currentOp } = bulkOp.s;\n  bulkOp.s.currentOp = undefined;\n  if (!currentOp) currentOp = {};\n  return currentOp;\n}\n"
        }
    ]
}