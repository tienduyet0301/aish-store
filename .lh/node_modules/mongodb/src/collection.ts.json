{
    "sourceFile": "node_modules/mongodb/src/collection.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1746892634509,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1746891704042,
            "name": "cart",
            "content": "import { type BSONSerializeOptions, type Document, resolveBSONOptions } from './bson';\nimport type { AnyBulkWriteOperation, BulkWriteOptions, BulkWriteResult } from './bulk/common';\nimport { OrderedBulkOperation } from './bulk/ordered';\nimport { UnorderedBulkOperation } from './bulk/unordered';\nimport { ChangeStream, type ChangeStreamDocument, type ChangeStreamOptions } from './change_stream';\nimport { AggregationCursor } from './cursor/aggregation_cursor';\nimport { FindCursor } from './cursor/find_cursor';\nimport { ListIndexesCursor } from './cursor/list_indexes_cursor';\nimport {\n  ListSearchIndexesCursor,\n  type ListSearchIndexesOptions\n} from './cursor/list_search_indexes_cursor';\nimport type { Db } from './db';\nimport { MongoInvalidArgumentError, MongoOperationTimeoutError } from './error';\nimport type { MongoClient, PkFactory } from './mongo_client';\nimport type {\n  Abortable,\n  Filter,\n  Flatten,\n  OptionalUnlessRequiredId,\n  TODO_NODE_3286,\n  UpdateFilter,\n  WithId,\n  WithoutId\n} from './mongo_types';\nimport type { AggregateOptions } from './operations/aggregate';\nimport { BulkWriteOperation } from './operations/bulk_write';\nimport { CountOperation, type CountOptions } from './operations/count';\nimport {\n  DeleteManyOperation,\n  DeleteOneOperation,\n  type DeleteOptions,\n  type DeleteResult\n} from './operations/delete';\nimport { DistinctOperation, type DistinctOptions } from './operations/distinct';\nimport { DropCollectionOperation, type DropCollectionOptions } from './operations/drop';\nimport {\n  EstimatedDocumentCountOperation,\n  type EstimatedDocumentCountOptions\n} from './operations/estimated_document_count';\nimport { executeOperation } from './operations/execute_operation';\nimport type { FindOptions } from './operations/find';\nimport {\n  FindOneAndDeleteOperation,\n  type FindOneAndDeleteOptions,\n  FindOneAndReplaceOperation,\n  type FindOneAndReplaceOptions,\n  FindOneAndUpdateOperation,\n  type FindOneAndUpdateOptions\n} from './operations/find_and_modify';\nimport {\n  CreateIndexesOperation,\n  type CreateIndexesOptions,\n  type DropIndexesOptions,\n  DropIndexOperation,\n  type IndexDescription,\n  type IndexDescriptionCompact,\n  type IndexDescriptionInfo,\n  type IndexInformationOptions,\n  type IndexSpecification,\n  type ListIndexesOptions\n} from './operations/indexes';\nimport {\n  InsertManyOperation,\n  type InsertManyResult,\n  InsertOneOperation,\n  type InsertOneOptions,\n  type InsertOneResult\n} from './operations/insert';\nimport { IsCappedOperation } from './operations/is_capped';\nimport type { Hint, OperationOptions } from './operations/operation';\nimport { OptionsOperation } from './operations/options_operation';\nimport { RenameOperation, type RenameOptions } from './operations/rename';\nimport {\n  CreateSearchIndexesOperation,\n  type SearchIndexDescription\n} from './operations/search_indexes/create';\nimport { DropSearchIndexOperation } from './operations/search_indexes/drop';\nimport { UpdateSearchIndexOperation } from './operations/search_indexes/update';\nimport {\n  ReplaceOneOperation,\n  type ReplaceOptions,\n  UpdateManyOperation,\n  UpdateOneOperation,\n  type UpdateOptions,\n  type UpdateResult\n} from './operations/update';\nimport { ReadConcern, type ReadConcernLike } from './read_concern';\nimport { ReadPreference, type ReadPreferenceLike } from './read_preference';\nimport {\n  DEFAULT_PK_FACTORY,\n  MongoDBCollectionNamespace,\n  normalizeHintField,\n  resolveOptions\n} from './utils';\nimport { WriteConcern, type WriteConcernOptions } from './write_concern';\n\n/** @public */\nexport interface ModifyResult<TSchema = Document> {\n  value: WithId<TSchema> | null;\n  lastErrorObject?: Document;\n  ok: 0 | 1;\n}\n\n/** @public */\nexport interface CountDocumentsOptions extends AggregateOptions {\n  /** The number of documents to skip. */\n  skip?: number;\n  /** The maximum amount of documents to consider. */\n  limit?: number;\n}\n\n/** @public */\nexport interface CollectionOptions extends BSONSerializeOptions, WriteConcernOptions {\n  /** Specify a read concern for the collection. (only MongoDB 3.2 or higher supported) */\n  readConcern?: ReadConcernLike;\n  /** The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST). */\n  readPreference?: ReadPreferenceLike;\n  /**\n   * @experimental\n   * Specifies the time an operation will run until it throws a timeout error\n   */\n  timeoutMS?: number;\n}\n\n/** @internal */\nexport interface CollectionPrivate {\n  pkFactory: PkFactory;\n  db: Db;\n  options: any;\n  namespace: MongoDBCollectionNamespace;\n  readPreference?: ReadPreference;\n  bsonOptions: BSONSerializeOptions;\n  collectionHint?: Hint;\n  readConcern?: ReadConcern;\n  writeConcern?: WriteConcern;\n}\n\n/**\n * The **Collection** class is an internal class that embodies a MongoDB collection\n * allowing for insert/find/update/delete and other command operation on that MongoDB collection.\n *\n * **COLLECTION Cannot directly be instantiated**\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * interface Pet {\n *   name: string;\n *   kind: 'dog' | 'cat' | 'fish';\n * }\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const pets = client.db().collection<Pet>('pets');\n *\n * const petCursor = pets.find();\n *\n * for await (const pet of petCursor) {\n *   console.log(`${pet.name} is a ${pet.kind}!`);\n * }\n * ```\n */\nexport class Collection<TSchema extends Document = Document> {\n  /** @internal */\n  s: CollectionPrivate;\n\n  /** @internal */\n  client: MongoClient;\n\n  /**\n   * Create a new Collection instance\n   * @internal\n   */\n  constructor(db: Db, name: string, options?: CollectionOptions) {\n    // Internal state\n    this.s = {\n      db,\n      options,\n      namespace: new MongoDBCollectionNamespace(db.databaseName, name),\n      pkFactory: db.options?.pkFactory ?? DEFAULT_PK_FACTORY,\n      readPreference: ReadPreference.fromOptions(options),\n      bsonOptions: resolveBSONOptions(options, db),\n      readConcern: ReadConcern.fromOptions(options),\n      writeConcern: WriteConcern.fromOptions(options)\n    };\n\n    this.client = db.client;\n  }\n\n  /**\n   * The name of the database this collection belongs to\n   */\n  get dbName(): string {\n    return this.s.namespace.db;\n  }\n\n  /**\n   * The name of this collection\n   */\n  get collectionName(): string {\n    return this.s.namespace.collection;\n  }\n\n  /**\n   * The namespace of this collection, in the format `${this.dbName}.${this.collectionName}`\n   */\n  get namespace(): string {\n    return this.fullNamespace.toString();\n  }\n\n  /**\n   *  @internal\n   *\n   * The `MongoDBNamespace` for the collection.\n   */\n  get fullNamespace(): MongoDBCollectionNamespace {\n    return this.s.namespace;\n  }\n\n  /**\n   * The current readConcern of the collection. If not explicitly defined for\n   * this collection, will be inherited from the parent DB\n   */\n  get readConcern(): ReadConcern | undefined {\n    if (this.s.readConcern == null) {\n      return this.s.db.readConcern;\n    }\n    return this.s.readConcern;\n  }\n\n  /**\n   * The current readPreference of the collection. If not explicitly defined for\n   * this collection, will be inherited from the parent DB\n   */\n  get readPreference(): ReadPreference | undefined {\n    if (this.s.readPreference == null) {\n      return this.s.db.readPreference;\n    }\n\n    return this.s.readPreference;\n  }\n\n  get bsonOptions(): BSONSerializeOptions {\n    return this.s.bsonOptions;\n  }\n\n  /**\n   * The current writeConcern of the collection. If not explicitly defined for\n   * this collection, will be inherited from the parent DB\n   */\n  get writeConcern(): WriteConcern | undefined {\n    if (this.s.writeConcern == null) {\n      return this.s.db.writeConcern;\n    }\n    return this.s.writeConcern;\n  }\n\n  /** The current index hint for the collection */\n  get hint(): Hint | undefined {\n    return this.s.collectionHint;\n  }\n\n  set hint(v: Hint | undefined) {\n    this.s.collectionHint = normalizeHintField(v);\n  }\n\n  public get timeoutMS(): number | undefined {\n    return this.s.options.timeoutMS;\n  }\n\n  /**\n   * Inserts a single document into MongoDB. If documents passed in do not contain the **_id** field,\n   * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n   * can be overridden by setting the **forceServerObjectId** flag.\n   *\n   * @param doc - The document to insert\n   * @param options - Optional settings for the command\n   */\n  async insertOne(\n    doc: OptionalUnlessRequiredId<TSchema>,\n    options?: InsertOneOptions\n  ): Promise<InsertOneResult<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new InsertOneOperation(\n        this as TODO_NODE_3286,\n        doc,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Inserts an array of documents into MongoDB. If documents passed in do not contain the **_id** field,\n   * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n   * can be overridden by setting the **forceServerObjectId** flag.\n   *\n   * @param docs - The documents to insert\n   * @param options - Optional settings for the command\n   */\n  async insertMany(\n    docs: ReadonlyArray<OptionalUnlessRequiredId<TSchema>>,\n    options?: BulkWriteOptions\n  ): Promise<InsertManyResult<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new InsertManyOperation(\n        this as TODO_NODE_3286,\n        docs,\n        resolveOptions(this, options ?? { ordered: true })\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Perform a bulkWrite operation without a fluent API\n   *\n   * Legal operation types are\n   * - `insertOne`\n   * - `replaceOne`\n   * - `updateOne`\n   * - `updateMany`\n   * - `deleteOne`\n   * - `deleteMany`\n   *\n   * If documents passed in do not contain the **_id** field,\n   * one will be added to each of the documents missing it by the driver, mutating the document. This behavior\n   * can be overridden by setting the **forceServerObjectId** flag.\n   *\n   * @param operations - Bulk operations to perform\n   * @param options - Optional settings for the command\n   * @throws MongoDriverError if operations is not an array\n   */\n  async bulkWrite(\n    operations: ReadonlyArray<AnyBulkWriteOperation<TSchema>>,\n    options?: BulkWriteOptions\n  ): Promise<BulkWriteResult> {\n    if (!Array.isArray(operations)) {\n      throw new MongoInvalidArgumentError('Argument \"operations\" must be an array of documents');\n    }\n\n    return await executeOperation(\n      this.client,\n      new BulkWriteOperation(\n        this as TODO_NODE_3286,\n        operations,\n        resolveOptions(this, options ?? { ordered: true })\n      )\n    );\n  }\n\n  /**\n   * Update a single document in a collection\n   *\n   * The value of `update` can be either:\n   * - UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * - Document[] - an aggregation pipeline.\n   *\n   * @param filter - The filter used to select the document to update\n   * @param update - The modifications to apply\n   * @param options - Optional settings for the command\n   */\n  async updateOne(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options?: UpdateOptions\n  ): Promise<UpdateResult<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new UpdateOneOperation(\n        this as TODO_NODE_3286,\n        filter,\n        update,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Replace a document in a collection with another document\n   *\n   * @param filter - The filter used to select the document to replace\n   * @param replacement - The Document that replaces the matching document\n   * @param options - Optional settings for the command\n   */\n  async replaceOne(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options?: ReplaceOptions\n  ): Promise<UpdateResult<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new ReplaceOneOperation(\n        this as TODO_NODE_3286,\n        filter,\n        replacement,\n        resolveOptions(this, options)\n      )\n    );\n  }\n\n  /**\n   * Update multiple documents in a collection\n   *\n   * The value of `update` can be either:\n   * - UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * - Document[] - an aggregation pipeline.\n   *\n   * @param filter - The filter used to select the document to update\n   * @param update - The modifications to apply\n   * @param options - Optional settings for the command\n   */\n  async updateMany(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options?: UpdateOptions\n  ): Promise<UpdateResult<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new UpdateManyOperation(\n        this as TODO_NODE_3286,\n        filter,\n        update,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Delete a document from a collection\n   *\n   * @param filter - The filter used to select the document to remove\n   * @param options - Optional settings for the command\n   */\n  async deleteOne(\n    filter: Filter<TSchema> = {},\n    options: DeleteOptions = {}\n  ): Promise<DeleteResult> {\n    return await executeOperation(\n      this.client,\n      new DeleteOneOperation(this as TODO_NODE_3286, filter, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Delete multiple documents from a collection\n   *\n   * @param filter - The filter used to select the documents to remove\n   * @param options - Optional settings for the command\n   */\n  async deleteMany(\n    filter: Filter<TSchema> = {},\n    options: DeleteOptions = {}\n  ): Promise<DeleteResult> {\n    return await executeOperation(\n      this.client,\n      new DeleteManyOperation(this as TODO_NODE_3286, filter, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Rename the collection.\n   *\n   * @remarks\n   * This operation does not inherit options from the Db or MongoClient.\n   *\n   * @param newName - New name of of the collection.\n   * @param options - Optional settings for the command\n   */\n  async rename(newName: string, options?: RenameOptions): Promise<Collection> {\n    // Intentionally, we do not inherit options from parent for this operation.\n    return await executeOperation(\n      this.client,\n      new RenameOperation(\n        this as TODO_NODE_3286,\n        newName,\n        resolveOptions(undefined, {\n          ...options,\n          readPreference: ReadPreference.PRIMARY\n        })\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Drop the collection from the database, removing it permanently. New accesses will create a new collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  async drop(options?: DropCollectionOptions): Promise<boolean> {\n    return await executeOperation(\n      this.client,\n      new DropCollectionOperation(this.s.db, this.collectionName, options)\n    );\n  }\n\n  /**\n   * Fetches the first document that matches the filter\n   *\n   * @param filter - Query for find Operation\n   * @param options - Optional settings for the command\n   */\n  async findOne(): Promise<WithId<TSchema> | null>;\n  async findOne(filter: Filter<TSchema>): Promise<WithId<TSchema> | null>;\n  async findOne(\n    filter: Filter<TSchema>,\n    options: Omit<FindOptions, 'timeoutMode'> & Abortable\n  ): Promise<WithId<TSchema> | null>;\n\n  // allow an override of the schema.\n  async findOne<T = TSchema>(): Promise<T | null>;\n  async findOne<T = TSchema>(filter: Filter<TSchema>): Promise<T | null>;\n  async findOne<T = TSchema>(\n    filter: Filter<TSchema>,\n    options?: Omit<FindOptions, 'timeoutMode'> & Abortable\n  ): Promise<T | null>;\n\n  async findOne(\n    filter: Filter<TSchema> = {},\n    options: FindOptions & Abortable = {}\n  ): Promise<WithId<TSchema> | null> {\n    const cursor = this.find(filter, options).limit(-1).batchSize(1);\n    const res = await cursor.next();\n    await cursor.close();\n    return res;\n  }\n\n  /**\n   * Creates a cursor for a filter that can be used to iterate over results from MongoDB\n   *\n   * @param filter - The filter predicate. If unspecified, then all documents in the collection will match the predicate\n   */\n  find(): FindCursor<WithId<TSchema>>;\n  find(filter: Filter<TSchema>, options?: FindOptions & Abortable): FindCursor<WithId<TSchema>>;\n  find<T extends Document>(\n    filter: Filter<TSchema>,\n    options?: FindOptions & Abortable\n  ): FindCursor<T>;\n  find(\n    filter: Filter<TSchema> = {},\n    options: FindOptions & Abortable = {}\n  ): FindCursor<WithId<TSchema>> {\n    return new FindCursor<WithId<TSchema>>(\n      this.client,\n      this.s.namespace,\n      filter,\n      resolveOptions(this as TODO_NODE_3286, options)\n    );\n  }\n\n  /**\n   * Returns the options of the collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  async options(options?: OperationOptions): Promise<Document> {\n    return await executeOperation(\n      this.client,\n      new OptionsOperation(this as TODO_NODE_3286, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Returns if the collection is a capped collection\n   *\n   * @param options - Optional settings for the command\n   */\n  async isCapped(options?: OperationOptions): Promise<boolean> {\n    return await executeOperation(\n      this.client,\n      new IsCappedOperation(this as TODO_NODE_3286, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Creates an index on the db and collection collection.\n   *\n   * @param indexSpec - The field name or index specification to create an index for\n   * @param options - Optional settings for the command\n   *\n   * @example\n   * ```ts\n   * const collection = client.db('foo').collection('bar');\n   *\n   * await collection.createIndex({ a: 1, b: -1 });\n   *\n   * // Alternate syntax for { c: 1, d: -1 } that ensures order of indexes\n   * await collection.createIndex([ [c, 1], [d, -1] ]);\n   *\n   * // Equivalent to { e: 1 }\n   * await collection.createIndex('e');\n   *\n   * // Equivalent to { f: 1, g: 1 }\n   * await collection.createIndex(['f', 'g'])\n   *\n   * // Equivalent to { h: 1, i: -1 }\n   * await collection.createIndex([ { h: 1 }, { i: -1 } ]);\n   *\n   * // Equivalent to { j: 1, k: -1, l: 2d }\n   * await collection.createIndex(['j', ['k', -1], { l: '2d' }])\n   * ```\n   */\n  async createIndex(\n    indexSpec: IndexSpecification,\n    options?: CreateIndexesOptions\n  ): Promise<string> {\n    const indexes = await executeOperation(\n      this.client,\n      CreateIndexesOperation.fromIndexSpecification(\n        this,\n        this.collectionName,\n        indexSpec,\n        resolveOptions(this, options)\n      )\n    );\n\n    return indexes[0];\n  }\n\n  /**\n   * Creates multiple indexes in the collection, this method is only supported for\n   * MongoDB 2.6 or higher. Earlier version of MongoDB will throw a command not supported\n   * error.\n   *\n   * **Note**: Unlike {@link Collection#createIndex| createIndex}, this function takes in raw index specifications.\n   * Index specifications are defined {@link https://www.mongodb.com/docs/manual/reference/command/createIndexes/| here}.\n   *\n   * @param indexSpecs - An array of index specifications to be created\n   * @param options - Optional settings for the command\n   *\n   * @example\n   * ```ts\n   * const collection = client.db('foo').collection('bar');\n   * await collection.createIndexes([\n   *   // Simple index on field fizz\n   *   {\n   *     key: { fizz: 1 },\n   *   }\n   *   // wildcard index\n   *   {\n   *     key: { '$**': 1 }\n   *   },\n   *   // named index on darmok and jalad\n   *   {\n   *     key: { darmok: 1, jalad: -1 }\n   *     name: 'tanagra'\n   *   }\n   * ]);\n   * ```\n   */\n  async createIndexes(\n    indexSpecs: IndexDescription[],\n    options?: CreateIndexesOptions\n  ): Promise<string[]> {\n    return await executeOperation(\n      this.client,\n      CreateIndexesOperation.fromIndexDescriptionArray(\n        this,\n        this.collectionName,\n        indexSpecs,\n        resolveOptions(this, { ...options, maxTimeMS: undefined })\n      )\n    );\n  }\n\n  /**\n   * Drops an index from this collection.\n   *\n   * @param indexName - Name of the index to drop.\n   * @param options - Optional settings for the command\n   */\n  async dropIndex(indexName: string, options?: DropIndexesOptions): Promise<Document> {\n    return await executeOperation(\n      this.client,\n      new DropIndexOperation(this as TODO_NODE_3286, indexName, {\n        ...resolveOptions(this, options),\n        readPreference: ReadPreference.primary\n      })\n    );\n  }\n\n  /**\n   * Drops all indexes from this collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  async dropIndexes(options?: DropIndexesOptions): Promise<boolean> {\n    try {\n      await executeOperation(\n        this.client,\n        new DropIndexOperation(this as TODO_NODE_3286, '*', resolveOptions(this, options))\n      );\n      return true;\n    } catch (error) {\n      // TODO(NODE-6517): Driver should only filter for namespace not found error. Other errors should be thrown.\n      if (error instanceof MongoOperationTimeoutError) throw error;\n      return false;\n    }\n  }\n\n  /**\n   * Get the list of all indexes information for the collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  listIndexes(options?: ListIndexesOptions): ListIndexesCursor {\n    return new ListIndexesCursor(this as TODO_NODE_3286, resolveOptions(this, options));\n  }\n\n  /**\n   * Checks if one or more indexes exist on the collection, fails on first non-existing index\n   *\n   * @param indexes - One or more index names to check.\n   * @param options - Optional settings for the command\n   */\n  async indexExists(indexes: string | string[], options?: ListIndexesOptions): Promise<boolean> {\n    const indexNames: string[] = Array.isArray(indexes) ? indexes : [indexes];\n    const allIndexes: Set<string> = new Set(\n      await this.listIndexes(options)\n        .map(({ name }) => name)\n        .toArray()\n    );\n    return indexNames.every(name => allIndexes.has(name));\n  }\n\n  /**\n   * Retrieves this collections index info.\n   *\n   * @param options - Optional settings for the command\n   */\n  indexInformation(\n    options: IndexInformationOptions & { full: true }\n  ): Promise<IndexDescriptionInfo[]>;\n  indexInformation(\n    options: IndexInformationOptions & { full?: false }\n  ): Promise<IndexDescriptionCompact>;\n  indexInformation(\n    options: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]>;\n  indexInformation(): Promise<IndexDescriptionCompact>;\n  async indexInformation(\n    options?: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]> {\n    return await this.indexes({\n      ...options,\n      full: options?.full ?? false\n    });\n  }\n\n  /**\n   * Gets an estimate of the count of documents in a collection using collection metadata.\n   * This will always run a count command on all server versions.\n   *\n   * due to an oversight in versions 5.0.0-5.0.8 of MongoDB, the count command,\n   * which estimatedDocumentCount uses in its implementation, was not included in v1 of\n   * the Stable API, and so users of the Stable API with estimatedDocumentCount are\n   * recommended to upgrade their server version to 5.0.9+ or set apiStrict: false to avoid\n   * encountering errors.\n   *\n   * @see {@link https://www.mongodb.com/docs/manual/reference/command/count/#behavior|Count: Behavior}\n   * @param options - Optional settings for the command\n   */\n  async estimatedDocumentCount(options?: EstimatedDocumentCountOptions): Promise<number> {\n    return await executeOperation(\n      this.client,\n      new EstimatedDocumentCountOperation(this as TODO_NODE_3286, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Gets the number of documents matching the filter.\n   * For a fast count of the total documents in a collection see {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.\n   *\n   * Due to countDocuments using the $match aggregation pipeline stage, certain query operators cannot be used in countDocuments. This includes the $where and $near query operators, among others. Details can be found in the documentation for the $match aggregation pipeline stage.\n   *\n   * **Note**: When migrating from {@link Collection#count| count} to {@link Collection#countDocuments| countDocuments}\n   * the following query operators must be replaced:\n   *\n   * | Operator | Replacement |\n   * | -------- | ----------- |\n   * | `$where`   | [`$expr`][1] |\n   * | `$near`    | [`$geoWithin`][2] with [`$center`][3] |\n   * | `$nearSphere` | [`$geoWithin`][2] with [`$centerSphere`][4] |\n   *\n   * [1]: https://www.mongodb.com/docs/manual/reference/operator/query/expr/\n   * [2]: https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n   * [3]: https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center\n   * [4]: https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere\n   *\n   * @param filter - The filter for the count\n   * @param options - Optional settings for the command\n   *\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/expr/\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/geoWithin/\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/center/#op._S_center\n   * @see https://www.mongodb.com/docs/manual/reference/operator/query/centerSphere/#op._S_centerSphere\n   */\n  async countDocuments(\n    filter: Filter<TSchema> = {},\n    options: CountDocumentsOptions & Abortable = {}\n  ): Promise<number> {\n    const pipeline = [];\n    pipeline.push({ $match: filter });\n\n    if (typeof options.skip === 'number') {\n      pipeline.push({ $skip: options.skip });\n    }\n\n    if (typeof options.limit === 'number') {\n      pipeline.push({ $limit: options.limit });\n    }\n\n    pipeline.push({ $group: { _id: 1, n: { $sum: 1 } } });\n\n    const cursor = this.aggregate<{ n: number }>(pipeline, options);\n    const doc = await cursor.next();\n    await cursor.close();\n    return doc?.n ?? 0;\n  }\n\n  /**\n   * The distinct command returns a list of distinct values for the given key across a collection.\n   *\n   * @param key - Field of the document to find distinct values for\n   * @param filter - The filter for filtering the set of documents to which we apply the distinct filter.\n   * @param options - Optional settings for the command\n   */\n  distinct<Key extends keyof WithId<TSchema>>(\n    key: Key\n  ): Promise<Array<Flatten<WithId<TSchema>[Key]>>>;\n  distinct<Key extends keyof WithId<TSchema>>(\n    key: Key,\n    filter: Filter<TSchema>\n  ): Promise<Array<Flatten<WithId<TSchema>[Key]>>>;\n  distinct<Key extends keyof WithId<TSchema>>(\n    key: Key,\n    filter: Filter<TSchema>,\n    options: DistinctOptions\n  ): Promise<Array<Flatten<WithId<TSchema>[Key]>>>;\n\n  // Embedded documents overload\n  distinct(key: string): Promise<any[]>;\n  distinct(key: string, filter: Filter<TSchema>): Promise<any[]>;\n  distinct(key: string, filter: Filter<TSchema>, options: DistinctOptions): Promise<any[]>;\n\n  async distinct<Key extends keyof WithId<TSchema>>(\n    key: Key,\n    filter: Filter<TSchema> = {},\n    options: DistinctOptions = {}\n  ): Promise<any[]> {\n    return await executeOperation(\n      this.client,\n      new DistinctOperation(\n        this as TODO_NODE_3286,\n        key as TODO_NODE_3286,\n        filter,\n        resolveOptions(this, options)\n      )\n    );\n  }\n\n  /**\n   * Retrieve all the indexes on the collection.\n   *\n   * @param options - Optional settings for the command\n   */\n  indexes(options: IndexInformationOptions & { full?: true }): Promise<IndexDescriptionInfo[]>;\n  indexes(options: IndexInformationOptions & { full: false }): Promise<IndexDescriptionCompact>;\n  indexes(\n    options: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]>;\n  indexes(options?: ListIndexesOptions): Promise<IndexDescriptionInfo[]>;\n  async indexes(\n    options?: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]> {\n    const indexes: IndexDescriptionInfo[] = await this.listIndexes(options).toArray();\n    const full = options?.full ?? true;\n    if (full) {\n      return indexes;\n    }\n\n    const object: IndexDescriptionCompact = Object.fromEntries(\n      indexes.map(({ name, key }) => [name, Object.entries(key)])\n    );\n\n    return object;\n  }\n\n  /**\n   * Find a document and delete it in one atomic operation. Requires a write lock for the duration of the operation.\n   *\n   * @param filter - The filter used to select the document to remove\n   * @param options - Optional settings for the command\n   */\n  async findOneAndDelete(\n    filter: Filter<TSchema>,\n    options: FindOneAndDeleteOptions & { includeResultMetadata: true }\n  ): Promise<ModifyResult<TSchema>>;\n  async findOneAndDelete(\n    filter: Filter<TSchema>,\n    options: FindOneAndDeleteOptions & { includeResultMetadata: false }\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndDelete(\n    filter: Filter<TSchema>,\n    options: FindOneAndDeleteOptions\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndDelete(filter: Filter<TSchema>): Promise<WithId<TSchema> | null>;\n  async findOneAndDelete(\n    filter: Filter<TSchema>,\n    options?: FindOneAndDeleteOptions\n  ): Promise<WithId<TSchema> | ModifyResult<TSchema> | null> {\n    return await executeOperation(\n      this.client,\n      new FindOneAndDeleteOperation(\n        this as TODO_NODE_3286,\n        filter,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Find a document and replace it in one atomic operation. Requires a write lock for the duration of the operation.\n   *\n   * @param filter - The filter used to select the document to replace\n   * @param replacement - The Document that replaces the matching document\n   * @param options - Optional settings for the command\n   */\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options: FindOneAndReplaceOptions & { includeResultMetadata: true }\n  ): Promise<ModifyResult<TSchema>>;\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options: FindOneAndReplaceOptions & { includeResultMetadata: false }\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options: FindOneAndReplaceOptions\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndReplace(\n    filter: Filter<TSchema>,\n    replacement: WithoutId<TSchema>,\n    options?: FindOneAndReplaceOptions\n  ): Promise<WithId<TSchema> | ModifyResult<TSchema> | null> {\n    return await executeOperation(\n      this.client,\n      new FindOneAndReplaceOperation(\n        this as TODO_NODE_3286,\n        filter,\n        replacement,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Find a document and update it in one atomic operation. Requires a write lock for the duration of the operation.\n   *\n   * The value of `update` can be either:\n   * - UpdateFilter<TSchema> - A document that contains update operator expressions,\n   * - Document[] - an aggregation pipeline consisting of the following stages:\n   *   - $addFields and its alias $set\n   *   - $project and its alias $unset\n   *   - $replaceRoot and its alias $replaceWith.\n   * See the [findAndModify command documentation](https://www.mongodb.com/docs/manual/reference/command/findAndModify) for details.\n   *\n   * @param filter - The filter used to select the document to update\n   * @param update - The modifications to apply\n   * @param options - Optional settings for the command\n   */\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options: FindOneAndUpdateOptions & { includeResultMetadata: true }\n  ): Promise<ModifyResult<TSchema>>;\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options: FindOneAndUpdateOptions & { includeResultMetadata: false }\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options: FindOneAndUpdateOptions\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[]\n  ): Promise<WithId<TSchema> | null>;\n  async findOneAndUpdate(\n    filter: Filter<TSchema>,\n    update: UpdateFilter<TSchema> | Document[],\n    options?: FindOneAndUpdateOptions\n  ): Promise<WithId<TSchema> | ModifyResult<TSchema> | null> {\n    return await executeOperation(\n      this.client,\n      new FindOneAndUpdateOperation(\n        this as TODO_NODE_3286,\n        filter,\n        update,\n        resolveOptions(this, options)\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Execute an aggregation framework pipeline against the collection, needs MongoDB \\>= 2.2\n   *\n   * @param pipeline - An array of aggregation pipelines to execute\n   * @param options - Optional settings for the command\n   */\n  aggregate<T extends Document = Document>(\n    pipeline: Document[] = [],\n    options?: AggregateOptions & Abortable\n  ): AggregationCursor<T> {\n    if (!Array.isArray(pipeline)) {\n      throw new MongoInvalidArgumentError(\n        'Argument \"pipeline\" must be an array of aggregation stages'\n      );\n    }\n\n    return new AggregationCursor(\n      this.client,\n      this.s.namespace,\n      pipeline,\n      resolveOptions(this, options)\n    );\n  }\n\n  /**\n   * Create a new Change Stream, watching for new changes (insertions, updates, replacements, deletions, and invalidations) in this collection.\n   *\n   * @remarks\n   * watch() accepts two generic arguments for distinct use cases:\n   * - The first is to override the schema that may be defined for this specific collection\n   * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n   * @example\n   * By just providing the first argument I can type the change to be `ChangeStreamDocument<{ _id: number }>`\n   * ```ts\n   * collection.watch<{ _id: number }>()\n   *   .on('change', change => console.log(change._id.toFixed(4)));\n   * ```\n   *\n   * @example\n   * Passing a second argument provides a way to reflect the type changes caused by an advanced pipeline.\n   * Here, we are using a pipeline to have MongoDB filter for insert changes only and add a comment.\n   * No need start from scratch on the ChangeStreamInsertDocument type!\n   * By using an intersection we can save time and ensure defaults remain the same type!\n   * ```ts\n   * collection\n   *   .watch<Schema, ChangeStreamInsertDocument<Schema> & { comment: string }>([\n   *     { $addFields: { comment: 'big changes' } },\n   *     { $match: { operationType: 'insert' } }\n   *   ])\n   *   .on('change', change => {\n   *     change.comment.startsWith('big');\n   *     change.operationType === 'insert';\n   *     // No need to narrow in code because the generics did that for us!\n   *     expectType<Schema>(change.fullDocument);\n   *   });\n   * ```\n   *\n   * @remarks\n   * When `timeoutMS` is configured for a change stream, it will have different behaviour depending\n   * on whether the change stream is in iterator mode or emitter mode. In both cases, a change\n   * stream will time out if it does not receive a change event within `timeoutMS` of the last change\n   * event.\n   *\n   * Note that if a change stream is consistently timing out when watching a collection, database or\n   * client that is being changed, then this may be due to the server timing out before it can finish\n   * processing the existing oplog. To address this, restart the change stream with a higher\n   * `timeoutMS`.\n   *\n   * If the change stream times out the initial aggregate operation to establish the change stream on\n   * the server, then the client will close the change stream. If the getMore calls to the server\n   * time out, then the change stream will be left open, but will throw a MongoOperationTimeoutError\n   * when in iterator mode and emit an error event that returns a MongoOperationTimeoutError in\n   * emitter mode.\n   *\n   * To determine whether or not the change stream is still open following a timeout, check the\n   * {@link ChangeStream.closed} getter.\n   *\n   * @example\n   * In iterator mode, if a next() call throws a timeout error, it will attempt to resume the change stream.\n   * The next call can just be retried after this succeeds.\n   * ```ts\n   * const changeStream = collection.watch([], { timeoutMS: 100 });\n   * try {\n   *     await changeStream.next();\n   * } catch (e) {\n   *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n   *       await changeStream.next();\n   *     }\n   *     throw e;\n   * }\n   * ```\n   *\n   * @example\n   * In emitter mode, if the change stream goes `timeoutMS` without emitting a change event, it will\n   * emit an error event that returns a MongoOperationTimeoutError, but will not close the change\n   * stream unless the resume attempt fails. There is no need to re-establish change listeners as\n   * this will automatically continue emitting change events once the resume attempt completes.\n   *\n   * ```ts\n   * const changeStream = collection.watch([], { timeoutMS: 100 });\n   * changeStream.on('change', console.log);\n   * changeStream.on('error', e => {\n   *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n   *         // do nothing\n   *     } else {\n   *         changeStream.close();\n   *     }\n   * });\n   * ```\n   *\n   * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n   * @param options - Optional settings for the command\n   * @typeParam TLocal - Type of the data being detected by the change stream\n   * @typeParam TChange - Type of the whole change stream document emitted\n   */\n  watch<TLocal extends Document = TSchema, TChange extends Document = ChangeStreamDocument<TLocal>>(\n    pipeline: Document[] = [],\n    options: ChangeStreamOptions = {}\n  ): ChangeStream<TLocal, TChange> {\n    // Allow optionally not specifying a pipeline\n    if (!Array.isArray(pipeline)) {\n      options = pipeline;\n      pipeline = [];\n    }\n\n    return new ChangeStream<TLocal, TChange>(this, pipeline, resolveOptions(this, options));\n  }\n\n  /**\n   * Initiate an Out of order batch write operation. All operations will be buffered into insert/update/remove commands executed out of order.\n   *\n   * @throws MongoNotConnectedError\n   * @remarks\n   * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.\n   * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.\n   */\n  initializeUnorderedBulkOp(options?: BulkWriteOptions): UnorderedBulkOperation {\n    return new UnorderedBulkOperation(this as TODO_NODE_3286, resolveOptions(this, options));\n  }\n\n  /**\n   * Initiate an In order bulk write operation. Operations will be serially executed in the order they are added, creating a new operation for each switch in types.\n   *\n   * @throws MongoNotConnectedError\n   * @remarks\n   * **NOTE:** MongoClient must be connected prior to calling this method due to a known limitation in this legacy implementation.\n   * However, `collection.bulkWrite()` provides an equivalent API that does not require prior connecting.\n   */\n  initializeOrderedBulkOp(options?: BulkWriteOptions): OrderedBulkOperation {\n    return new OrderedBulkOperation(this as TODO_NODE_3286, resolveOptions(this, options));\n  }\n\n  /**\n   * An estimated count of matching documents in the db to a filter.\n   *\n   * **NOTE:** This method has been deprecated, since it does not provide an accurate count of the documents\n   * in a collection. To obtain an accurate count of documents in the collection, use {@link Collection#countDocuments| countDocuments}.\n   * To obtain an estimated count of all documents in the collection, use {@link Collection#estimatedDocumentCount| estimatedDocumentCount}.\n   *\n   * @deprecated use {@link Collection#countDocuments| countDocuments} or {@link Collection#estimatedDocumentCount| estimatedDocumentCount} instead\n   *\n   * @param filter - The filter for the count.\n   * @param options - Optional settings for the command\n   */\n  async count(filter: Filter<TSchema> = {}, options: CountOptions = {}): Promise<number> {\n    return await executeOperation(\n      this.client,\n      new CountOperation(this.fullNamespace, filter, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Returns all search indexes for the current collection.\n   *\n   * @param options - The options for the list indexes operation.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  listSearchIndexes(options?: ListSearchIndexesOptions): ListSearchIndexesCursor;\n  /**\n   * Returns all search indexes for the current collection.\n   *\n   * @param name - The name of the index to search for.  Only indexes with matching index names will be returned.\n   * @param options - The options for the list indexes operation.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  listSearchIndexes(name: string, options?: ListSearchIndexesOptions): ListSearchIndexesCursor;\n  listSearchIndexes(\n    indexNameOrOptions?: string | ListSearchIndexesOptions,\n    options?: ListSearchIndexesOptions\n  ): ListSearchIndexesCursor {\n    options =\n      typeof indexNameOrOptions === 'object' ? indexNameOrOptions : options == null ? {} : options;\n\n    const indexName =\n      indexNameOrOptions == null\n        ? null\n        : typeof indexNameOrOptions === 'object'\n          ? null\n          : indexNameOrOptions;\n\n    return new ListSearchIndexesCursor(this as TODO_NODE_3286, indexName, options);\n  }\n\n  /**\n   * Creates a single search index for the collection.\n   *\n   * @param description - The index description for the new search index.\n   * @returns A promise that resolves to the name of the new search index.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  async createSearchIndex(description: SearchIndexDescription): Promise<string> {\n    const [index] = await this.createSearchIndexes([description]);\n    return index;\n  }\n\n  /**\n   * Creates multiple search indexes for the current collection.\n   *\n   * @param descriptions - An array of `SearchIndexDescription`s for the new search indexes.\n   * @returns A promise that resolves to an array of the newly created search index names.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   * @returns\n   */\n  async createSearchIndexes(descriptions: SearchIndexDescription[]): Promise<string[]> {\n    return await executeOperation(\n      this.client,\n      new CreateSearchIndexesOperation(this as TODO_NODE_3286, descriptions)\n    );\n  }\n\n  /**\n   * Deletes a search index by index name.\n   *\n   * @param name - The name of the search index to be deleted.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  async dropSearchIndex(name: string): Promise<void> {\n    return await executeOperation(\n      this.client,\n      new DropSearchIndexOperation(this as TODO_NODE_3286, name)\n    );\n  }\n\n  /**\n   * Updates a search index by replacing the existing index definition with the provided definition.\n   *\n   * @param name - The name of the search index to update.\n   * @param definition - The new search index definition.\n   *\n   * @remarks Only available when used against a 7.0+ Atlas cluster.\n   */\n  async updateSearchIndex(name: string, definition: Document): Promise<void> {\n    return await executeOperation(\n      this.client,\n      new UpdateSearchIndexOperation(this as TODO_NODE_3286, name, definition)\n    );\n  }\n}\n"
        }
    ]
}