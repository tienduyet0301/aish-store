{
    "sourceFile": "node_modules/mongodb/src/db.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1746892634960,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1746891704042,
            "name": "cart",
            "content": "import { Admin } from './admin';\nimport { type BSONSerializeOptions, type Document, resolveBSONOptions } from './bson';\nimport { ChangeStream, type ChangeStreamDocument, type ChangeStreamOptions } from './change_stream';\nimport { Collection, type CollectionOptions } from './collection';\nimport * as CONSTANTS from './constants';\nimport { AggregationCursor } from './cursor/aggregation_cursor';\nimport { ListCollectionsCursor } from './cursor/list_collections_cursor';\nimport { RunCommandCursor, type RunCursorCommandOptions } from './cursor/run_command_cursor';\nimport { MongoInvalidArgumentError } from './error';\nimport type { MongoClient, PkFactory } from './mongo_client';\nimport type { Abortable, TODO_NODE_3286 } from './mongo_types';\nimport type { AggregateOptions } from './operations/aggregate';\nimport { CollectionsOperation } from './operations/collections';\nimport {\n  CreateCollectionOperation,\n  type CreateCollectionOptions\n} from './operations/create_collection';\nimport {\n  DropCollectionOperation,\n  type DropCollectionOptions,\n  DropDatabaseOperation,\n  type DropDatabaseOptions\n} from './operations/drop';\nimport { executeOperation } from './operations/execute_operation';\nimport {\n  CreateIndexesOperation,\n  type CreateIndexesOptions,\n  type IndexDescriptionCompact,\n  type IndexDescriptionInfo,\n  type IndexInformationOptions,\n  type IndexSpecification\n} from './operations/indexes';\nimport type { CollectionInfo, ListCollectionsOptions } from './operations/list_collections';\nimport { ProfilingLevelOperation, type ProfilingLevelOptions } from './operations/profiling_level';\nimport { RemoveUserOperation, type RemoveUserOptions } from './operations/remove_user';\nimport { RenameOperation, type RenameOptions } from './operations/rename';\nimport { RunCommandOperation, type RunCommandOptions } from './operations/run_command';\nimport {\n  type ProfilingLevel,\n  SetProfilingLevelOperation,\n  type SetProfilingLevelOptions\n} from './operations/set_profiling_level';\nimport { DbStatsOperation, type DbStatsOptions } from './operations/stats';\nimport { ReadConcern } from './read_concern';\nimport { ReadPreference, type ReadPreferenceLike } from './read_preference';\nimport { DEFAULT_PK_FACTORY, filterOptions, MongoDBNamespace, resolveOptions } from './utils';\nimport { WriteConcern, type WriteConcernOptions } from './write_concern';\n\n// Allowed parameters\nconst DB_OPTIONS_ALLOW_LIST = [\n  'writeConcern',\n  'readPreference',\n  'readPreferenceTags',\n  'native_parser',\n  'forceServerObjectId',\n  'pkFactory',\n  'serializeFunctions',\n  'raw',\n  'authSource',\n  'ignoreUndefined',\n  'readConcern',\n  'retryMiliSeconds',\n  'numberOfRetries',\n  'useBigInt64',\n  'promoteBuffers',\n  'promoteLongs',\n  'bsonRegExp',\n  'enableUtf8Validation',\n  'promoteValues',\n  'compression',\n  'retryWrites',\n  'timeoutMS'\n];\n\n/** @internal */\nexport interface DbPrivate {\n  options?: DbOptions;\n  readPreference?: ReadPreference;\n  pkFactory: PkFactory;\n  readConcern?: ReadConcern;\n  bsonOptions: BSONSerializeOptions;\n  writeConcern?: WriteConcern;\n  namespace: MongoDBNamespace;\n}\n\n/** @public */\nexport interface DbOptions extends BSONSerializeOptions, WriteConcernOptions {\n  /** If the database authentication is dependent on another databaseName. */\n  authSource?: string;\n  /** Force server to assign _id values instead of driver. */\n  forceServerObjectId?: boolean;\n  /** The preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST). */\n  readPreference?: ReadPreferenceLike;\n  /** A primary key factory object for generation of custom _id keys. */\n  pkFactory?: PkFactory;\n  /** Specify a read concern for the collection. (only MongoDB 3.2 or higher supported) */\n  readConcern?: ReadConcern;\n  /** Should retry failed writes */\n  retryWrites?: boolean;\n  /**\n   * @experimental\n   * Specifies the time an operation will run until it throws a timeout error\n   */\n  timeoutMS?: number;\n}\n\n/**\n * The **Db** class is a class that represents a MongoDB Database.\n * @public\n *\n * @example\n * ```ts\n * import { MongoClient } from 'mongodb';\n *\n * interface Pet {\n *   name: string;\n *   kind: 'dog' | 'cat' | 'fish';\n * }\n *\n * const client = new MongoClient('mongodb://localhost:27017');\n * const db = client.db();\n *\n * // Create a collection that validates our union\n * await db.createCollection<Pet>('pets', {\n *   validator: { $expr: { $in: ['$kind', ['dog', 'cat', 'fish']] } }\n * })\n * ```\n */\nexport class Db {\n  /** @internal */\n  s: DbPrivate;\n\n  /** @internal */\n  readonly client: MongoClient;\n\n  public static SYSTEM_NAMESPACE_COLLECTION = CONSTANTS.SYSTEM_NAMESPACE_COLLECTION;\n  public static SYSTEM_INDEX_COLLECTION = CONSTANTS.SYSTEM_INDEX_COLLECTION;\n  public static SYSTEM_PROFILE_COLLECTION = CONSTANTS.SYSTEM_PROFILE_COLLECTION;\n  public static SYSTEM_USER_COLLECTION = CONSTANTS.SYSTEM_USER_COLLECTION;\n  public static SYSTEM_COMMAND_COLLECTION = CONSTANTS.SYSTEM_COMMAND_COLLECTION;\n  public static SYSTEM_JS_COLLECTION = CONSTANTS.SYSTEM_JS_COLLECTION;\n\n  /**\n   * Creates a new Db instance.\n   *\n   * Db name cannot contain a dot, the server may apply more restrictions when an operation is run.\n   *\n   * @param client - The MongoClient for the database.\n   * @param databaseName - The name of the database this instance represents.\n   * @param options - Optional settings for Db construction.\n   */\n  constructor(client: MongoClient, databaseName: string, options?: DbOptions) {\n    options = options ?? {};\n\n    // Filter the options\n    options = filterOptions(options, DB_OPTIONS_ALLOW_LIST);\n\n    // Ensure there are no dots in database name\n    if (typeof databaseName === 'string' && databaseName.includes('.')) {\n      throw new MongoInvalidArgumentError(`Database names cannot contain the character '.'`);\n    }\n\n    // Internal state of the db object\n    this.s = {\n      // Options\n      options,\n      // Unpack read preference\n      readPreference: ReadPreference.fromOptions(options),\n      // Merge bson options\n      bsonOptions: resolveBSONOptions(options, client),\n      // Set up the primary key factory or fallback to ObjectId\n      pkFactory: options?.pkFactory ?? DEFAULT_PK_FACTORY,\n      // ReadConcern\n      readConcern: ReadConcern.fromOptions(options),\n      writeConcern: WriteConcern.fromOptions(options),\n      // Namespace\n      namespace: new MongoDBNamespace(databaseName)\n    };\n\n    this.client = client;\n  }\n\n  get databaseName(): string {\n    return this.s.namespace.db;\n  }\n\n  // Options\n  get options(): DbOptions | undefined {\n    return this.s.options;\n  }\n\n  /**\n   * Check if a secondary can be used (because the read preference is *not* set to primary)\n   */\n  get secondaryOk(): boolean {\n    return this.s.readPreference?.preference !== 'primary' || false;\n  }\n\n  get readConcern(): ReadConcern | undefined {\n    return this.s.readConcern;\n  }\n\n  /**\n   * The current readPreference of the Db. If not explicitly defined for\n   * this Db, will be inherited from the parent MongoClient\n   */\n  get readPreference(): ReadPreference {\n    if (this.s.readPreference == null) {\n      return this.client.readPreference;\n    }\n\n    return this.s.readPreference;\n  }\n\n  get bsonOptions(): BSONSerializeOptions {\n    return this.s.bsonOptions;\n  }\n\n  // get the write Concern\n  get writeConcern(): WriteConcern | undefined {\n    return this.s.writeConcern;\n  }\n\n  get namespace(): string {\n    return this.s.namespace.toString();\n  }\n\n  public get timeoutMS(): number | undefined {\n    return this.s.options?.timeoutMS;\n  }\n\n  /**\n   * Create a new collection on a server with the specified options. Use this to create capped collections.\n   * More information about command options available at https://www.mongodb.com/docs/manual/reference/command/create/\n   *\n   * Collection namespace validation is performed server-side.\n   *\n   * @param name - The name of the collection to create\n   * @param options - Optional settings for the command\n   */\n  async createCollection<TSchema extends Document = Document>(\n    name: string,\n    options?: CreateCollectionOptions\n  ): Promise<Collection<TSchema>> {\n    return await executeOperation(\n      this.client,\n      new CreateCollectionOperation(this, name, resolveOptions(this, options)) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Execute a command\n   *\n   * @remarks\n   * This command does not inherit options from the MongoClient.\n   *\n   * The driver will ensure the following fields are attached to the command sent to the server:\n   * - `lsid` - sourced from an implicit session or options.session\n   * - `$readPreference` - defaults to primary or can be configured by options.readPreference\n   * - `$db` - sourced from the name of this database\n   *\n   * If the client has a serverApi setting:\n   * - `apiVersion`\n   * - `apiStrict`\n   * - `apiDeprecationErrors`\n   *\n   * When in a transaction:\n   * - `readConcern` - sourced from readConcern set on the TransactionOptions\n   * - `writeConcern` - sourced from writeConcern set on the TransactionOptions\n   *\n   * Attaching any of the above fields to the command will have no effect as the driver will overwrite the value.\n   *\n   * @param command - The command to run\n   * @param options - Optional settings for the command\n   */\n  async command(command: Document, options?: RunCommandOptions & Abortable): Promise<Document> {\n    // Intentionally, we do not inherit options from parent for this operation.\n    return await executeOperation(\n      this.client,\n      new RunCommandOperation(\n        this,\n        command,\n        resolveOptions(undefined, {\n          ...resolveBSONOptions(options),\n          timeoutMS: options?.timeoutMS ?? this.timeoutMS,\n          session: options?.session,\n          readPreference: options?.readPreference,\n          signal: options?.signal\n        })\n      )\n    );\n  }\n\n  /**\n   * Execute an aggregation framework pipeline against the database.\n   *\n   * @param pipeline - An array of aggregation stages to be executed\n   * @param options - Optional settings for the command\n   */\n  aggregate<T extends Document = Document>(\n    pipeline: Document[] = [],\n    options?: AggregateOptions\n  ): AggregationCursor<T> {\n    return new AggregationCursor(\n      this.client,\n      this.s.namespace,\n      pipeline,\n      resolveOptions(this, options)\n    );\n  }\n\n  /** Return the Admin db instance */\n  admin(): Admin {\n    return new Admin(this);\n  }\n\n  /**\n   * Returns a reference to a MongoDB Collection. If it does not exist it will be created implicitly.\n   *\n   * Collection namespace validation is performed server-side.\n   *\n   * @param name - the collection name we wish to access.\n   * @returns return the new Collection instance\n   */\n  collection<TSchema extends Document = Document>(\n    name: string,\n    options: CollectionOptions = {}\n  ): Collection<TSchema> {\n    if (typeof options === 'function') {\n      throw new MongoInvalidArgumentError('The callback form of this helper has been removed.');\n    }\n    return new Collection<TSchema>(this, name, resolveOptions(this, options));\n  }\n\n  /**\n   * Get all the db statistics.\n   *\n   * @param options - Optional settings for the command\n   */\n  async stats(options?: DbStatsOptions): Promise<Document> {\n    return await executeOperation(\n      this.client,\n      new DbStatsOperation(this, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * List all collections of this database with optional filter\n   *\n   * @param filter - Query to filter collections by\n   * @param options - Optional settings for the command\n   */\n  listCollections(\n    filter: Document,\n    options: Exclude<ListCollectionsOptions, 'nameOnly'> & { nameOnly: true } & Abortable\n  ): ListCollectionsCursor<Pick<CollectionInfo, 'name' | 'type'>>;\n  listCollections(\n    filter: Document,\n    options: Exclude<ListCollectionsOptions, 'nameOnly'> & { nameOnly: false } & Abortable\n  ): ListCollectionsCursor<CollectionInfo>;\n  listCollections<\n    T extends Pick<CollectionInfo, 'name' | 'type'> | CollectionInfo =\n      | Pick<CollectionInfo, 'name' | 'type'>\n      | CollectionInfo\n  >(filter?: Document, options?: ListCollectionsOptions & Abortable): ListCollectionsCursor<T>;\n  listCollections<\n    T extends Pick<CollectionInfo, 'name' | 'type'> | CollectionInfo =\n      | Pick<CollectionInfo, 'name' | 'type'>\n      | CollectionInfo\n  >(\n    filter: Document = {},\n    options: ListCollectionsOptions & Abortable = {}\n  ): ListCollectionsCursor<T> {\n    return new ListCollectionsCursor<T>(this, filter, resolveOptions(this, options));\n  }\n\n  /**\n   * Rename a collection.\n   *\n   * @remarks\n   * This operation does not inherit options from the MongoClient.\n   *\n   * @param fromCollection - Name of current collection to rename\n   * @param toCollection - New name of of the collection\n   * @param options - Optional settings for the command\n   */\n  async renameCollection<TSchema extends Document = Document>(\n    fromCollection: string,\n    toCollection: string,\n    options?: RenameOptions\n  ): Promise<Collection<TSchema>> {\n    // Intentionally, we do not inherit options from parent for this operation.\n    return await executeOperation(\n      this.client,\n      new RenameOperation(\n        this.collection<TSchema>(fromCollection) as TODO_NODE_3286,\n        toCollection,\n        resolveOptions(undefined, {\n          ...options,\n          new_collection: true,\n          readPreference: ReadPreference.primary\n        })\n      ) as TODO_NODE_3286\n    );\n  }\n\n  /**\n   * Drop a collection from the database, removing it permanently. New accesses will create a new collection.\n   *\n   * @param name - Name of collection to drop\n   * @param options - Optional settings for the command\n   */\n  async dropCollection(name: string, options?: DropCollectionOptions): Promise<boolean> {\n    return await executeOperation(\n      this.client,\n      new DropCollectionOperation(this, name, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Drop a database, removing it permanently from the server.\n   *\n   * @param options - Optional settings for the command\n   */\n  async dropDatabase(options?: DropDatabaseOptions): Promise<boolean> {\n    return await executeOperation(\n      this.client,\n      new DropDatabaseOperation(this, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Fetch all collections for the current db.\n   *\n   * @param options - Optional settings for the command\n   */\n  async collections(options?: ListCollectionsOptions): Promise<Collection[]> {\n    return await executeOperation(\n      this.client,\n      new CollectionsOperation(this, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Creates an index on the db and collection.\n   *\n   * @param name - Name of the collection to create the index on.\n   * @param indexSpec - Specify the field to index, or an index specification\n   * @param options - Optional settings for the command\n   */\n  async createIndex(\n    name: string,\n    indexSpec: IndexSpecification,\n    options?: CreateIndexesOptions\n  ): Promise<string> {\n    const indexes = await executeOperation(\n      this.client,\n      CreateIndexesOperation.fromIndexSpecification(this, name, indexSpec, options)\n    );\n    return indexes[0];\n  }\n\n  /**\n   * Remove a user from a database\n   *\n   * @param username - The username to remove\n   * @param options - Optional settings for the command\n   */\n  async removeUser(username: string, options?: RemoveUserOptions): Promise<boolean> {\n    return await executeOperation(\n      this.client,\n      new RemoveUserOperation(this, username, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Set the current profiling level of MongoDB\n   *\n   * @param level - The new profiling level (off, slow_only, all).\n   * @param options - Optional settings for the command\n   */\n  async setProfilingLevel(\n    level: ProfilingLevel,\n    options?: SetProfilingLevelOptions\n  ): Promise<ProfilingLevel> {\n    return await executeOperation(\n      this.client,\n      new SetProfilingLevelOperation(this, level, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Retrieve the current profiling Level for MongoDB\n   *\n   * @param options - Optional settings for the command\n   */\n  async profilingLevel(options?: ProfilingLevelOptions): Promise<string> {\n    return await executeOperation(\n      this.client,\n      new ProfilingLevelOperation(this, resolveOptions(this, options))\n    );\n  }\n\n  /**\n   * Retrieves this collections index info.\n   *\n   * @param name - The name of the collection.\n   * @param options - Optional settings for the command\n   */\n  indexInformation(\n    name: string,\n    options: IndexInformationOptions & { full: true }\n  ): Promise<IndexDescriptionInfo[]>;\n  indexInformation(\n    name: string,\n    options: IndexInformationOptions & { full?: false }\n  ): Promise<IndexDescriptionCompact>;\n  indexInformation(\n    name: string,\n    options: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]>;\n  indexInformation(name: string): Promise<IndexDescriptionCompact>;\n  async indexInformation(\n    name: string,\n    options?: IndexInformationOptions\n  ): Promise<IndexDescriptionCompact | IndexDescriptionInfo[]> {\n    return await this.collection(name).indexInformation(resolveOptions(this, options));\n  }\n\n  /**\n   * Create a new Change Stream, watching for new changes (insertions, updates,\n   * replacements, deletions, and invalidations) in this database. Will ignore all\n   * changes to system collections.\n   *\n   * @remarks\n   * watch() accepts two generic arguments for distinct use cases:\n   * - The first is to provide the schema that may be defined for all the collections within this database\n   * - The second is to override the shape of the change stream document entirely, if it is not provided the type will default to ChangeStreamDocument of the first argument\n   *\n   * @remarks\n   * When `timeoutMS` is configured for a change stream, it will have different behaviour depending\n   * on whether the change stream is in iterator mode or emitter mode. In both cases, a change\n   * stream will time out if it does not receive a change event within `timeoutMS` of the last change\n   * event.\n   *\n   * Note that if a change stream is consistently timing out when watching a collection, database or\n   * client that is being changed, then this may be due to the server timing out before it can finish\n   * processing the existing oplog. To address this, restart the change stream with a higher\n   * `timeoutMS`.\n   *\n   * If the change stream times out the initial aggregate operation to establish the change stream on\n   * the server, then the client will close the change stream. If the getMore calls to the server\n   * time out, then the change stream will be left open, but will throw a MongoOperationTimeoutError\n   * when in iterator mode and emit an error event that returns a MongoOperationTimeoutError in\n   * emitter mode.\n   *\n   * To determine whether or not the change stream is still open following a timeout, check the\n   * {@link ChangeStream.closed} getter.\n   *\n   * @example\n   * In iterator mode, if a next() call throws a timeout error, it will attempt to resume the change stream.\n   * The next call can just be retried after this succeeds.\n   * ```ts\n   * const changeStream = collection.watch([], { timeoutMS: 100 });\n   * try {\n   *     await changeStream.next();\n   * } catch (e) {\n   *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n   *       await changeStream.next();\n   *     }\n   *     throw e;\n   * }\n   * ```\n   *\n   * @example\n   * In emitter mode, if the change stream goes `timeoutMS` without emitting a change event, it will\n   * emit an error event that returns a MongoOperationTimeoutError, but will not close the change\n   * stream unless the resume attempt fails. There is no need to re-establish change listeners as\n   * this will automatically continue emitting change events once the resume attempt completes.\n   *\n   * ```ts\n   * const changeStream = collection.watch([], { timeoutMS: 100 });\n   * changeStream.on('change', console.log);\n   * changeStream.on('error', e => {\n   *     if (e instanceof MongoOperationTimeoutError && !changeStream.closed) {\n   *         // do nothing\n   *     } else {\n   *         changeStream.close();\n   *     }\n   * });\n   * ```\n   * @param pipeline - An array of {@link https://www.mongodb.com/docs/manual/reference/operator/aggregation-pipeline/|aggregation pipeline stages} through which to pass change stream documents. This allows for filtering (using $match) and manipulating the change stream documents.\n   * @param options - Optional settings for the command\n   * @typeParam TSchema - Type of the data being detected by the change stream\n   * @typeParam TChange - Type of the whole change stream document emitted\n   */\n  watch<\n    TSchema extends Document = Document,\n    TChange extends Document = ChangeStreamDocument<TSchema>\n  >(pipeline: Document[] = [], options: ChangeStreamOptions = {}): ChangeStream<TSchema, TChange> {\n    // Allow optionally not specifying a pipeline\n    if (!Array.isArray(pipeline)) {\n      options = pipeline;\n      pipeline = [];\n    }\n\n    return new ChangeStream<TSchema, TChange>(this, pipeline, resolveOptions(this, options));\n  }\n\n  /**\n   * A low level cursor API providing basic driver functionality:\n   * - ClientSession management\n   * - ReadPreference for server selection\n   * - Running getMores automatically when a local batch is exhausted\n   *\n   * @param command - The command that will start a cursor on the server.\n   * @param options - Configurations for running the command, bson options will apply to getMores\n   */\n  runCursorCommand(command: Document, options?: RunCursorCommandOptions): RunCommandCursor {\n    return new RunCommandCursor(this, command, options);\n  }\n}\n"
        }
    ]
}