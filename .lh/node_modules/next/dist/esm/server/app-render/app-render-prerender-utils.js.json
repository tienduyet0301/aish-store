{
    "sourceFile": "node_modules/next/dist/esm/server/app-render/app-render-prerender-utils.js",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1746892820422,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1746891704042,
            "name": "cart",
            "content": "import { InvariantError } from '../../shared/lib/invariant-error';\nimport { isPrerenderInterruptedError } from './dynamic-rendering';\n/**\n * This is a utility function to make scheduling sequential tasks that run back to back easier.\n * We schedule on the same queue (setImmediate) at the same time to ensure no other events can sneak in between.\n */ export function prerenderAndAbortInSequentialTasks(prerender, abort) {\n    if (process.env.NEXT_RUNTIME === 'edge') {\n        throw Object.defineProperty(new InvariantError('`prerenderAndAbortInSequentialTasks` should not be called in edge runtime.'), \"__NEXT_ERROR_CODE\", {\n            value: \"E538\",\n            enumerable: false,\n            configurable: true\n        });\n    } else {\n        return new Promise((resolve, reject)=>{\n            let pendingResult;\n            setImmediate(()=>{\n                try {\n                    pendingResult = prerender();\n                    pendingResult.catch(()=>{});\n                } catch (err) {\n                    reject(err);\n                }\n            });\n            setImmediate(()=>{\n                abort();\n                resolve(pendingResult);\n            });\n        });\n    }\n}\nexport function prerenderServerWithPhases(signal, render, ...remainingPhases) {\n    if (process.env.NEXT_RUNTIME === 'edge') {\n        throw Object.defineProperty(new InvariantError('`prerenderAndAbortInSequentialTasks` should not be called in edge runtime.'), \"__NEXT_ERROR_CODE\", {\n            value: \"E538\",\n            enumerable: false,\n            configurable: true\n        });\n    } else {\n        return new Promise((resolve, reject)=>{\n            let result;\n            signal.addEventListener('abort', ()=>{\n                if (isPrerenderInterruptedError(signal.reason)) {\n                    result.markInterrupted();\n                } else {\n                    result.markComplete();\n                }\n            }, {\n                once: true\n            });\n            setImmediate(()=>{\n                try {\n                    result = new ServerPrerenderStreamResult(render());\n                } catch (err) {\n                    reject(err);\n                }\n            });\n            function runFinalTask() {\n                try {\n                    if (result) {\n                        result.markComplete();\n                        this();\n                    }\n                    resolve(result);\n                } catch (err) {\n                    reject(err);\n                }\n            }\n            function runNextTask() {\n                try {\n                    if (result) {\n                        result.markPhase();\n                        this();\n                    }\n                } catch (err) {\n                    reject(err);\n                }\n            }\n            let i = 0;\n            for(; i < remainingPhases.length - 1; i++){\n                const phase = remainingPhases[i];\n                setImmediate(runNextTask.bind(phase));\n            }\n            if (remainingPhases[i]) {\n                const finalPhase = remainingPhases[i];\n                setImmediate(runFinalTask.bind(finalPhase));\n            }\n        });\n    }\n}\nconst PENDING = 0;\nconst COMPLETE = 1;\nconst INTERRUPTED = 2;\nconst ERRORED = 3;\nexport class ServerPrerenderStreamResult {\n    constructor(stream){\n        this.status = PENDING;\n        this.reason = null;\n        this.trailingChunks = [];\n        this.currentChunks = [];\n        this.chunksByPhase = [\n            this.currentChunks\n        ];\n        const reader = stream.getReader();\n        const progress = ({ done, value })=>{\n            if (done) {\n                if (this.status === PENDING) {\n                    this.status = COMPLETE;\n                }\n                return;\n            }\n            if (this.status === PENDING || this.status === INTERRUPTED) {\n                this.currentChunks.push(value);\n            } else {\n                this.trailingChunks.push(value);\n            }\n            reader.read().then(progress, error);\n        };\n        const error = (reason)=>{\n            this.status = ERRORED;\n            this.reason = reason;\n        };\n        reader.read().then(progress, error);\n    }\n    markPhase() {\n        this.currentChunks = [];\n        this.chunksByPhase.push(this.currentChunks);\n    }\n    markComplete() {\n        if (this.status === PENDING) {\n            this.status = COMPLETE;\n        }\n    }\n    markInterrupted() {\n        this.status = INTERRUPTED;\n    }\n    /**\n   * Returns a stream which only releases chunks when `releasePhase` is called. This stream will never \"complete\" because\n   * we rely upon the stream remaining open when prerendering to avoid triggering errors for incomplete chunks in the client.\n   *\n   * asPhasedStream is expected to be called once per result however it is safe to call multiple times as long as we have not\n   * transferred the underlying data. Generally this will only happen when streaming to a response\n   */ asPhasedStream() {\n        switch(this.status){\n            case COMPLETE:\n            case INTERRUPTED:\n                return new PhasedStream(this.chunksByPhase);\n            default:\n                throw Object.defineProperty(new InvariantError(`ServerPrerenderStreamResult cannot be consumed as a stream because it is not yet complete. status: ${this.status}`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E612\",\n                    enumerable: false,\n                    configurable: true\n                });\n        }\n    }\n    /**\n   * Returns a stream which will release all chunks immediately. This stream will \"complete\" synchronously. It should be used outside\n   * of render use cases like loading client chunks ahead of SSR or writing the streamed content to disk.\n   */ asStream() {\n        switch(this.status){\n            case COMPLETE:\n            case INTERRUPTED:\n                const chunksByPhase = this.chunksByPhase;\n                const trailingChunks = this.trailingChunks;\n                return new ReadableStream({\n                    start (controller) {\n                        for(let i = 0; i < chunksByPhase.length; i++){\n                            const chunks = chunksByPhase[i];\n                            for(let j = 0; j < chunks.length; j++){\n                                controller.enqueue(chunks[j]);\n                            }\n                        }\n                        for(let i = 0; i < trailingChunks.length; i++){\n                            controller.enqueue(trailingChunks[i]);\n                        }\n                        controller.close();\n                    }\n                });\n            default:\n                throw Object.defineProperty(new InvariantError(`ServerPrerenderStreamResult cannot be consumed as a stream because it is not yet complete. status: ${this.status}`), \"__NEXT_ERROR_CODE\", {\n                    value: \"E612\",\n                    enumerable: false,\n                    configurable: true\n                });\n        }\n    }\n}\nclass PhasedStream extends ReadableStream {\n    constructor(chunksByPhase){\n        if (chunksByPhase.length === 0) {\n            throw Object.defineProperty(new InvariantError('PhasedStream expected at least one phase but none were found.'), \"__NEXT_ERROR_CODE\", {\n                value: \"E574\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        let destination;\n        super({\n            start (controller) {\n                destination = controller;\n            }\n        });\n        // the start function above is called synchronously during construction so we will always have a destination\n        // We wait to assign it until after the super call because we cannot access `this` before calling super\n        this.destination = destination;\n        this.nextPhase = 0;\n        this.chunksByPhase = chunksByPhase;\n        this.releasePhase();\n    }\n    releasePhase() {\n        if (this.nextPhase < this.chunksByPhase.length) {\n            const chunks = this.chunksByPhase[this.nextPhase++];\n            for(let i = 0; i < chunks.length; i++){\n                this.destination.enqueue(chunks[i]);\n            }\n        } else {\n            throw Object.defineProperty(new InvariantError('PhasedStream expected more phases to release but none were found.'), \"__NEXT_ERROR_CODE\", {\n                value: \"E541\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n    }\n    assertExhausted() {\n        if (this.nextPhase < this.chunksByPhase.length) {\n            throw Object.defineProperty(new InvariantError('PhasedStream expected no more phases to release but some were found.'), \"__NEXT_ERROR_CODE\", {\n                value: \"E584\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n    }\n}\nexport function prerenderClientWithPhases(render, ...remainingPhases) {\n    if (process.env.NEXT_RUNTIME === 'edge') {\n        throw Object.defineProperty(new InvariantError('`prerenderAndAbortInSequentialTasks` should not be called in edge runtime.'), \"__NEXT_ERROR_CODE\", {\n            value: \"E538\",\n            enumerable: false,\n            configurable: true\n        });\n    } else {\n        return new Promise((resolve, reject)=>{\n            let pendingResult;\n            setImmediate(()=>{\n                try {\n                    pendingResult = render();\n                    pendingResult.catch((err)=>reject(err));\n                } catch (err) {\n                    reject(err);\n                }\n            });\n            function runFinalTask() {\n                try {\n                    this();\n                    resolve(pendingResult);\n                } catch (err) {\n                    reject(err);\n                }\n            }\n            function runNextTask() {\n                try {\n                    this();\n                } catch (err) {\n                    reject(err);\n                }\n            }\n            let i = 0;\n            for(; i < remainingPhases.length - 1; i++){\n                const phase = remainingPhases[i];\n                setImmediate(runNextTask.bind(phase));\n            }\n            if (remainingPhases[i]) {\n                const finalPhase = remainingPhases[i];\n                setImmediate(runFinalTask.bind(finalPhase));\n            }\n        });\n    }\n}\n// React's RSC prerender function will emit an incomplete flight stream when using `prerender`. If the connection\n// closes then whatever hanging chunks exist will be errored. This is because prerender (an experimental feature)\n// has not yet implemented a concept of resume. For now we will simulate a paused connection by wrapping the stream\n// in one that doesn't close even when the underlying is complete.\nexport class ReactServerResult {\n    constructor(stream){\n        this._stream = stream;\n    }\n    tee() {\n        if (this._stream === null) {\n            throw Object.defineProperty(new Error('Cannot tee a ReactServerResult that has already been consumed'), \"__NEXT_ERROR_CODE\", {\n                value: \"E106\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        const tee = this._stream.tee();\n        this._stream = tee[0];\n        return tee[1];\n    }\n    consume() {\n        if (this._stream === null) {\n            throw Object.defineProperty(new Error('Cannot consume a ReactServerResult that has already been consumed'), \"__NEXT_ERROR_CODE\", {\n                value: \"E470\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        const stream = this._stream;\n        this._stream = null;\n        return stream;\n    }\n}\nexport async function createReactServerPrerenderResult(underlying) {\n    const chunks = [];\n    const { prelude } = await underlying;\n    const reader = prelude.getReader();\n    while(true){\n        const { done, value } = await reader.read();\n        if (done) {\n            return new ReactServerPrerenderResult(chunks);\n        } else {\n            chunks.push(value);\n        }\n    }\n}\nexport async function createReactServerPrerenderResultFromRender(underlying) {\n    const chunks = [];\n    const reader = underlying.getReader();\n    while(true){\n        const { done, value } = await reader.read();\n        if (done) {\n            break;\n        } else {\n            chunks.push(value);\n        }\n    }\n    return new ReactServerPrerenderResult(chunks);\n}\nexport class ReactServerPrerenderResult {\n    assertChunks(expression) {\n        if (this._chunks === null) {\n            throw Object.defineProperty(new InvariantError(`Cannot \\`${expression}\\` on a ReactServerPrerenderResult that has already been consumed.`), \"__NEXT_ERROR_CODE\", {\n                value: \"E593\",\n                enumerable: false,\n                configurable: true\n            });\n        }\n        return this._chunks;\n    }\n    consumeChunks(expression) {\n        const chunks = this.assertChunks(expression);\n        this.consume();\n        return chunks;\n    }\n    consume() {\n        this._chunks = null;\n    }\n    constructor(chunks){\n        this._chunks = chunks;\n    }\n    asUnclosingStream() {\n        const chunks = this.assertChunks('asUnclosingStream()');\n        return createUnclosingStream(chunks);\n    }\n    consumeAsUnclosingStream() {\n        const chunks = this.consumeChunks('consumeAsUnclosingStream()');\n        return createUnclosingStream(chunks);\n    }\n    asStream() {\n        const chunks = this.assertChunks('asStream()');\n        return createClosingStream(chunks);\n    }\n    consumeAsStream() {\n        const chunks = this.consumeChunks('consumeAsStream()');\n        return createClosingStream(chunks);\n    }\n}\nfunction createUnclosingStream(chunks) {\n    let i = 0;\n    return new ReadableStream({\n        async pull (controller) {\n            if (i < chunks.length) {\n                controller.enqueue(chunks[i++]);\n            }\n        // we intentionally keep the stream open. The consumer will clear\n        // out chunks once finished and the remaining memory will be GC'd\n        // when this object goes out of scope\n        }\n    });\n}\nfunction createClosingStream(chunks) {\n    let i = 0;\n    return new ReadableStream({\n        async pull (controller) {\n            if (i < chunks.length) {\n                controller.enqueue(chunks[i++]);\n            } else {\n                controller.close();\n            }\n        }\n    });\n}\n\n//# sourceMappingURL=app-render-prerender-utils.js.map"
        }
    ]
}