{
    "sourceFile": "node_modules/next/dist/esm/server/lib/dedupe-fetch.js",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1746892830285,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1746891704042,
            "name": "cart",
            "content": "/**\n * Based on https://github.com/facebook/react/blob/d4e78c42a94be027b4dc7ed2659a5fddfbf9bd4e/packages/react/src/ReactFetch.js\n */ import * as React from 'react';\nimport { cloneResponse } from './clone-response';\nimport { InvariantError } from '../../shared/lib/invariant-error';\nconst simpleCacheKey = '[\"GET\",[],null,\"follow\",null,null,null,null]' // generateCacheKey(new Request('https://blank'));\n;\nfunction generateCacheKey(request) {\n    // We pick the fields that goes into the key used to dedupe requests.\n    // We don't include the `cache` field, because we end up using whatever\n    // caching resulted from the first request.\n    // Notably we currently don't consider non-standard (or future) options.\n    // This might not be safe. TODO: warn for non-standard extensions differing.\n    // IF YOU CHANGE THIS UPDATE THE simpleCacheKey ABOVE.\n    return JSON.stringify([\n        request.method,\n        Array.from(request.headers.entries()),\n        request.mode,\n        request.redirect,\n        request.credentials,\n        request.referrer,\n        request.referrerPolicy,\n        request.integrity\n    ]);\n}\nexport function createDedupeFetch(originalFetch) {\n    const getCacheEntries = React.cache(// eslint-disable-next-line @typescript-eslint/no-unused-vars -- url is the cache key\n    (url)=>[]);\n    return function dedupeFetch(resource, options) {\n        if (options && options.signal) {\n            // If we're passed a signal, then we assume that\n            // someone else controls the lifetime of this object and opts out of\n            // caching. It's effectively the opt-out mechanism.\n            // Ideally we should be able to check this on the Request but\n            // it always gets initialized with its own signal so we don't\n            // know if it's supposed to override - unless we also override the\n            // Request constructor.\n            return originalFetch(resource, options);\n        }\n        // Normalize the Request\n        let url;\n        let cacheKey;\n        if (typeof resource === 'string' && !options) {\n            // Fast path.\n            cacheKey = simpleCacheKey;\n            url = resource;\n        } else {\n            // Normalize the request.\n            // if resource is not a string or a URL (its an instance of Request)\n            // then do not instantiate a new Request but instead\n            // reuse the request as to not disturb the body in the event it's a ReadableStream.\n            const request = typeof resource === 'string' || resource instanceof URL ? new Request(resource, options) : resource;\n            if (request.method !== 'GET' && request.method !== 'HEAD' || request.keepalive) {\n                // We currently don't dedupe requests that might have side-effects. Those\n                // have to be explicitly cached. We assume that the request doesn't have a\n                // body if it's GET or HEAD.\n                // keepalive gets treated the same as if you passed a custom cache signal.\n                return originalFetch(resource, options);\n            }\n            cacheKey = generateCacheKey(request);\n            url = request.url;\n        }\n        const cacheEntries = getCacheEntries(url);\n        for(let i = 0, j = cacheEntries.length; i < j; i += 1){\n            const [key, promise] = cacheEntries[i];\n            if (key === cacheKey) {\n                return promise.then(()=>{\n                    const response = cacheEntries[i][2];\n                    if (!response) throw Object.defineProperty(new InvariantError('No cached response'), \"__NEXT_ERROR_CODE\", {\n                        value: \"E579\",\n                        enumerable: false,\n                        configurable: true\n                    });\n                    // We're cloning the response using this utility because there exists\n                    // a bug in the undici library around response cloning. See the\n                    // following pull request for more details:\n                    // https://github.com/vercel/next.js/pull/73274\n                    const [cloned1, cloned2] = cloneResponse(response);\n                    cacheEntries[i][2] = cloned2;\n                    return cloned1;\n                });\n            }\n        }\n        // We pass the original arguments here in case normalizing the Request\n        // doesn't include all the options in this environment.\n        const promise = originalFetch(resource, options);\n        const entry = [\n            cacheKey,\n            promise,\n            null\n        ];\n        cacheEntries.push(entry);\n        return promise.then((response)=>{\n            // We're cloning the response using this utility because there exists\n            // a bug in the undici library around response cloning. See the\n            // following pull request for more details:\n            // https://github.com/vercel/next.js/pull/73274\n            const [cloned1, cloned2] = cloneResponse(response);\n            entry[2] = cloned2;\n            return cloned1;\n        });\n    };\n}\n\n//# sourceMappingURL=dedupe-fetch.js.map"
        }
    ]
}