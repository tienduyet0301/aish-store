{
    "sourceFile": "node_modules/next/dist/esm/client/components/segment-cache-impl/cache.js",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1746892784347,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1746891704042,
            "name": "cart",
            "content": "import { NEXT_DID_POSTPONE_HEADER, NEXT_ROUTER_PREFETCH_HEADER, NEXT_ROUTER_SEGMENT_PREFETCH_HEADER, NEXT_ROUTER_STALE_TIME_HEADER, NEXT_ROUTER_STATE_TREE_HEADER, NEXT_URL, RSC_CONTENT_TYPE_HEADER, RSC_HEADER } from '../app-router-headers';\nimport { createFetch, createFromNextReadableStream } from '../router-reducer/fetch-server-response';\nimport { pingPrefetchTask } from './scheduler';\nimport { getAppBuildId } from '../../app-build-id';\nimport { createHrefFromUrl } from '../router-reducer/create-href-from-url';\nimport { createTupleMap } from './tuple-map';\nimport { createLRU } from './lru';\nimport { convertSegmentPathToStaticExportFilename, encodeChildSegmentKey, encodeSegment, ROOT_SEGMENT_KEY } from '../../../shared/lib/segment-cache/segment-value-encoding';\nimport { normalizeFlightData } from '../../flight-data-helpers';\nimport { STATIC_STALETIME_MS } from '../router-reducer/prefetch-cache-utils';\nimport { pingVisibleLinks } from '../links';\nimport { PAGE_SEGMENT_KEY } from '../../../shared/lib/segment';\n/**\n * Tracks the status of a cache entry as it progresses from no data (Empty),\n * waiting for server data (Pending), and finished (either Fulfilled or\n * Rejected depending on the response from the server.\n */ export var EntryStatus = /*#__PURE__*/ function(EntryStatus) {\n    EntryStatus[EntryStatus[\"Empty\"] = 0] = \"Empty\";\n    EntryStatus[EntryStatus[\"Pending\"] = 1] = \"Pending\";\n    EntryStatus[EntryStatus[\"Fulfilled\"] = 2] = \"Fulfilled\";\n    EntryStatus[EntryStatus[\"Rejected\"] = 3] = \"Rejected\";\n    return EntryStatus;\n}({});\nexport var FetchStrategy = /*#__PURE__*/ function(FetchStrategy) {\n    FetchStrategy[FetchStrategy[\"PPR\"] = 0] = \"PPR\";\n    FetchStrategy[FetchStrategy[\"Full\"] = 1] = \"Full\";\n    FetchStrategy[FetchStrategy[\"LoadingBoundary\"] = 2] = \"LoadingBoundary\";\n    return FetchStrategy;\n}({});\nconst isOutputExportMode = process.env.NODE_ENV === 'production' && process.env.__NEXT_CONFIG_OUTPUT === 'export';\nlet routeCacheMap = createTupleMap();\n// We use an LRU for memory management. We must update this whenever we add or\n// remove a new cache entry, or when an entry changes size.\n// TODO: I chose the max size somewhat arbitrarily. Consider setting this based\n// on navigator.deviceMemory, or some other heuristic. We should make this\n// customizable via the Next.js config, too.\nconst maxRouteLruSize = 10 * 1024 * 1024 // 10 MB\n;\nlet routeCacheLru = createLRU(maxRouteLruSize, onRouteLRUEviction);\nlet segmentCacheMap = createTupleMap();\n// NOTE: Segments and Route entries are managed by separate LRUs. We could\n// combine them into a single LRU, but because they are separate types, we'd\n// need to wrap each one in an extra LRU node (to maintain monomorphism, at the\n// cost of additional memory).\nconst maxSegmentLruSize = 50 * 1024 * 1024 // 50 MB\n;\nlet segmentCacheLru = createLRU(maxSegmentLruSize, onSegmentLRUEviction);\n// Incrementing counter used to track cache invalidations.\nlet currentCacheVersion = 0;\nexport function getCurrentCacheVersion() {\n    return currentCacheVersion;\n}\n/**\n * Used to clear the client prefetch cache when a server action calls\n * revalidatePath or revalidateTag. Eventually we will support only clearing the\n * segments that were actually affected, but there's more work to be done on the\n * server before the client is able to do this correctly.\n */ export function revalidateEntireCache(nextUrl, tree) {\n    currentCacheVersion++;\n    // Clearing the cache also effectively rejects any pending requests, because\n    // when the response is received, it gets written into a cache entry that is\n    // no longer reachable.\n    // TODO: There's an exception to this case that we don't currently handle\n    // correctly: background revalidations. See note in `upsertSegmentEntry`.\n    routeCacheMap = createTupleMap();\n    routeCacheLru = createLRU(maxRouteLruSize, onRouteLRUEviction);\n    segmentCacheMap = createTupleMap();\n    segmentCacheLru = createLRU(maxSegmentLruSize, onSegmentLRUEviction);\n    // Prefetch all the currently visible links again, to re-fill the cache.\n    pingVisibleLinks(nextUrl, tree);\n}\nexport function readExactRouteCacheEntry(now, href, nextUrl) {\n    const keypath = nextUrl === null ? [\n        href\n    ] : [\n        href,\n        nextUrl\n    ];\n    const existingEntry = routeCacheMap.get(keypath);\n    if (existingEntry !== null) {\n        // Check if the entry is stale\n        if (existingEntry.staleAt > now) {\n            // Reuse the existing entry.\n            // Since this is an access, move the entry to the front of the LRU.\n            routeCacheLru.put(existingEntry);\n            return existingEntry;\n        } else {\n            // Evict the stale entry from the cache.\n            deleteRouteFromCache(existingEntry, keypath);\n        }\n    }\n    return null;\n}\nexport function readRouteCacheEntry(now, key) {\n    // First check if there's a non-intercepted entry. Most routes cannot be\n    // intercepted, so this is the common case.\n    const nonInterceptedEntry = readExactRouteCacheEntry(now, key.href, null);\n    if (nonInterceptedEntry !== null && !nonInterceptedEntry.couldBeIntercepted) {\n        // Found a match, and the route cannot be intercepted. We can reuse it.\n        return nonInterceptedEntry;\n    }\n    // There was no match. Check again but include the Next-Url this time.\n    return readExactRouteCacheEntry(now, key.href, key.nextUrl);\n}\nexport function getSegmentKeypathForTask(task, route, path) {\n    // When a prefetch includes dynamic data, the search params are included\n    // in the result, so we must include the search string in the segment\n    // cache key. (Note that this is true even if the search string is empty.)\n    //\n    // If we're fetching using PPR, we do not need to include the search params in\n    // the cache key, because the search params are treated as dynamic data. The\n    // cache entry is valid for all possible search param values.\n    const isDynamicTask = task.includeDynamicData || !route.isPPREnabled;\n    return isDynamicTask && path.endsWith('/' + PAGE_SEGMENT_KEY) ? [\n        path,\n        task.key.search\n    ] : [\n        path\n    ];\n}\nexport function readSegmentCacheEntry(now, routeCacheKey, path) {\n    if (!path.endsWith('/' + PAGE_SEGMENT_KEY)) {\n        // Fast path. Search params only exist on page segments.\n        return readExactSegmentCacheEntry(now, [\n            path\n        ]);\n    }\n    // Page segments may or may not contain search params. If they were prefetched\n    // using a dynamic request, then we will have an entry with search params.\n    // Check for that case first.\n    const entryWithSearchParams = readExactSegmentCacheEntry(now, [\n        path,\n        routeCacheKey.search\n    ]);\n    if (entryWithSearchParams !== null) {\n        return entryWithSearchParams;\n    }\n    // If we did not find an entry with the given search params, check for a\n    // \"fallback\" entry, where the search params are treated as dynamic data. This\n    // is the common case because PPR/static prerenders always treat search params\n    // as dynamic.\n    //\n    // See corresponding logic in `getSegmentKeypathForTask`.\n    const entryWithoutSearchParams = readExactSegmentCacheEntry(now, [\n        path\n    ]);\n    return entryWithoutSearchParams;\n}\nfunction readExactSegmentCacheEntry(now, keypath) {\n    const existingEntry = segmentCacheMap.get(keypath);\n    if (existingEntry !== null) {\n        // Check if the entry is stale\n        if (existingEntry.staleAt > now) {\n            // Reuse the existing entry.\n            // Since this is an access, move the entry to the front of the LRU.\n            segmentCacheLru.put(existingEntry);\n            return existingEntry;\n        } else {\n            // This is a stale entry.\n            const revalidatingEntry = existingEntry.revalidating;\n            if (revalidatingEntry !== null) {\n                // There's a revalidation in progress. Upsert it.\n                const upsertedEntry = upsertSegmentEntry(now, keypath, revalidatingEntry);\n                if (upsertedEntry !== null && upsertedEntry.staleAt > now) {\n                    // We can use the upserted revalidation entry.\n                    return upsertedEntry;\n                }\n            } else {\n                // Evict the stale entry from the cache.\n                deleteSegmentFromCache(existingEntry, keypath);\n            }\n        }\n    }\n    return null;\n}\nfunction readRevalidatingSegmentCacheEntry(now, owner) {\n    const existingRevalidation = owner.revalidating;\n    if (existingRevalidation !== null) {\n        if (existingRevalidation.staleAt > now) {\n            // There's already a revalidation in progress. Or a previous revalidation\n            // failed and it has not yet expired.\n            return existingRevalidation;\n        } else {\n            // Clear the stale revalidation from its owner.\n            clearRevalidatingSegmentFromOwner(owner);\n        }\n    }\n    return null;\n}\nexport function waitForSegmentCacheEntry(pendingEntry) {\n    // Because the entry is pending, there's already a in-progress request.\n    // Attach a promise to the entry that will resolve when the server responds.\n    let promiseWithResolvers = pendingEntry.promise;\n    if (promiseWithResolvers === null) {\n        promiseWithResolvers = pendingEntry.promise = createPromiseWithResolvers();\n    } else {\n    // There's already a promise we can use\n    }\n    return promiseWithResolvers.promise;\n}\n/**\n * Checks if an entry for a route exists in the cache. If so, it returns the\n * entry, If not, it adds an empty entry to the cache and returns it.\n */ export function readOrCreateRouteCacheEntry(now, task) {\n    const key = task.key;\n    const existingEntry = readRouteCacheEntry(now, key);\n    if (existingEntry !== null) {\n        return existingEntry;\n    }\n    // Create a pending entry and add it to the cache.\n    const pendingEntry = {\n        canonicalUrl: null,\n        status: 0,\n        blockedTasks: null,\n        tree: null,\n        head: null,\n        isHeadPartial: true,\n        // Since this is an empty entry, there's no reason to ever evict it. It will\n        // be updated when the data is populated.\n        staleAt: Infinity,\n        // This is initialized to true because we don't know yet whether the route\n        // could be intercepted. It's only set to false once we receive a response\n        // from the server.\n        couldBeIntercepted: true,\n        // Similarly, we don't yet know if the route supports PPR.\n        isPPREnabled: false,\n        // LRU-related fields\n        keypath: null,\n        next: null,\n        prev: null,\n        size: 0\n    };\n    const keypath = key.nextUrl === null ? [\n        key.href\n    ] : [\n        key.href,\n        key.nextUrl\n    ];\n    routeCacheMap.set(keypath, pendingEntry);\n    // Stash the keypath on the entry so we know how to remove it from the map\n    // if it gets evicted from the LRU.\n    pendingEntry.keypath = keypath;\n    routeCacheLru.put(pendingEntry);\n    return pendingEntry;\n}\n/**\n * Checks if an entry for a segment exists in the cache. If so, it returns the\n * entry, If not, it adds an empty entry to the cache and returns it.\n */ export function readOrCreateSegmentCacheEntry(now, task, route, path) {\n    const keypath = getSegmentKeypathForTask(task, route, path);\n    const existingEntry = readExactSegmentCacheEntry(now, keypath);\n    if (existingEntry !== null) {\n        return existingEntry;\n    }\n    // Create a pending entry and add it to the cache.\n    const pendingEntry = createDetachedSegmentCacheEntry(route.staleAt);\n    segmentCacheMap.set(keypath, pendingEntry);\n    // Stash the keypath on the entry so we know how to remove it from the map\n    // if it gets evicted from the LRU.\n    pendingEntry.keypath = keypath;\n    segmentCacheLru.put(pendingEntry);\n    return pendingEntry;\n}\nexport function readOrCreateRevalidatingSegmentEntry(now, prevEntry) {\n    const existingRevalidation = readRevalidatingSegmentCacheEntry(now, prevEntry);\n    if (existingRevalidation !== null) {\n        return existingRevalidation;\n    }\n    const pendingEntry = createDetachedSegmentCacheEntry(prevEntry.staleAt);\n    // Background revalidations are not stored directly in the cache map or LRU;\n    // they're stashed on the entry that they will (potentially) replace.\n    //\n    // Note that we don't actually ever clear this field, except when the entry\n    // expires. When the revalidation finishes, one of two things will happen:\n    //\n    //  1) the revalidation is successful, `prevEntry` is removed from the cache\n    //     and garbage collected (so there's no point clearing any of its fields)\n    //  2) the revalidation fails, and we'll use the `revalidating` field to\n    //     prevent subsequent revalidation attempts, until it expires.\n    prevEntry.revalidating = pendingEntry;\n    return pendingEntry;\n}\nexport function upsertSegmentEntry(now, keypath, candidateEntry) {\n    // We have a new entry that has not yet been inserted into the cache. Before\n    // we do so, we need to confirm whether it takes precedence over the existing\n    // entry (if one exists).\n    // TODO: We should not upsert an entry if its key was invalidated in the time\n    // since the request was made. We can do that by passing the \"owner\" entry to\n    // this function and confirming it's the same as `existingEntry`.\n    const existingEntry = readExactSegmentCacheEntry(now, keypath);\n    if (existingEntry !== null) {\n        if (candidateEntry.isPartial && !existingEntry.isPartial) {\n            // Don't replace a full segment with a partial one. A case where this\n            // might happen is if the existing segment was fetched via\n            // <Link prefetch={true}>.\n            // We're going to leave the entry on the owner's `revalidating` field\n            // so that it doesn't get revalidated again unnecessarily. Downgrade the\n            // Fulfilled entry to Rejected and null out the data so it can be garbage\n            // collected. We leave `staleAt` intact to prevent subsequent revalidation\n            // attempts only until the entry expires.\n            const rejectedEntry = candidateEntry;\n            rejectedEntry.status = 3;\n            rejectedEntry.loading = null;\n            rejectedEntry.rsc = null;\n            return null;\n        }\n        // Evict the existing entry from the cache.\n        deleteSegmentFromCache(existingEntry, keypath);\n    }\n    segmentCacheMap.set(keypath, candidateEntry);\n    // Stash the keypath on the entry so we know how to remove it from the map\n    // if it gets evicted from the LRU.\n    candidateEntry.keypath = keypath;\n    segmentCacheLru.put(candidateEntry);\n    return candidateEntry;\n}\nexport function createDetachedSegmentCacheEntry(staleAt) {\n    const emptyEntry = {\n        status: 0,\n        // Default to assuming the fetch strategy will be PPR. This will be updated\n        // when a fetch is actually initiated.\n        fetchStrategy: 0,\n        revalidating: null,\n        rsc: null,\n        loading: null,\n        staleAt,\n        isPartial: true,\n        promise: null,\n        // LRU-related fields\n        keypath: null,\n        next: null,\n        prev: null,\n        size: 0\n    };\n    return emptyEntry;\n}\nexport function upgradeToPendingSegment(emptyEntry, fetchStrategy) {\n    const pendingEntry = emptyEntry;\n    pendingEntry.status = 1;\n    pendingEntry.fetchStrategy = fetchStrategy;\n    return pendingEntry;\n}\nfunction deleteRouteFromCache(entry, keypath) {\n    pingBlockedTasks(entry);\n    routeCacheMap.delete(keypath);\n    routeCacheLru.delete(entry);\n}\nfunction deleteSegmentFromCache(entry, keypath) {\n    cancelEntryListeners(entry);\n    segmentCacheMap.delete(keypath);\n    segmentCacheLru.delete(entry);\n    clearRevalidatingSegmentFromOwner(entry);\n}\nfunction clearRevalidatingSegmentFromOwner(owner) {\n    // Revalidating segments are not stored in the cache directly; they're\n    // stored as a field on the entry that they will (potentially) replace. So\n    // to dispose of an existing revalidation, we just need to null out the field\n    // on the owner.\n    const revalidatingSegment = owner.revalidating;\n    if (revalidatingSegment !== null) {\n        cancelEntryListeners(revalidatingSegment);\n        owner.revalidating = null;\n    }\n}\nexport function resetRevalidatingSegmentEntry(owner) {\n    clearRevalidatingSegmentFromOwner(owner);\n    const emptyEntry = createDetachedSegmentCacheEntry(owner.staleAt);\n    owner.revalidating = emptyEntry;\n    return emptyEntry;\n}\nfunction onRouteLRUEviction(entry) {\n    // The LRU evicted this entry. Remove it from the map.\n    const keypath = entry.keypath;\n    if (keypath !== null) {\n        entry.keypath = null;\n        pingBlockedTasks(entry);\n        routeCacheMap.delete(keypath);\n    }\n}\nfunction onSegmentLRUEviction(entry) {\n    // The LRU evicted this entry. Remove it from the map.\n    const keypath = entry.keypath;\n    if (keypath !== null) {\n        entry.keypath = null;\n        cancelEntryListeners(entry);\n        segmentCacheMap.delete(keypath);\n    }\n}\nfunction cancelEntryListeners(entry) {\n    if (entry.status === 1 && entry.promise !== null) {\n        // There were listeners for this entry. Resolve them with `null` to indicate\n        // that the prefetch failed. It's up to the listener to decide how to handle\n        // this case.\n        // NOTE: We don't currently propagate the reason the prefetch was canceled\n        // but we could by accepting a `reason` argument.\n        entry.promise.resolve(null);\n        entry.promise = null;\n    }\n}\nfunction pingBlockedTasks(entry) {\n    const blockedTasks = entry.blockedTasks;\n    if (blockedTasks !== null) {\n        for (const task of blockedTasks){\n            pingPrefetchTask(task);\n        }\n        entry.blockedTasks = null;\n    }\n}\nfunction fulfillRouteCacheEntry(entry, tree, head, isHeadPartial, staleAt, couldBeIntercepted, canonicalUrl, isPPREnabled) {\n    const fulfilledEntry = entry;\n    fulfilledEntry.status = 2;\n    fulfilledEntry.tree = tree;\n    fulfilledEntry.head = head;\n    fulfilledEntry.isHeadPartial = isHeadPartial;\n    fulfilledEntry.staleAt = staleAt;\n    fulfilledEntry.couldBeIntercepted = couldBeIntercepted;\n    fulfilledEntry.canonicalUrl = canonicalUrl;\n    fulfilledEntry.isPPREnabled = isPPREnabled;\n    pingBlockedTasks(entry);\n    return fulfilledEntry;\n}\nfunction fulfillSegmentCacheEntry(segmentCacheEntry, rsc, loading, staleAt, isPartial) {\n    const fulfilledEntry = segmentCacheEntry;\n    fulfilledEntry.status = 2;\n    fulfilledEntry.rsc = rsc;\n    fulfilledEntry.loading = loading;\n    fulfilledEntry.staleAt = staleAt;\n    fulfilledEntry.isPartial = isPartial;\n    // Resolve any listeners that were waiting for this data.\n    if (segmentCacheEntry.promise !== null) {\n        segmentCacheEntry.promise.resolve(fulfilledEntry);\n        // Free the promise for garbage collection.\n        fulfilledEntry.promise = null;\n    }\n    return fulfilledEntry;\n}\nfunction rejectRouteCacheEntry(entry, staleAt) {\n    const rejectedEntry = entry;\n    rejectedEntry.status = 3;\n    rejectedEntry.staleAt = staleAt;\n    pingBlockedTasks(entry);\n}\nfunction rejectSegmentCacheEntry(entry, staleAt) {\n    const rejectedEntry = entry;\n    rejectedEntry.status = 3;\n    rejectedEntry.staleAt = staleAt;\n    if (entry.promise !== null) {\n        // NOTE: We don't currently propagate the reason the prefetch was canceled\n        // but we could by accepting a `reason` argument.\n        entry.promise.resolve(null);\n        entry.promise = null;\n    }\n}\nfunction convertRootTreePrefetchToRouteTree(rootTree) {\n    return convertTreePrefetchToRouteTree(rootTree.tree, ROOT_SEGMENT_KEY);\n}\nfunction convertTreePrefetchToRouteTree(prefetch, key) {\n    // Converts the route tree sent by the server into the format used by the\n    // cache. The cached version of the tree includes additional fields, such as a\n    // cache key for each segment. Since this is frequently accessed, we compute\n    // it once instead of on every access. This same cache key is also used to\n    // request the segment from the server.\n    let slots = null;\n    const prefetchSlots = prefetch.slots;\n    if (prefetchSlots !== null) {\n        slots = {};\n        for(let parallelRouteKey in prefetchSlots){\n            const childPrefetch = prefetchSlots[parallelRouteKey];\n            const childSegment = childPrefetch.segment;\n            // TODO: Eventually, the param values will not be included in the response\n            // from the server. We'll instead fill them in on the client by parsing\n            // the URL. This is where we'll do that.\n            const childKey = encodeChildSegmentKey(key, parallelRouteKey, encodeSegment(childSegment));\n            slots[parallelRouteKey] = convertTreePrefetchToRouteTree(childPrefetch, childKey);\n        }\n    }\n    return {\n        key,\n        segment: prefetch.segment,\n        slots,\n        isRootLayout: prefetch.isRootLayout\n    };\n}\nfunction convertRootFlightRouterStateToRouteTree(flightRouterState) {\n    return convertFlightRouterStateToRouteTree(flightRouterState, ROOT_SEGMENT_KEY);\n}\nfunction convertFlightRouterStateToRouteTree(flightRouterState, key) {\n    let slots = null;\n    const parallelRoutes = flightRouterState[1];\n    for(let parallelRouteKey in parallelRoutes){\n        const childRouterState = parallelRoutes[parallelRouteKey];\n        const childSegment = childRouterState[0];\n        // TODO: Eventually, the param values will not be included in the response\n        // from the server. We'll instead fill them in on the client by parsing\n        // the URL. This is where we'll do that.\n        const childKey = encodeChildSegmentKey(key, parallelRouteKey, encodeSegment(childSegment));\n        const childTree = convertFlightRouterStateToRouteTree(childRouterState, childKey);\n        if (slots === null) {\n            slots = {\n                [parallelRouteKey]: childTree\n            };\n        } else {\n            slots[parallelRouteKey] = childTree;\n        }\n    }\n    // The navigation implementation expects the search params to be included\n    // in the segment. However, in the case of a static response, the search\n    // params are omitted. So the client needs to add them back in when reading\n    // from the Segment Cache.\n    //\n    // For consistency, we'll do this for dynamic responses, too.\n    //\n    // TODO: We should move search params out of FlightRouterState and handle them\n    // entirely on the client, similar to our plan for dynamic params.\n    const originalSegment = flightRouterState[0];\n    const segmentWithoutSearchParams = typeof originalSegment === 'string' && originalSegment.startsWith(PAGE_SEGMENT_KEY) ? PAGE_SEGMENT_KEY : originalSegment;\n    return {\n        key,\n        segment: segmentWithoutSearchParams,\n        slots,\n        isRootLayout: flightRouterState[4] === true\n    };\n}\nexport function convertRouteTreeToFlightRouterState(routeTree) {\n    const parallelRoutes = {};\n    if (routeTree.slots !== null) {\n        for(const parallelRouteKey in routeTree.slots){\n            parallelRoutes[parallelRouteKey] = convertRouteTreeToFlightRouterState(routeTree.slots[parallelRouteKey]);\n        }\n    }\n    const flightRouterState = [\n        routeTree.segment,\n        parallelRoutes,\n        null,\n        null,\n        routeTree.isRootLayout\n    ];\n    return flightRouterState;\n}\nexport async function fetchRouteOnCacheMiss(entry, task) {\n    // This function is allowed to use async/await because it contains the actual\n    // fetch that gets issued on a cache miss. Notice it writes the result to the\n    // cache entry directly, rather than return data that is then written by\n    // the caller.\n    const key = task.key;\n    const href = key.href;\n    const nextUrl = key.nextUrl;\n    const segmentPath = '/_tree';\n    const headers = {\n        [RSC_HEADER]: '1',\n        [NEXT_ROUTER_PREFETCH_HEADER]: '1',\n        [NEXT_ROUTER_SEGMENT_PREFETCH_HEADER]: segmentPath\n    };\n    if (nextUrl !== null) {\n        headers[NEXT_URL] = nextUrl;\n    }\n    // In output: \"export\" mode, we need to add the segment path to the URL.\n    const url = new URL(href);\n    const requestUrl = isOutputExportMode ? addSegmentPathToUrlInOutputExportMode(url, segmentPath) : url;\n    try {\n        const response = await fetchPrefetchResponse(requestUrl, headers);\n        if (!response || !response.ok || // 204 is a Cache miss. Though theoretically this shouldn't happen when\n        // PPR is enabled, because we always respond to route tree requests, even\n        // if it needs to be blockingly generated on demand.\n        response.status === 204 || !response.body) {\n            // Server responded with an error, or with a miss. We should still cache\n            // the response, but we can try again after 10 seconds.\n            rejectRouteCacheEntry(entry, Date.now() + 10 * 1000);\n            return null;\n        }\n        // TODO: The canonical URL is the href without the origin. I think\n        // historically the reason for this is because the initial canonical URL\n        // gets passed as a prop to the top-level React component, which means it\n        // needs to be computed during SSR. If it were to include the origin, it\n        // would need to always be same as location.origin on the client, to prevent\n        // a hydration mismatch. To sidestep this complexity, we omit the origin.\n        //\n        // However, since this is neither a native URL object nor a fully qualified\n        // URL string, we need to be careful about how we use it. To prevent subtle\n        // mistakes, we should create a special type for it, instead of just string.\n        // Or, we should just use a (readonly) URL object instead. The type of the\n        // prop that we pass to seed the initial state does not need to be the same\n        // type as the state itself.\n        const canonicalUrl = createHrefFromUrl(new URL(response.redirected ? removeSegmentPathFromURLInOutputExportMode(href, requestUrl.href, response.url) : href));\n        // Check whether the response varies based on the Next-Url header.\n        const varyHeader = response.headers.get('vary');\n        const couldBeIntercepted = varyHeader !== null && varyHeader.includes(NEXT_URL);\n        // Track when the network connection closes.\n        const closed = createPromiseWithResolvers();\n        // This checks whether the response was served from the per-segment cache,\n        // rather than the old prefetching flow. If it fails, it implies that PPR\n        // is disabled on this route.\n        const routeIsPPREnabled = response.headers.get(NEXT_DID_POSTPONE_HEADER) === '2' || // In output: \"export\" mode, we can't rely on response headers. But if we\n        // receive a well-formed response, we can assume it's a static response,\n        // because all data is static in this mode.\n        isOutputExportMode;\n        if (routeIsPPREnabled) {\n            const prefetchStream = createPrefetchResponseStream(response.body, closed.resolve, function onResponseSizeUpdate(size) {\n                routeCacheLru.updateSize(entry, size);\n            });\n            const serverData = await createFromNextReadableStream(prefetchStream);\n            if (serverData.buildId !== getAppBuildId()) {\n                // The server build does not match the client. Treat as a 404. During\n                // an actual navigation, the router will trigger an MPA navigation.\n                // TODO: Consider moving the build ID to a response header so we can check\n                // it before decoding the response, and so there's one way of checking\n                // across all response types.\n                rejectRouteCacheEntry(entry, Date.now() + 10 * 1000);\n                return null;\n            }\n            const staleTimeMs = serverData.staleTime * 1000;\n            fulfillRouteCacheEntry(entry, convertRootTreePrefetchToRouteTree(serverData), serverData.head, serverData.isHeadPartial, Date.now() + staleTimeMs, couldBeIntercepted, canonicalUrl, routeIsPPREnabled);\n        } else {\n            // PPR is not enabled for this route. The server responds with a\n            // different format (FlightRouterState) that we need to convert.\n            // TODO: We will unify the responses eventually. I'm keeping the types\n            // separate for now because FlightRouterState has so many\n            // overloaded concerns.\n            const prefetchStream = createPrefetchResponseStream(response.body, closed.resolve, function onResponseSizeUpdate(size) {\n                routeCacheLru.updateSize(entry, size);\n            });\n            const serverData = await createFromNextReadableStream(prefetchStream);\n            writeDynamicTreeResponseIntoCache(Date.now(), task, response, serverData, entry, couldBeIntercepted, canonicalUrl, routeIsPPREnabled);\n        }\n        if (!couldBeIntercepted && nextUrl !== null) {\n            // This route will never be intercepted. So we can use this entry for all\n            // requests to this route, regardless of the Next-Url header. This works\n            // because when reading the cache we always check for a valid\n            // non-intercepted entry first.\n            //\n            // Re-key the entry. Since we're in an async task, we must first confirm\n            // that the entry hasn't been concurrently modified by a different task.\n            const currentKeypath = [\n                href,\n                nextUrl\n            ];\n            const expectedEntry = routeCacheMap.get(currentKeypath);\n            if (expectedEntry === entry) {\n                routeCacheMap.delete(currentKeypath);\n                const newKeypath = [\n                    href\n                ];\n                routeCacheMap.set(newKeypath, entry);\n                // We don't need to update the LRU because the entry is already in it.\n                // But since we changed the keypath, we do need to update that, so we\n                // know how to remove it from the map if it gets evicted from the LRU.\n                entry.keypath = newKeypath;\n            } else {\n            // Something else modified this entry already. Since the re-keying is\n            // just a performance optimization, we can safely skip it.\n            }\n        }\n        // Return a promise that resolves when the network connection closes, so\n        // the scheduler can track the number of concurrent network connections.\n        return {\n            value: null,\n            closed: closed.promise\n        };\n    } catch (error) {\n        // Either the connection itself failed, or something bad happened while\n        // decoding the response.\n        rejectRouteCacheEntry(entry, Date.now() + 10 * 1000);\n        return null;\n    }\n}\nexport async function fetchSegmentOnCacheMiss(route, segmentCacheEntry, routeKey, segmentPath) {\n    // This function is allowed to use async/await because it contains the actual\n    // fetch that gets issued on a cache miss. Notice it writes the result to the\n    // cache entry directly, rather than return data that is then written by\n    // the caller.\n    //\n    // Segment fetches are non-blocking so we don't need to ping the scheduler\n    // on completion.\n    // Use the canonical URL to request the segment, not the original URL. These\n    // are usually the same, but the canonical URL will be different if the route\n    // tree response was redirected. To avoid an extra waterfall on every segment\n    // request, we pass the redirected URL instead of the original one.\n    const url = new URL(route.canonicalUrl, routeKey.href);\n    const nextUrl = routeKey.nextUrl;\n    const normalizedSegmentPath = segmentPath === ROOT_SEGMENT_KEY ? // handling of these requests, we encode the root segment path as\n    // `_index` instead of as an empty string. This should be treated as\n    // an implementation detail and not as a stable part of the protocol.\n    // It just needs to match the equivalent logic that happens when\n    // prerendering the responses. It should not leak outside of Next.js.\n    '/_index' : segmentPath;\n    const headers = {\n        [RSC_HEADER]: '1',\n        [NEXT_ROUTER_PREFETCH_HEADER]: '1',\n        [NEXT_ROUTER_SEGMENT_PREFETCH_HEADER]: normalizedSegmentPath\n    };\n    if (nextUrl !== null) {\n        headers[NEXT_URL] = nextUrl;\n    }\n    const requestUrl = isOutputExportMode ? addSegmentPathToUrlInOutputExportMode(url, normalizedSegmentPath) : url;\n    try {\n        const response = await fetchPrefetchResponse(requestUrl, headers);\n        if (!response || !response.ok || response.status === 204 || // Cache miss\n        // This checks whether the response was served from the per-segment cache,\n        // rather than the old prefetching flow. If it fails, it implies that PPR\n        // is disabled on this route. Theoretically this should never happen\n        // because we only issue requests for segments once we've verified that\n        // the route supports PPR.\n        response.headers.get(NEXT_DID_POSTPONE_HEADER) !== '2' && // In output: \"export\" mode, we can't rely on response headers. But if\n        // we receive a well-formed response, we can assume it's a static\n        // response, because all data is static in this mode.\n        !isOutputExportMode || !response.body) {\n            // Server responded with an error, or with a miss. We should still cache\n            // the response, but we can try again after 10 seconds.\n            rejectSegmentCacheEntry(segmentCacheEntry, Date.now() + 10 * 1000);\n            return null;\n        }\n        // Track when the network connection closes.\n        const closed = createPromiseWithResolvers();\n        // Wrap the original stream in a new stream that never closes. That way the\n        // Flight client doesn't error if there's a hanging promise.\n        const prefetchStream = createPrefetchResponseStream(response.body, closed.resolve, function onResponseSizeUpdate(size) {\n            segmentCacheLru.updateSize(segmentCacheEntry, size);\n        });\n        const serverData = await createFromNextReadableStream(prefetchStream);\n        if (serverData.buildId !== getAppBuildId()) {\n            // The server build does not match the client. Treat as a 404. During\n            // an actual navigation, the router will trigger an MPA navigation.\n            // TODO: Consider moving the build ID to a response header so we can check\n            // it before decoding the response, and so there's one way of checking\n            // across all response types.\n            rejectSegmentCacheEntry(segmentCacheEntry, Date.now() + 10 * 1000);\n            return null;\n        }\n        return {\n            value: fulfillSegmentCacheEntry(segmentCacheEntry, serverData.rsc, serverData.loading, // TODO: The server does not currently provide per-segment stale time.\n            // So we use the stale time of the route.\n            route.staleAt, serverData.isPartial),\n            // Return a promise that resolves when the network connection closes, so\n            // the scheduler can track the number of concurrent network connections.\n            closed: closed.promise\n        };\n    } catch (error) {\n        // Either the connection itself failed, or something bad happened while\n        // decoding the response.\n        rejectSegmentCacheEntry(segmentCacheEntry, Date.now() + 10 * 1000);\n        return null;\n    }\n}\nexport async function fetchSegmentPrefetchesUsingDynamicRequest(task, route, fetchStrategy, dynamicRequestTree, spawnedEntries) {\n    const url = new URL(route.canonicalUrl, task.key.href);\n    const nextUrl = task.key.nextUrl;\n    const headers = {\n        [RSC_HEADER]: '1',\n        [NEXT_ROUTER_STATE_TREE_HEADER]: encodeURIComponent(JSON.stringify(dynamicRequestTree))\n    };\n    if (nextUrl !== null) {\n        headers[NEXT_URL] = nextUrl;\n    }\n    // Only set the prefetch header if we're not doing a \"full\" prefetch. We\n    // omit the prefetch header from a full prefetch because it's essentially\n    // just a navigation request that happens ahead of time — it should include\n    // all the same data in the response.\n    if (fetchStrategy !== 1) {\n        headers[NEXT_ROUTER_PREFETCH_HEADER] = '1';\n    }\n    try {\n        const response = await fetchPrefetchResponse(url, headers);\n        if (!response || !response.ok || !response.body) {\n            // Server responded with an error, or with a miss. We should still cache\n            // the response, but we can try again after 10 seconds.\n            rejectSegmentEntriesIfStillPending(spawnedEntries, Date.now() + 10 * 1000);\n            return null;\n        }\n        // Track when the network connection closes.\n        const closed = createPromiseWithResolvers();\n        let fulfilledEntries = null;\n        const prefetchStream = createPrefetchResponseStream(response.body, closed.resolve, function onResponseSizeUpdate(totalBytesReceivedSoFar) {\n            // When processing a dynamic response, we don't know how large each\n            // individual segment is, so approximate by assiging each segment\n            // the average of the total response size.\n            if (fulfilledEntries === null) {\n                // Haven't received enough data yet to know which segments\n                // were included.\n                return;\n            }\n            const averageSize = totalBytesReceivedSoFar / fulfilledEntries.length;\n            for (const entry of fulfilledEntries){\n                segmentCacheLru.updateSize(entry, averageSize);\n            }\n        });\n        const serverData = await createFromNextReadableStream(prefetchStream);\n        // Since we did not set the prefetch header, the response from the server\n        // will never contain dynamic holes.\n        const isResponsePartial = false;\n        // Aside from writing the data into the cache, this function also returns\n        // the entries that were fulfilled, so we can streamingly update their sizes\n        // in the LRU as more data comes in.\n        fulfilledEntries = writeDynamicRenderResponseIntoCache(Date.now(), task, response, serverData, isResponsePartial, route, spawnedEntries);\n        // Return a promise that resolves when the network connection closes, so\n        // the scheduler can track the number of concurrent network connections.\n        return {\n            value: null,\n            closed: closed.promise\n        };\n    } catch (error) {\n        rejectSegmentEntriesIfStillPending(spawnedEntries, Date.now() + 10 * 1000);\n        return null;\n    }\n}\nfunction writeDynamicTreeResponseIntoCache(now, task, response, serverData, entry, couldBeIntercepted, canonicalUrl, routeIsPPREnabled) {\n    if (serverData.b !== getAppBuildId()) {\n        // The server build does not match the client. Treat as a 404. During\n        // an actual navigation, the router will trigger an MPA navigation.\n        // TODO: Consider moving the build ID to a response header so we can check\n        // it before decoding the response, and so there's one way of checking\n        // across all response types.\n        rejectRouteCacheEntry(entry, now + 10 * 1000);\n        return;\n    }\n    const normalizedFlightDataResult = normalizeFlightData(serverData.f);\n    if (// A string result means navigating to this route will result in an\n    // MPA navigation.\n    typeof normalizedFlightDataResult === 'string' || normalizedFlightDataResult.length !== 1) {\n        rejectRouteCacheEntry(entry, now + 10 * 1000);\n        return;\n    }\n    const flightData = normalizedFlightDataResult[0];\n    if (!flightData.isRootRender) {\n        // Unexpected response format.\n        rejectRouteCacheEntry(entry, now + 10 * 1000);\n        return;\n    }\n    const flightRouterState = flightData.tree;\n    // TODO: Extract to function\n    const staleTimeHeaderSeconds = response.headers.get(NEXT_ROUTER_STALE_TIME_HEADER);\n    const staleTimeMs = staleTimeHeaderSeconds !== null ? parseInt(staleTimeHeaderSeconds, 10) * 1000 : STATIC_STALETIME_MS;\n    // If the response contains dynamic holes, then we must conservatively assume\n    // that any individual segment might contain dynamic holes, and also the\n    // head. If it did not contain dynamic holes, then we can assume every segment\n    // and the head is completely static.\n    const isResponsePartial = response.headers.get(NEXT_DID_POSTPONE_HEADER) === '1';\n    const fulfilledEntry = fulfillRouteCacheEntry(entry, convertRootFlightRouterStateToRouteTree(flightRouterState), flightData.head, isResponsePartial, now + staleTimeMs, couldBeIntercepted, canonicalUrl, routeIsPPREnabled);\n    // If the server sent segment data as part of the response, we should write\n    // it into the cache to prevent a second, redundant prefetch request.\n    //\n    // TODO: When `clientSegmentCache` is enabled, the server does not include\n    // segment data when responding to a route tree prefetch request. However,\n    // when `clientSegmentCache` is set to \"client-only\", and PPR is enabled (or\n    // the page is fully static), the normal check is bypassed and the server\n    // responds with the full page. This is a temporary situation until we can\n    // remove the \"client-only\" option. Then, we can delete this function call.\n    writeDynamicRenderResponseIntoCache(now, task, response, serverData, isResponsePartial, fulfilledEntry, null);\n}\nfunction rejectSegmentEntriesIfStillPending(entries, staleAt) {\n    const fulfilledEntries = [];\n    for (const entry of entries.values()){\n        if (entry.status === 1) {\n            rejectSegmentCacheEntry(entry, staleAt);\n        } else if (entry.status === 2) {\n            fulfilledEntries.push(entry);\n        }\n    }\n    return fulfilledEntries;\n}\nfunction writeDynamicRenderResponseIntoCache(now, task, response, serverData, isResponsePartial, route, spawnedEntries) {\n    if (serverData.b !== getAppBuildId()) {\n        // The server build does not match the client. Treat as a 404. During\n        // an actual navigation, the router will trigger an MPA navigation.\n        // TODO: Consider moving the build ID to a response header so we can check\n        // it before decoding the response, and so there's one way of checking\n        // across all response types.\n        if (spawnedEntries !== null) {\n            rejectSegmentEntriesIfStillPending(spawnedEntries, now + 10 * 1000);\n        }\n        return null;\n    }\n    const flightDatas = normalizeFlightData(serverData.f);\n    if (typeof flightDatas === 'string') {\n        // This means navigating to this route will result in an MPA navigation.\n        // TODO: We should cache this, too, so that the MPA navigation is immediate.\n        return null;\n    }\n    for (const flightData of flightDatas){\n        const seedData = flightData.seedData;\n        if (seedData !== null) {\n            // The data sent by the server represents only a subtree of the app. We\n            // need to find the part of the task tree that matches the response.\n            //\n            // segmentPath represents the parent path of subtree. It's a repeating\n            // pattern of parallel route key and segment:\n            //\n            //   [string, Segment, string, Segment, string, Segment, ...]\n            const segmentPath = flightData.segmentPath;\n            let segmentKey = ROOT_SEGMENT_KEY;\n            for(let i = 0; i < segmentPath.length; i += 2){\n                const parallelRouteKey = segmentPath[i];\n                const segment = segmentPath[i + 1];\n                segmentKey = encodeChildSegmentKey(segmentKey, parallelRouteKey, encodeSegment(segment));\n            }\n            const staleTimeHeaderSeconds = response.headers.get(NEXT_ROUTER_STALE_TIME_HEADER);\n            const staleTimeMs = staleTimeHeaderSeconds !== null ? parseInt(staleTimeHeaderSeconds, 10) * 1000 : STATIC_STALETIME_MS;\n            writeSeedDataIntoCache(now, task, route, now + staleTimeMs, seedData, isResponsePartial, segmentKey, spawnedEntries);\n        }\n    }\n    // Any entry that's still pending was intentionally not rendered by the\n    // server, because it was inside the loading boundary. Mark them as rejected\n    // so we know not to fetch them again.\n    // TODO: If PPR is enabled on some routes but not others, then it's possible\n    // that a different page is able to do a per-segment prefetch of one of the\n    // segments we're marking as rejected here. We should mark on the segment\n    // somehow that the reason for the rejection is because of a non-PPR prefetch.\n    // That way a per-segment prefetch knows to disregard the rejection.\n    if (spawnedEntries !== null) {\n        const fulfilledEntries = rejectSegmentEntriesIfStillPending(spawnedEntries, now + 10 * 1000);\n        return fulfilledEntries;\n    }\n    return null;\n}\nfunction writeSeedDataIntoCache(now, task, route, staleAt, seedData, isResponsePartial, key, entriesOwnedByCurrentTask) {\n    // This function is used to write the result of a dynamic server request\n    // (CacheNodeSeedData) into the prefetch cache. It's used in cases where we\n    // want to treat a dynamic response as if it were static. The two examples\n    // where this happens are <Link prefetch={true}> (which implicitly opts\n    // dynamic data into being static) and when prefetching a PPR-disabled route\n    const rsc = seedData[1];\n    const loading = seedData[3];\n    const isPartial = rsc === null || isResponsePartial;\n    // We should only write into cache entries that are owned by us. Or create\n    // a new one and write into that. We must never write over an entry that was\n    // created by a different task, because that causes data races.\n    const ownedEntry = entriesOwnedByCurrentTask !== null ? entriesOwnedByCurrentTask.get(key) : undefined;\n    if (ownedEntry !== undefined) {\n        fulfillSegmentCacheEntry(ownedEntry, rsc, loading, staleAt, isPartial);\n    } else {\n        // There's no matching entry. Attempt to create a new one.\n        const possiblyNewEntry = readOrCreateSegmentCacheEntry(now, task, route, key);\n        if (possiblyNewEntry.status === 0) {\n            // Confirmed this is a new entry. We can fulfill it.\n            const newEntry = possiblyNewEntry;\n            fulfillSegmentCacheEntry(newEntry, rsc, loading, staleAt, isPartial);\n        } else {\n            // There was already an entry in the cache. But we may be able to\n            // replace it with the new one from the server.\n            const newEntry = fulfillSegmentCacheEntry(createDetachedSegmentCacheEntry(staleAt), rsc, loading, staleAt, isPartial);\n            upsertSegmentEntry(now, getSegmentKeypathForTask(task, route, key), newEntry);\n        }\n    }\n    // Recursively write the child data into the cache.\n    const seedDataChildren = seedData[2];\n    if (seedDataChildren !== null) {\n        for(const parallelRouteKey in seedDataChildren){\n            const childSeedData = seedDataChildren[parallelRouteKey];\n            if (childSeedData !== null) {\n                const childSegment = childSeedData[0];\n                writeSeedDataIntoCache(now, task, route, staleAt, childSeedData, isResponsePartial, encodeChildSegmentKey(key, parallelRouteKey, encodeSegment(childSegment)), entriesOwnedByCurrentTask);\n            }\n        }\n    }\n}\nasync function fetchPrefetchResponse(url, headers) {\n    const fetchPriority = 'low';\n    const response = await createFetch(url, headers, fetchPriority);\n    if (!response.ok) {\n        return null;\n    }\n    // Check the content type\n    if (isOutputExportMode) {\n    // In output: \"export\" mode, we relaxed about the content type, since it's\n    // not Next.js that's serving the response. If the status is OK, assume the\n    // response is valid. If it's not a valid response, the Flight client won't\n    // be able to decode it, and we'll treat it as a miss.\n    } else {\n        const contentType = response.headers.get('content-type');\n        const isFlightResponse = contentType && contentType.startsWith(RSC_CONTENT_TYPE_HEADER);\n        if (!isFlightResponse) {\n            return null;\n        }\n    }\n    return response;\n}\nfunction createPrefetchResponseStream(originalFlightStream, onStreamClose, onResponseSizeUpdate) {\n    // When PPR is enabled, prefetch streams may contain references that never\n    // resolve, because that's how we encode dynamic data access. In the decoded\n    // object returned by the Flight client, these are reified into hanging\n    // promises that suspend during render, which is effectively what we want.\n    // The UI resolves when it switches to the dynamic data stream\n    // (via useDeferredValue(dynamic, static)).\n    //\n    // However, the Flight implementation currently errors if the server closes\n    // the response before all the references are resolved. As a cheat to work\n    // around this, we wrap the original stream in a new stream that never closes,\n    // and therefore doesn't error.\n    //\n    // While processing the original stream, we also incrementally update the size\n    // of the cache entry in the LRU.\n    let totalByteLength = 0;\n    const reader = originalFlightStream.getReader();\n    return new ReadableStream({\n        async pull (controller) {\n            while(true){\n                const { done, value } = await reader.read();\n                if (!done) {\n                    // Pass to the target stream and keep consuming the Flight response\n                    // from the server.\n                    controller.enqueue(value);\n                    // Incrementally update the size of the cache entry in the LRU.\n                    // NOTE: Since prefetch responses are delivered in a single chunk,\n                    // it's not really necessary to do this streamingly, but I'm doing it\n                    // anyway in case this changes in the future.\n                    totalByteLength += value.byteLength;\n                    onResponseSizeUpdate(totalByteLength);\n                    continue;\n                }\n                // The server stream has closed. Exit, but intentionally do not close\n                // the target stream. We do notify the caller, though.\n                onStreamClose();\n                return;\n            }\n        }\n    });\n}\nfunction addSegmentPathToUrlInOutputExportMode(url, segmentPath) {\n    if (isOutputExportMode) {\n        // In output: \"export\" mode, we cannot use a header to encode the segment\n        // path. Instead, we append it to the end of the pathname.\n        const staticUrl = new URL(url);\n        const routeDir = staticUrl.pathname.endsWith('/') ? staticUrl.pathname.substring(0, -1) : staticUrl.pathname;\n        const staticExportFilename = convertSegmentPathToStaticExportFilename(segmentPath);\n        staticUrl.pathname = routeDir + \"/\" + staticExportFilename;\n        return staticUrl;\n    }\n    return url;\n}\nfunction removeSegmentPathFromURLInOutputExportMode(href, requestUrl, redirectUrl) {\n    if (isOutputExportMode) {\n        // Reverse of addSegmentPathToUrlInOutputExportMode.\n        //\n        // In output: \"export\" mode, we append an extra string to the URL that\n        // represents the segment path. If the server performs a redirect, it must\n        // include the segment path in new URL.\n        //\n        // This removes the segment path from the redirected URL to obtain the\n        // URL of the page.\n        const segmentPath = requestUrl.substring(href.length);\n        if (redirectUrl.endsWith(segmentPath)) {\n            // Remove the segment path from the redirect URL to get the page URL.\n            return redirectUrl.substring(0, redirectUrl.length - segmentPath.length);\n        } else {\n        // The server redirected to a URL that doesn't include the segment path.\n        // This suggests the server may not have been configured correctly, but\n        // we'll assume the redirected URL represents the page URL and continue.\n        // TODO: Consider printing a warning with a link to a page that explains\n        // how to configure redirects and rewrites correctly.\n        }\n    }\n    return redirectUrl;\n}\nfunction createPromiseWithResolvers() {\n    // Shim of Stage 4 Promise.withResolvers proposal\n    let resolve;\n    let reject;\n    const promise = new Promise((res, rej)=>{\n        resolve = res;\n        reject = rej;\n    });\n    return {\n        resolve: resolve,\n        reject: reject,\n        promise\n    };\n}\n\n//# sourceMappingURL=cache.js.map"
        }
    ]
}