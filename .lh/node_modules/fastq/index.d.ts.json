{
    "sourceFile": "node_modules/fastq/index.d.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1746892293918,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1746891704042,
            "name": "cart",
            "content": "declare function fastq<C, T = any, R = any>(context: C, worker: fastq.worker<C, T, R>, concurrency: number): fastq.queue<T, R>\ndeclare function fastq<C, T = any, R = any>(worker: fastq.worker<C, T, R>, concurrency: number): fastq.queue<T, R>\n\ndeclare namespace fastq {\n  type worker<C, T = any, R = any> = (this: C, task: T, cb: fastq.done<R>) => void\n  type asyncWorker<C, T = any, R = any> = (this: C, task: T) => Promise<R>\n  type done<R = any> = (err: Error | null, result?: R) => void\n  type errorHandler<T = any> = (err: Error, task: T) => void\n\n  interface queue<T = any, R = any> {\n    /** Add a task at the end of the queue. `done(err, result)` will be called when the task was processed. */\n    push(task: T, done?: done<R>): void\n    /** Add a task at the beginning of the queue. `done(err, result)` will be called when the task was processed. */\n    unshift(task: T, done?: done<R>): void\n    /** Pause the processing of tasks. Currently worked tasks are not stopped. */\n    pause(): any\n    /** Resume the processing of tasks. */\n    resume(): any\n    running(): number\n    /** Returns `false` if there are tasks being processed or waiting to be processed. `true` otherwise. */\n    idle(): boolean\n    /** Returns the number of tasks waiting to be processed (in the queue). */\n    length(): number\n    /** Returns all the tasks be processed (in the queue). Returns empty array when there are no tasks */\n    getQueue(): T[]\n    /** Removes all tasks waiting to be processed, and reset `drain` to an empty function. */\n    kill(): any\n    /** Same than `kill` but the `drain` function will be called before reset to empty. */\n    killAndDrain(): any\n    /** Set a global error handler. `handler(err, task)` will be called each time a task is completed, `err` will be not null if the task has thrown an error. */\n    error(handler: errorHandler<T>): void\n    /** Property that returns the number of concurrent tasks that could be executed in parallel. It can be altered at runtime. */\n    concurrency: number\n    /** Property (Read-Only) that returns `true` when the queue is in a paused state. */\n    readonly paused: boolean\n    /** Function that will be called when the last item from the queue has been processed by a worker. It can be altered at runtime. */\n    drain(): any\n    /** Function that will be called when the last item from the queue has been assigned to a worker. It can be altered at runtime. */\n    empty: () => void\n    /** Function that will be called when the queue hits the concurrency limit. It can be altered at runtime. */\n    saturated: () => void\n  }\n\n  interface queueAsPromised<T = any, R = any> extends queue<T, R> {\n    /** Add a task at the end of the queue. The returned `Promise` will be fulfilled (rejected) when the task is completed successfully (unsuccessfully). */\n    push(task: T): Promise<R>\n    /** Add a task at the beginning of the queue. The returned `Promise` will be fulfilled (rejected) when the task is completed successfully (unsuccessfully). */\n    unshift(task: T): Promise<R>\n    /** Wait for the queue to be drained. The returned `Promise` will be resolved when all tasks in the queue have been processed by a worker. */\n    drained(): Promise<void>\n  }\n\n  function promise<C, T = any, R = any>(context: C, worker: fastq.asyncWorker<C, T, R>, concurrency: number): fastq.queueAsPromised<T, R>\n  function promise<C, T = any, R = any>(worker: fastq.asyncWorker<C, T, R>, concurrency: number): fastq.queueAsPromised<T, R>\n}\n\nexport = fastq\n"
        }
    ]
}