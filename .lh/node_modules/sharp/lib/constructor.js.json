{
    "sourceFile": "node_modules/sharp/lib/constructor.js",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1746893027461,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1746891704042,
            "name": "cart",
            "content": "// Copyright 2013 Lovell Fuller and others.\n// SPDX-License-Identifier: Apache-2.0\n\n'use strict';\n\nconst util = require('node:util');\nconst stream = require('node:stream');\nconst is = require('./is');\n\nrequire('./sharp');\n\n// Use NODE_DEBUG=sharp to enable libvips warnings\nconst debuglog = util.debuglog('sharp');\n\n/**\n * Constructor factory to create an instance of `sharp`, to which further methods are chained.\n *\n * JPEG, PNG, WebP, GIF, AVIF or TIFF format image data can be streamed out from this object.\n * When using Stream based output, derived attributes are available from the `info` event.\n *\n * Non-critical problems encountered during processing are emitted as `warning` events.\n *\n * Implements the [stream.Duplex](http://nodejs.org/api/stream.html#stream_class_stream_duplex) class.\n *\n * When loading more than one page/frame of an animated image,\n * these are combined as a vertically-stacked \"toilet roll\" image\n * where the overall height is the `pageHeight` multiplied by the number of `pages`.\n *\n * @constructs Sharp\n *\n * @emits Sharp#info\n * @emits Sharp#warning\n *\n * @example\n * sharp('input.jpg')\n *   .resize(300, 200)\n *   .toFile('output.jpg', function(err) {\n *     // output.jpg is a 300 pixels wide and 200 pixels high image\n *     // containing a scaled and cropped version of input.jpg\n *   });\n *\n * @example\n * // Read image data from remote URL,\n * // resize to 300 pixels wide,\n * // emit an 'info' event with calculated dimensions\n * // and finally write image data to writableStream\n * const { body } = fetch('https://...');\n * const readableStream = Readable.fromWeb(body);\n * const transformer = sharp()\n *   .resize(300)\n *   .on('info', ({ height }) => {\n *     console.log(`Image height is ${height}`);\n *   });\n * readableStream.pipe(transformer).pipe(writableStream);\n *\n * @example\n * // Create a blank 300x200 PNG image of semi-translucent red pixels\n * sharp({\n *   create: {\n *     width: 300,\n *     height: 200,\n *     channels: 4,\n *     background: { r: 255, g: 0, b: 0, alpha: 0.5 }\n *   }\n * })\n * .png()\n * .toBuffer()\n * .then( ... );\n *\n * @example\n * // Convert an animated GIF to an animated WebP\n * await sharp('in.gif', { animated: true }).toFile('out.webp');\n *\n * @example\n * // Read a raw array of pixels and save it to a png\n * const input = Uint8Array.from([255, 255, 255, 0, 0, 0]); // or Uint8ClampedArray\n * const image = sharp(input, {\n *   // because the input does not contain its dimensions or how many channels it has\n *   // we need to specify it in the constructor options\n *   raw: {\n *     width: 2,\n *     height: 1,\n *     channels: 3\n *   }\n * });\n * await image.toFile('my-two-pixels.png');\n *\n * @example\n * // Generate RGB Gaussian noise\n * await sharp({\n *   create: {\n *     width: 300,\n *     height: 200,\n *     channels: 3,\n *     noise: {\n *       type: 'gaussian',\n *       mean: 128,\n *       sigma: 30\n *     }\n *  }\n * }).toFile('noise.png');\n *\n * @example\n * // Generate an image from text\n * await sharp({\n *   text: {\n *     text: 'Hello, world!',\n *     width: 400, // max width\n *     height: 300 // max height\n *   }\n * }).toFile('text_bw.png');\n *\n * @example\n * // Generate an rgba image from text using pango markup and font\n * await sharp({\n *   text: {\n *     text: '<span foreground=\"red\">Red!</span><span background=\"cyan\">blue</span>',\n *     font: 'sans',\n *     rgba: true,\n *     dpi: 300\n *   }\n * }).toFile('text_rgba.png');\n *\n * @example\n * // Join four input images as a 2x2 grid with a 4 pixel gutter\n * const data = await sharp(\n *  [image1, image2, image3, image4],\n *  { join: { across: 2, shim: 4 } }\n * ).toBuffer();\n *\n * @example\n * // Generate a two-frame animated image from emoji\n * const images = ['ðŸ˜€', 'ðŸ˜›'].map(text => ({\n *   text: { text, width: 64, height: 64, channels: 4, rgba: true }\n * }));\n * await sharp(images, { join: { animated: true } }).toFile('out.gif');\n *\n * @param {(Buffer|ArrayBuffer|Uint8Array|Uint8ClampedArray|Int8Array|Uint16Array|Int16Array|Uint32Array|Int32Array|Float32Array|Float64Array|string|Array)} [input] - if present, can be\n *  a Buffer / ArrayBuffer / Uint8Array / Uint8ClampedArray containing JPEG, PNG, WebP, AVIF, GIF, SVG or TIFF image data, or\n *  a TypedArray containing raw pixel image data, or\n *  a String containing the filesystem path to an JPEG, PNG, WebP, AVIF, GIF, SVG or TIFF image file.\n *  An array of inputs can be provided, and these will be joined together.\n *  JPEG, PNG, WebP, AVIF, GIF, SVG, TIFF or raw pixel image data can be streamed into the object when not present.\n * @param {Object} [options] - if present, is an Object with optional attributes.\n * @param {string} [options.failOn='warning'] - When to abort processing of invalid pixel data, one of (in order of sensitivity, least to most): 'none', 'truncated', 'error', 'warning'. Higher levels imply lower levels. Invalid metadata will always abort.\n * @param {number|boolean} [options.limitInputPixels=268402689] - Do not process input images where the number of pixels\n *  (width x height) exceeds this limit. Assumes image dimensions contained in the input metadata can be trusted.\n *  An integral Number of pixels, zero or false to remove limit, true to use default limit of 268402689 (0x3FFF x 0x3FFF).\n * @param {boolean} [options.unlimited=false] - Set this to `true` to remove safety features that help prevent memory exhaustion (JPEG, PNG, SVG, HEIF).\n * @param {boolean} [options.autoOrient=false] - Set this to `true` to rotate/flip the image to match EXIF `Orientation`, if any.\n * @param {boolean} [options.sequentialRead=true] - Set this to `false` to use random access rather than sequential read. Some operations will do this automatically.\n * @param {number} [options.density=72] - number representing the DPI for vector images in the range 1 to 100000.\n * @param {number} [options.ignoreIcc=false] - should the embedded ICC profile, if any, be ignored.\n * @param {number} [options.pages=1] - Number of pages to extract for multi-page input (GIF, WebP, TIFF), use -1 for all pages.\n * @param {number} [options.page=0] - Page number to start extracting from for multi-page input (GIF, WebP, TIFF), zero based.\n * @param {number} [options.subifd=-1] - subIFD (Sub Image File Directory) to extract for OME-TIFF, defaults to main image.\n * @param {number} [options.level=0] - level to extract from a multi-level input (OpenSlide), zero based.\n * @param {string|Object} [options.pdfBackground] - Background colour to use when PDF is partially transparent. Parsed by the [color](https://www.npmjs.org/package/color) module to extract values for red, green, blue and alpha. Requires the use of a globally-installed libvips compiled with support for PDFium, Poppler, ImageMagick or GraphicsMagick.\n * @param {boolean} [options.animated=false] - Set to `true` to read all frames/pages of an animated image (GIF, WebP, TIFF), equivalent of setting `pages` to `-1`.\n * @param {Object} [options.raw] - describes raw pixel input image data. See `raw()` for pixel ordering.\n * @param {number} [options.raw.width] - integral number of pixels wide.\n * @param {number} [options.raw.height] - integral number of pixels high.\n * @param {number} [options.raw.channels] - integral number of channels, between 1 and 4.\n * @param {boolean} [options.raw.premultiplied] - specifies that the raw input has already been premultiplied, set to `true`\n *  to avoid sharp premultiplying the image. (optional, default `false`)\n * @param {Object} [options.create] - describes a new image to be created.\n * @param {number} [options.create.width] - integral number of pixels wide.\n * @param {number} [options.create.height] - integral number of pixels high.\n * @param {number} [options.create.channels] - integral number of channels, either 3 (RGB) or 4 (RGBA).\n * @param {string|Object} [options.create.background] - parsed by the [color](https://www.npmjs.org/package/color) module to extract values for red, green, blue and alpha.\n * @param {Object} [options.create.noise] - describes a noise to be created.\n * @param {string} [options.create.noise.type] - type of generated noise, currently only `gaussian` is supported.\n * @param {number} [options.create.noise.mean] - mean of pixels in generated noise.\n * @param {number} [options.create.noise.sigma] - standard deviation of pixels in generated noise.\n * @param {Object} [options.text] - describes a new text image to be created.\n * @param {string} [options.text.text] - text to render as a UTF-8 string. It can contain Pango markup, for example `<i>Le</i>Monde`.\n * @param {string} [options.text.font] - font name to render with.\n * @param {string} [options.text.fontfile] - absolute filesystem path to a font file that can be used by `font`.\n * @param {number} [options.text.width=0] - Integral number of pixels to word-wrap at. Lines of text wider than this will be broken at word boundaries.\n * @param {number} [options.text.height=0] - Maximum integral number of pixels high. When defined, `dpi` will be ignored and the text will automatically fit the pixel resolution defined by `width` and `height`. Will be ignored if `width` is not specified or set to 0.\n * @param {string} [options.text.align='left'] - Alignment style for multi-line text (`'left'`, `'centre'`, `'center'`, `'right'`).\n * @param {boolean} [options.text.justify=false] - set this to true to apply justification to the text.\n * @param {number} [options.text.dpi=72] - the resolution (size) at which to render the text. Does not take effect if `height` is specified.\n * @param {boolean} [options.text.rgba=false] - set this to true to enable RGBA output. This is useful for colour emoji rendering, or support for pango markup features like `<span foreground=\"red\">Red!</span>`.\n * @param {number} [options.text.spacing=0] - text line height in points. Will use the font line height if none is specified.\n * @param {string} [options.text.wrap='word'] - word wrapping style when width is provided, one of: 'word', 'char', 'word-char' (prefer word, fallback to char) or 'none'.\n * @param {Object} [options.join] - describes how an array of input images should be joined.\n * @param {number} [options.join.across=1] - number of images to join horizontally.\n * @param {boolean} [options.join.animated=false] - set this to `true` to join the images as an animated image.\n * @param {number} [options.join.shim=0] - number of pixels to insert between joined images.\n * @param {string|Object} [options.join.background] - parsed by the [color](https://www.npmjs.org/package/color) module to extract values for red, green, blue and alpha.\n * @param {string} [options.join.halign='left'] - horizontal alignment style for images joined horizontally (`'left'`, `'centre'`, `'center'`, `'right'`).\n * @param {string} [options.join.valign='top'] - vertical alignment style for images joined vertically (`'top'`, `'centre'`, `'center'`, `'bottom'`).\n *\n * @returns {Sharp}\n * @throws {Error} Invalid parameters\n */\nconst Sharp = function (input, options) {\n  if (arguments.length === 1 && !is.defined(input)) {\n    throw new Error('Invalid input');\n  }\n  if (!(this instanceof Sharp)) {\n    return new Sharp(input, options);\n  }\n  stream.Duplex.call(this);\n  this.options = {\n    // resize options\n    topOffsetPre: -1,\n    leftOffsetPre: -1,\n    widthPre: -1,\n    heightPre: -1,\n    topOffsetPost: -1,\n    leftOffsetPost: -1,\n    widthPost: -1,\n    heightPost: -1,\n    width: -1,\n    height: -1,\n    canvas: 'crop',\n    position: 0,\n    resizeBackground: [0, 0, 0, 255],\n    angle: 0,\n    rotationAngle: 0,\n    rotationBackground: [0, 0, 0, 255],\n    rotateBeforePreExtract: false,\n    flip: false,\n    flop: false,\n    extendTop: 0,\n    extendBottom: 0,\n    extendLeft: 0,\n    extendRight: 0,\n    extendBackground: [0, 0, 0, 255],\n    extendWith: 'background',\n    withoutEnlargement: false,\n    withoutReduction: false,\n    affineMatrix: [],\n    affineBackground: [0, 0, 0, 255],\n    affineIdx: 0,\n    affineIdy: 0,\n    affineOdx: 0,\n    affineOdy: 0,\n    affineInterpolator: this.constructor.interpolators.bilinear,\n    kernel: 'lanczos3',\n    fastShrinkOnLoad: true,\n    // operations\n    tint: [-1, 0, 0, 0],\n    flatten: false,\n    flattenBackground: [0, 0, 0],\n    unflatten: false,\n    negate: false,\n    negateAlpha: true,\n    medianSize: 0,\n    blurSigma: 0,\n    precision: 'integer',\n    minAmpl: 0.2,\n    sharpenSigma: 0,\n    sharpenM1: 1,\n    sharpenM2: 2,\n    sharpenX1: 2,\n    sharpenY2: 10,\n    sharpenY3: 20,\n    threshold: 0,\n    thresholdGrayscale: true,\n    trimBackground: [],\n    trimThreshold: -1,\n    trimLineArt: false,\n    dilateWidth: 0,\n    erodeWidth: 0,\n    gamma: 0,\n    gammaOut: 0,\n    greyscale: false,\n    normalise: false,\n    normaliseLower: 1,\n    normaliseUpper: 99,\n    claheWidth: 0,\n    claheHeight: 0,\n    claheMaxSlope: 3,\n    brightness: 1,\n    saturation: 1,\n    hue: 0,\n    lightness: 0,\n    booleanBufferIn: null,\n    booleanFileIn: '',\n    joinChannelIn: [],\n    extractChannel: -1,\n    removeAlpha: false,\n    ensureAlpha: -1,\n    colourspace: 'srgb',\n    colourspacePipeline: 'last',\n    composite: [],\n    // output\n    fileOut: '',\n    formatOut: 'input',\n    streamOut: false,\n    keepMetadata: 0,\n    withMetadataOrientation: -1,\n    withMetadataDensity: 0,\n    withIccProfile: '',\n    withExif: {},\n    withExifMerge: true,\n    resolveWithObject: false,\n    loop: 1,\n    delay: [],\n    // output format\n    jpegQuality: 80,\n    jpegProgressive: false,\n    jpegChromaSubsampling: '4:2:0',\n    jpegTrellisQuantisation: false,\n    jpegOvershootDeringing: false,\n    jpegOptimiseScans: false,\n    jpegOptimiseCoding: true,\n    jpegQuantisationTable: 0,\n    pngProgressive: false,\n    pngCompressionLevel: 6,\n    pngAdaptiveFiltering: false,\n    pngPalette: false,\n    pngQuality: 100,\n    pngEffort: 7,\n    pngBitdepth: 8,\n    pngDither: 1,\n    jp2Quality: 80,\n    jp2TileHeight: 512,\n    jp2TileWidth: 512,\n    jp2Lossless: false,\n    jp2ChromaSubsampling: '4:4:4',\n    webpQuality: 80,\n    webpAlphaQuality: 100,\n    webpLossless: false,\n    webpNearLossless: false,\n    webpSmartSubsample: false,\n    webpSmartDeblock: false,\n    webpPreset: 'default',\n    webpEffort: 4,\n    webpMinSize: false,\n    webpMixed: false,\n    gifBitdepth: 8,\n    gifEffort: 7,\n    gifDither: 1,\n    gifInterFrameMaxError: 0,\n    gifInterPaletteMaxError: 3,\n    gifReuse: true,\n    gifProgressive: false,\n    tiffQuality: 80,\n    tiffCompression: 'jpeg',\n    tiffPredictor: 'horizontal',\n    tiffPyramid: false,\n    tiffMiniswhite: false,\n    tiffBitdepth: 8,\n    tiffTile: false,\n    tiffTileHeight: 256,\n    tiffTileWidth: 256,\n    tiffXres: 1.0,\n    tiffYres: 1.0,\n    tiffResolutionUnit: 'inch',\n    heifQuality: 50,\n    heifLossless: false,\n    heifCompression: 'av1',\n    heifEffort: 4,\n    heifChromaSubsampling: '4:4:4',\n    heifBitdepth: 8,\n    jxlDistance: 1,\n    jxlDecodingTier: 0,\n    jxlEffort: 7,\n    jxlLossless: false,\n    rawDepth: 'uchar',\n    tileSize: 256,\n    tileOverlap: 0,\n    tileContainer: 'fs',\n    tileLayout: 'dz',\n    tileFormat: 'last',\n    tileDepth: 'last',\n    tileAngle: 0,\n    tileSkipBlanks: -1,\n    tileBackground: [255, 255, 255, 255],\n    tileCentre: false,\n    tileId: 'https://example.com/iiif',\n    tileBasename: '',\n    timeoutSeconds: 0,\n    linearA: [],\n    linearB: [],\n    pdfBackground: [255, 255, 255, 255],\n    // Function to notify of libvips warnings\n    debuglog: warning => {\n      this.emit('warning', warning);\n      debuglog(warning);\n    },\n    // Function to notify of queue length changes\n    queueListener: function (queueLength) {\n      Sharp.queue.emit('change', queueLength);\n    }\n  };\n  this.options.input = this._createInputDescriptor(input, options, { allowStream: true });\n  return this;\n};\nObject.setPrototypeOf(Sharp.prototype, stream.Duplex.prototype);\nObject.setPrototypeOf(Sharp, stream.Duplex);\n\n/**\n * Take a \"snapshot\" of the Sharp instance, returning a new instance.\n * Cloned instances inherit the input of their parent instance.\n * This allows multiple output Streams and therefore multiple processing pipelines to share a single input Stream.\n *\n * @example\n * const pipeline = sharp().rotate();\n * pipeline.clone().resize(800, 600).pipe(firstWritableStream);\n * pipeline.clone().extract({ left: 20, top: 20, width: 100, height: 100 }).pipe(secondWritableStream);\n * readableStream.pipe(pipeline);\n * // firstWritableStream receives auto-rotated, resized readableStream\n * // secondWritableStream receives auto-rotated, extracted region of readableStream\n *\n * @example\n * // Create a pipeline that will download an image, resize it and format it to different files\n * // Using Promises to know when the pipeline is complete\n * const fs = require(\"fs\");\n * const got = require(\"got\");\n * const sharpStream = sharp({ failOn: 'none' });\n *\n * const promises = [];\n *\n * promises.push(\n *   sharpStream\n *     .clone()\n *     .jpeg({ quality: 100 })\n *     .toFile(\"originalFile.jpg\")\n * );\n *\n * promises.push(\n *   sharpStream\n *     .clone()\n *     .resize({ width: 500 })\n *     .jpeg({ quality: 80 })\n *     .toFile(\"optimized-500.jpg\")\n * );\n *\n * promises.push(\n *   sharpStream\n *     .clone()\n *     .resize({ width: 500 })\n *     .webp({ quality: 80 })\n *     .toFile(\"optimized-500.webp\")\n * );\n *\n * // https://github.com/sindresorhus/got/blob/main/documentation/3-streams.md\n * got.stream(\"https://www.example.com/some-file.jpg\").pipe(sharpStream);\n *\n * Promise.all(promises)\n *   .then(res => { console.log(\"Done!\", res); })\n *   .catch(err => {\n *     console.error(\"Error processing files, let's clean it up\", err);\n *     try {\n *       fs.unlinkSync(\"originalFile.jpg\");\n *       fs.unlinkSync(\"optimized-500.jpg\");\n *       fs.unlinkSync(\"optimized-500.webp\");\n *     } catch (e) {}\n *   });\n *\n * @returns {Sharp}\n */\nfunction clone () {\n  // Clone existing options\n  const clone = this.constructor.call();\n  const { debuglog, queueListener, ...options } = this.options;\n  clone.options = structuredClone(options);\n  clone.options.debuglog = debuglog;\n  clone.options.queueListener = queueListener;\n  // Pass 'finish' event to clone for Stream-based input\n  if (this._isStreamInput()) {\n    this.on('finish', () => {\n      // Clone inherits input data\n      this._flattenBufferIn();\n      clone.options.input.buffer = this.options.input.buffer;\n      clone.emit('finish');\n    });\n  }\n  return clone;\n}\nObject.assign(Sharp.prototype, { clone });\n\n/**\n * Export constructor.\n * @module Sharp\n * @private\n */\nmodule.exports = Sharp;\n"
        }
    ]
}